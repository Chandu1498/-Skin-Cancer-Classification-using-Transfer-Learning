{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiFfpaxJ7Eiw"
      },
      "source": [
        "#Transfer Learning.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ABdJtgZCqCJ",
        "outputId": "18aea696-8b62-4dfc-8133-94fd7f086cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSsJa4LzCqCJ",
        "outputId": "1d8120d9-826a-4a2e-c6b1-b7f149442005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/University of Southampton\n",
            "/content/drive/MyDrive/University of Southampton/Desertation Project\n",
            "/content/drive/MyDrive/University of Southampton/Desertation Project/Code\n",
            "/content/drive/MyDrive/University of Southampton/Desertation Project/Code/Main Code files\n",
            "/content/drive/MyDrive/University of Southampton/Desertation Project/Code/Main Code files/cascade_transfer_learning_medical\n"
          ]
        }
      ],
      "source": [
        "%cd drive\n",
        "%cd MyDrive\n",
        "%cd University of Southampton\n",
        "%cd Desertation Project\n",
        "%cd Code\n",
        "%cd Main Code files\n",
        "%cd cascade_transfer_learning_medical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZzpsiYdTcsq",
        "outputId": "c2f94a10-413e-4d8e-949b-e54ea89baaf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  7 10:02:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDvcrsZ09x8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OwtT8Qt39x5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1J9e3hXdaZO"
      },
      "source": [
        "#EDA of Melanoma Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDloxPYcSkcv"
      },
      "source": [
        "Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdJj6437Skcx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQeDpBmqSkcy"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('siim-isic-melanoma-classification/train.csv')\n",
        "test = pd.read_csv('siim-isic-melanoma-classification/test.csv')\n",
        "sample = pd.read_csv('siim-isic-melanoma-classification/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hE7XfxWJSkcz",
        "outputId": "2928e07a-1fed-433a-f806-6050a00ebf9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cc4c05c3-37b2-435a-b77e-e7287723b397\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>anatom_site_general_challenge</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>benign_malignant</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_2637011</td>\n",
              "      <td>IP_7279968</td>\n",
              "      <td>male</td>\n",
              "      <td>45.0</td>\n",
              "      <td>head/neck</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0015719</td>\n",
              "      <td>IP_3075186</td>\n",
              "      <td>female</td>\n",
              "      <td>45.0</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0052212</td>\n",
              "      <td>IP_2842074</td>\n",
              "      <td>female</td>\n",
              "      <td>50.0</td>\n",
              "      <td>lower extremity</td>\n",
              "      <td>nevus</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0068279</td>\n",
              "      <td>IP_6890425</td>\n",
              "      <td>female</td>\n",
              "      <td>45.0</td>\n",
              "      <td>head/neck</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0074268</td>\n",
              "      <td>IP_8723313</td>\n",
              "      <td>female</td>\n",
              "      <td>55.0</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33121</th>\n",
              "      <td>ISIC_9999134</td>\n",
              "      <td>IP_6526534</td>\n",
              "      <td>male</td>\n",
              "      <td>50.0</td>\n",
              "      <td>torso</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33122</th>\n",
              "      <td>ISIC_9999320</td>\n",
              "      <td>IP_3650745</td>\n",
              "      <td>male</td>\n",
              "      <td>65.0</td>\n",
              "      <td>torso</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33123</th>\n",
              "      <td>ISIC_9999515</td>\n",
              "      <td>IP_2026598</td>\n",
              "      <td>male</td>\n",
              "      <td>20.0</td>\n",
              "      <td>lower extremity</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33124</th>\n",
              "      <td>ISIC_9999666</td>\n",
              "      <td>IP_7702038</td>\n",
              "      <td>male</td>\n",
              "      <td>50.0</td>\n",
              "      <td>lower extremity</td>\n",
              "      <td>unknown</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33125</th>\n",
              "      <td>ISIC_9999806</td>\n",
              "      <td>IP_0046310</td>\n",
              "      <td>male</td>\n",
              "      <td>45.0</td>\n",
              "      <td>torso</td>\n",
              "      <td>nevus</td>\n",
              "      <td>benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33126 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc4c05c3-37b2-435a-b77e-e7287723b397')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc4c05c3-37b2-435a-b77e-e7287723b397 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc4c05c3-37b2-435a-b77e-e7287723b397');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         image_name  patient_id     sex  age_approx  \\\n",
              "0      ISIC_2637011  IP_7279968    male        45.0   \n",
              "1      ISIC_0015719  IP_3075186  female        45.0   \n",
              "2      ISIC_0052212  IP_2842074  female        50.0   \n",
              "3      ISIC_0068279  IP_6890425  female        45.0   \n",
              "4      ISIC_0074268  IP_8723313  female        55.0   \n",
              "...             ...         ...     ...         ...   \n",
              "33121  ISIC_9999134  IP_6526534    male        50.0   \n",
              "33122  ISIC_9999320  IP_3650745    male        65.0   \n",
              "33123  ISIC_9999515  IP_2026598    male        20.0   \n",
              "33124  ISIC_9999666  IP_7702038    male        50.0   \n",
              "33125  ISIC_9999806  IP_0046310    male        45.0   \n",
              "\n",
              "      anatom_site_general_challenge diagnosis benign_malignant  target  \n",
              "0                         head/neck   unknown           benign       0  \n",
              "1                   upper extremity   unknown           benign       0  \n",
              "2                   lower extremity     nevus           benign       0  \n",
              "3                         head/neck   unknown           benign       0  \n",
              "4                   upper extremity   unknown           benign       0  \n",
              "...                             ...       ...              ...     ...  \n",
              "33121                         torso   unknown           benign       0  \n",
              "33122                         torso   unknown           benign       0  \n",
              "33123               lower extremity   unknown           benign       0  \n",
              "33124               lower extremity   unknown           benign       0  \n",
              "33125                         torso     nevus           benign       0  \n",
              "\n",
              "[33126 rows x 8 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-OT5_Fm3U0B2",
        "outputId": "1b80a7e9-5a5d-4418-fc87-7cc2c7be1b16"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-079c5de7-d2c9-4f24-b02e-84159dabae91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>anatom_site_general_challenge</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0052060</td>\n",
              "      <td>IP_3579794</td>\n",
              "      <td>male</td>\n",
              "      <td>70.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0052349</td>\n",
              "      <td>IP_7782715</td>\n",
              "      <td>male</td>\n",
              "      <td>40.0</td>\n",
              "      <td>lower extremity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0058510</td>\n",
              "      <td>IP_7960270</td>\n",
              "      <td>female</td>\n",
              "      <td>55.0</td>\n",
              "      <td>torso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0073313</td>\n",
              "      <td>IP_6375035</td>\n",
              "      <td>female</td>\n",
              "      <td>50.0</td>\n",
              "      <td>torso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0073502</td>\n",
              "      <td>IP_0589375</td>\n",
              "      <td>female</td>\n",
              "      <td>45.0</td>\n",
              "      <td>lower extremity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10977</th>\n",
              "      <td>ISIC_9992485</td>\n",
              "      <td>IP_4152479</td>\n",
              "      <td>male</td>\n",
              "      <td>40.0</td>\n",
              "      <td>torso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10978</th>\n",
              "      <td>ISIC_9996992</td>\n",
              "      <td>IP_4890115</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>torso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10979</th>\n",
              "      <td>ISIC_9997917</td>\n",
              "      <td>IP_2852390</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>upper extremity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10980</th>\n",
              "      <td>ISIC_9998234</td>\n",
              "      <td>IP_8861963</td>\n",
              "      <td>male</td>\n",
              "      <td>65.0</td>\n",
              "      <td>lower extremity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10981</th>\n",
              "      <td>ISIC_9999302</td>\n",
              "      <td>IP_6214039</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0</td>\n",
              "      <td>upper extremity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10982 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-079c5de7-d2c9-4f24-b02e-84159dabae91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-079c5de7-d2c9-4f24-b02e-84159dabae91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-079c5de7-d2c9-4f24-b02e-84159dabae91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         image_name  patient_id     sex  age_approx  \\\n",
              "0      ISIC_0052060  IP_3579794    male        70.0   \n",
              "1      ISIC_0052349  IP_7782715    male        40.0   \n",
              "2      ISIC_0058510  IP_7960270  female        55.0   \n",
              "3      ISIC_0073313  IP_6375035  female        50.0   \n",
              "4      ISIC_0073502  IP_0589375  female        45.0   \n",
              "...             ...         ...     ...         ...   \n",
              "10977  ISIC_9992485  IP_4152479    male        40.0   \n",
              "10978  ISIC_9996992  IP_4890115    male        35.0   \n",
              "10979  ISIC_9997917  IP_2852390    male        25.0   \n",
              "10980  ISIC_9998234  IP_8861963    male        65.0   \n",
              "10981  ISIC_9999302  IP_6214039    male        30.0   \n",
              "\n",
              "      anatom_site_general_challenge  \n",
              "0                               NaN  \n",
              "1                   lower extremity  \n",
              "2                             torso  \n",
              "3                             torso  \n",
              "4                   lower extremity  \n",
              "...                             ...  \n",
              "10977                         torso  \n",
              "10978                         torso  \n",
              "10979               upper extremity  \n",
              "10980               lower extremity  \n",
              "10981               upper extremity  \n",
              "\n",
              "[10982 rows x 5 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbhBmxAmSkc0",
        "outputId": "635e38c8-2f4f-4daf-a53f-cca84b569434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data has 8 features,\n",
            " \t33126 observations  \n",
            " \tTest data 5 features, \n",
            " \t10982 observations.\n",
            " \n",
            "Train features are:\n",
            "['image_name', 'patient_id', 'sex', 'age_approx', 'anatom_site_general_challenge', 'diagnosis', 'benign_malignant', 'target']\n",
            " \n",
            "Test features are:\n",
            "['image_name', 'patient_id', 'sex', 'age_approx', 'anatom_site_general_challenge']\n"
          ]
        }
      ],
      "source": [
        "print(f'Train data has {train.shape[1]} features,\\n \\t{train.shape[0]} observations  \\n \\tTest data {test.shape[1]} features, \\n \\t{test.shape[0]} observations.\\n \\nTrain features are:\\n{train.columns.tolist()}\\n \\nTest features are:\\n{test.columns.tolist()}'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiELDcN-Skc1"
      },
      "outputs": [],
      "source": [
        "train.columns = [\n",
        "    'img_name', 'patient_id', 'sex', 'age', 'location', 'target','width','height'\n",
        "]\n",
        "\n",
        "test.columns = ['img_name', 'patient_id', 'sex', 'age', 'location']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "Z8VkeC1DSkc3",
        "outputId": "c4482cd1-9554-4ba1-d1be-c7ab32725ba3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x648 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(constrained_layout=True, figsize=(20, 9))\n",
        "grid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n",
        "\n",
        "ax1 = fig.add_subplot(grid[0, :2])\n",
        "ax1.set_title('Gender Distribution')\n",
        "sns.countplot(train.sex.sort_values(ignore_index=True),\n",
        "              alpha=0.9,\n",
        "              ax=ax1,\n",
        "              color='#C3073F',\n",
        "              label='Train')\n",
        "sns.countplot(test.sex.sort_values(ignore_index=True),\n",
        "              alpha=0.7,\n",
        "              ax=ax1,\n",
        "              color='#1A1A1D',\n",
        "              label='Test')\n",
        "ax1.legend()\n",
        "ax2 = fig.add_subplot(grid[0, 2:])\n",
        "sns.countplot(train.location,\n",
        "              alpha=0.9,\n",
        "              ax=ax2,\n",
        "              color='#C3073F',\n",
        "              label='Train',\n",
        "              order=train['location'].value_counts().index)\n",
        "sns.countplot(test.location,\n",
        "              alpha=0.7,\n",
        "              ax=ax2,\n",
        "              color='#1A1A1D',\n",
        "              label='Test',\n",
        "              order=test['location'].value_counts().index), ax2.set_title(\n",
        "                  'Anatom Site Distribution')\n",
        "ax2.legend()\n",
        "plt.xticks(rotation=20)\n",
        "ax3 = fig.add_subplot(grid[1, :])\n",
        "ax3.set_title('Age Distribution')\n",
        "sns.distplot(train.age, ax=ax3, label='Train', color='#C3073F')\n",
        "sns.distplot(test.age, ax=ax3, label='Test', color='#1A1A1D')\n",
        "ax3.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al7h-NzVSkc4"
      },
      "outputs": [],
      "source": [
        "for df in [train, test]:\n",
        "    df['location'].fillna('unknown', inplace=True)\n",
        "    \n",
        "train['sex'].fillna('unknown', inplace=True)\n",
        "\n",
        "train['age'].fillna(-1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m23xa4z7Skc5",
        "outputId": "42a698ad-9140-4fbf-8058-cdce345325b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are no different body parts occuring between train and test set.\n"
          ]
        }
      ],
      "source": [
        "ids_train = train.location.values\n",
        "ids_test = test.location.values\n",
        "ids_train_set = set(ids_train)\n",
        "ids_test_set = set(ids_test)\n",
        "\n",
        "location_not_overlap = list(ids_train_set.symmetric_difference(ids_test_set))\n",
        "n_overlap = len(location_not_overlap)\n",
        "if n_overlap == 0:\n",
        "    print(\n",
        "        f'There are no different body parts occuring between train and test set.'\n",
        "    )\n",
        "else:\n",
        "    print('There are some non-overlapping values between train and test set!\\n')\n",
        "    print(f'Different ones are:\\n{pd.Series(np.setdiff1d((train.location.value_counts().index), pd.Series(test.location.value_counts().index)))}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDFbw6EFSkc5"
      },
      "outputs": [],
      "source": [
        "train.replace(['anterior torso','lateral torso','posterior torso'], 'torso', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "S-GiuEUXSkc6",
        "outputId": "948223f9-dbe1-401b-8592-44d7606880df"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(constrained_layout=True, figsize=(15, 6))\n",
        "grid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n",
        "ax1 = fig.add_subplot(grid[1, :2])\n",
        "ax1.set_title('Scanned Body Parts - Female')\n",
        "sns.countplot(\n",
        "    train[train['sex'] == 'female'].location.sort_values(ignore_index=True),\n",
        "    alpha=0.9,\n",
        "    ax=ax1,\n",
        "    color='#C3073F',\n",
        "    label='Female',\n",
        "    order=train['location'].value_counts().index)\n",
        "ax1.legend()\n",
        "plt.xticks(rotation=20)\n",
        "ax2 = fig.add_subplot(grid[1, 2:])\n",
        "ax2.set_title('Scanned Body Parts - Male')\n",
        "sns.countplot(\n",
        "    train[train['sex'] == 'male'].location.sort_values(ignore_index=True),\n",
        "    alpha=0.9,\n",
        "    ax=ax2,\n",
        "    color='#1A1A1D',\n",
        "    label='Male',\n",
        "    order=train['location'].value_counts().index)\n",
        "\n",
        "ax2.legend()\n",
        "plt.xticks(rotation=20)\n",
        "ax3.set_title('Malignant Ratio Per Body Part')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KHzvPwFySkc6",
        "outputId": "c4cc14d0-6534-4130-e4f4-2b36844b8974"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"0d5757c3-249a-47d0-b05d-67be9a75fb15\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0d5757c3-249a-47d0-b05d-67be9a75fb15\")) {                    Plotly.newPlot(                        \"0d5757c3-249a-47d0-b05d-67be9a75fb15\",                        [{\"branchvalues\":\"total\",\"customdata\":[[\"(?)\"],[\"male\"],[\"male\"],[\"female\"],[\"male\"],[\"female\"],[\"female\"],[\"female\"],[\"female\"],[\"female\"],[\"male\"],[\"female\"],[\"male\"],[\"male\"],[\"(?)\"],[\"unknown\"],[\"female\"],[\"female\"],[\"female\"],[\"male\"],[\"male\"],[\"male\"],[\"male\"],[\"female\"],[\"female\"],[\"female\"],[\"female\"],[\"male\"],[\"female\"],[\"female\"],[\"unknown\"],[\"male\"],[\"male\"],[\"female\"],[\"(?)\"],[\"male\"],[\"male\"],[\"(?)\"],[\"male\"],[\"male\"],[\"male\"],[\"male\"],[\"female\"],[\"female\"],[\"female\"],[\"male\"],[\"female\"],[\"male\"],[\"male\"],[\"male\"],[\"female\"],[\"female\"],[\"(?)\"],[\"(?)\"],[\"male\"],[\"male\"],[\"(?)\"],[\"unknown\"],[\"female\"],[\"unknown\"],[\"female\"],[\"male\"],[\"male\"],[\"female\"],[\"female\"],[\"male\"],[\"male\"],[\"male\"],[\"male\"],[\"female\"],[\"female\"],[\"male\"],[\"male\"],[\"male\"],[\"male\"],[\"unknown\"],[\"female\"],[\"female\"],[\"female\"],[\"female\"],[\"female\"],[\"female\"],[\"male\"],[\"male\"],[\"male\"],[\"male\"],[\"male\"],[\"male\"],[\"female\"],[\"male\"],[\"male\"],[\"female\"],[\"female\"],[\"male\"],[\"female\"],[\"male\"],[\"male\"],[\"female\"],[\"male\"],[\"female\"],[\"female\"],[\"male\"],[\"male\"],[\"male\"]],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"labels=%{label}<br>count=%{value}<br>parent=%{parent}<br>id=%{id}<br>sex=%{customdata[0]}<extra></extra>\",\"ids\":[\"unknown\",\"unknown/male/oral/genital\",\"lichenoid keratosis/male/upper extremity\",\"solar lentigo/female\",\"melanoma/male/palms/soles\",\"lentigo NOS/female/torso\",\"lichenoid keratosis/female/torso\",\"melanoma/female/torso\",\"nevus/female/torso\",\"seborrheic keratosis/female/torso\",\"cafe-au-lait macule/male/torso\",\"lentigo NOS/female\",\"seborrheic keratosis/male/torso\",\"seborrheic keratosis/male/oral/genital\",\"solar lentigo\",\"unknown/unknown/torso\",\"melanoma/female/unknown\",\"seborrheic keratosis/female/unknown\",\"unknown/female/unknown\",\"nevus/male/upper extremity\",\"nevus/male/unknown\",\"melanoma/male/upper extremity\",\"unknown/male/unknown\",\"lentigo NOS/female/upper extremity\",\"lichenoid keratosis/female/upper extremity\",\"melanoma/female/upper extremity\",\"nevus/female/upper extremity\",\"unknown/male/torso\",\"unknown/female/oral/genital\",\"unknown/female\",\"unknown/unknown/lower extremity\",\"unknown/male/head/neck\",\"cafe-au-lait macule\",\"melanoma/female/oral/genital\",\"melanoma\",\"atypical melanocytic proliferation\",\"melanoma/male/head/neck\",\"nevus\",\"lentigo NOS/male/head/neck\",\"solar lentigo/male/head/neck\",\"seborrheic keratosis/male\",\"solar lentigo/male\",\"unknown/female/head/neck\",\"seborrheic keratosis/female/head/neck\",\"nevus/female/head/neck\",\"lichenoid keratosis/male/lower extremity\",\"melanoma/female/head/neck\",\"lichenoid keratosis/male\",\"lentigo NOS/male\",\"cafe-au-lait macule/male\",\"lichenoid keratosis/female/head/neck\",\"unknown/female/lower extremity\",\"lichenoid keratosis\",\"seborrheic keratosis\",\"seborrheic keratosis/male/upper extremity\",\"unknown/male/upper extremity\",\"lentigo NOS\",\"unknown/unknown/upper extremity\",\"lichenoid keratosis/female\",\"unknown/unknown\",\"melanoma/female\",\"unknown/male\",\"nevus/male\",\"nevus/female\",\"seborrheic keratosis/female\",\"melanoma/male\",\"atypical melanocytic proliferation/male\",\"solar lentigo/male/upper extremity\",\"lentigo NOS/male/upper extremity\",\"lentigo NOS/female/head/neck\",\"solar lentigo/female/upper extremity\",\"atypical melanocytic proliferation/male/head/neck\",\"lichenoid keratosis/male/head/neck\",\"nevus/male/head/neck\",\"seborrheic keratosis/male/head/neck\",\"unknown/unknown/head/neck\",\"lentigo NOS/female/lower extremity\",\"lichenoid keratosis/female/lower extremity\",\"melanoma/female/lower extremity\",\"nevus/female/lower extremity\",\"seborrheic keratosis/female/lower extremity\",\"solar lentigo/female/lower extremity\",\"lentigo NOS/male/lower extremity\",\"melanoma/male/lower extremity\",\"nevus/male/lower extremity\",\"seborrheic keratosis/male/lower extremity\",\"unknown/male/lower extremity\",\"melanoma/male/oral/genital\",\"seborrheic keratosis/female/upper extremity\",\"seborrheic keratosis/male/unknown\",\"melanoma/male/unknown\",\"nevus/female/unknown\",\"lichenoid keratosis/female/unknown\",\"nevus/male/torso\",\"unknown/female/upper extremity\",\"melanoma/male/torso\",\"lentigo NOS/male/torso\",\"unknown/female/torso\",\"nevus/male/palms/soles\",\"unknown/female/palms/soles\",\"melanoma/female/palms/soles\",\"lichenoid keratosis/male/torso\",\"solar lentigo/male/torso\",\"unknown/male/palms/soles\"],\"labels\":[\"unknown\",\"oral/genital\",\"upper extremity\",\"female\",\"palms/soles\",\"torso\",\"torso\",\"torso\",\"torso\",\"torso\",\"torso\",\"female\",\"torso\",\"oral/genital\",\"solar lentigo\",\"torso\",\"unknown\",\"unknown\",\"unknown\",\"upper extremity\",\"unknown\",\"upper extremity\",\"unknown\",\"upper extremity\",\"upper extremity\",\"upper extremity\",\"upper extremity\",\"torso\",\"oral/genital\",\"female\",\"lower extremity\",\"head/neck\",\"cafe-au-lait macule\",\"oral/genital\",\"melanoma\",\"atypical melanocytic proliferation\",\"head/neck\",\"nevus\",\"head/neck\",\"head/neck\",\"male\",\"male\",\"head/neck\",\"head/neck\",\"head/neck\",\"lower extremity\",\"head/neck\",\"male\",\"male\",\"male\",\"head/neck\",\"lower extremity\",\"lichenoid keratosis\",\"seborrheic keratosis\",\"upper extremity\",\"upper extremity\",\"lentigo NOS\",\"upper extremity\",\"female\",\"unknown\",\"female\",\"male\",\"male\",\"female\",\"female\",\"male\",\"male\",\"upper extremity\",\"upper extremity\",\"head/neck\",\"upper extremity\",\"head/neck\",\"head/neck\",\"head/neck\",\"head/neck\",\"head/neck\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"lower extremity\",\"oral/genital\",\"upper extremity\",\"unknown\",\"unknown\",\"unknown\",\"unknown\",\"torso\",\"upper extremity\",\"torso\",\"torso\",\"torso\",\"palms/soles\",\"palms/soles\",\"palms/soles\",\"torso\",\"torso\",\"palms/soles\"],\"marker\":{\"colors\":[\"#1A1A1D\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#1A1A1D\",\"#6F2232\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#6F2232\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#1A1A1D\",\"#4E4E50\",\"#4E4E50\",\"#1A1A1D\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#1A1A1D\",\"#1A1A1D\",\"#4E4E50\",\"#4E4E50\",\"#1A1A1D\",\"#6F2232\",\"#C5C6C7\",\"#6F2232\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#6F2232\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#C5C6C7\",\"#4E4E50\",\"#C5C6C7\",\"#C5C6C7\",\"#4E4E50\",\"#4E4E50\",\"#4E4E50\"]},\"maxdepth\":-1,\"name\":\"\",\"parents\":[\"\",\"unknown/male\",\"lichenoid keratosis/male\",\"solar lentigo\",\"melanoma/male\",\"lentigo NOS/female\",\"lichenoid keratosis/female\",\"melanoma/female\",\"nevus/female\",\"seborrheic keratosis/female\",\"cafe-au-lait macule/male\",\"lentigo NOS\",\"seborrheic keratosis/male\",\"seborrheic keratosis/male\",\"\",\"unknown/unknown\",\"melanoma/female\",\"seborrheic keratosis/female\",\"unknown/female\",\"nevus/male\",\"nevus/male\",\"melanoma/male\",\"unknown/male\",\"lentigo NOS/female\",\"lichenoid keratosis/female\",\"melanoma/female\",\"nevus/female\",\"unknown/male\",\"unknown/female\",\"unknown\",\"unknown/unknown\",\"unknown/male\",\"\",\"melanoma/female\",\"\",\"\",\"melanoma/male\",\"\",\"lentigo NOS/male\",\"solar lentigo/male\",\"seborrheic keratosis\",\"solar lentigo\",\"unknown/female\",\"seborrheic keratosis/female\",\"nevus/female\",\"lichenoid keratosis/male\",\"melanoma/female\",\"lichenoid keratosis\",\"lentigo NOS\",\"cafe-au-lait macule\",\"lichenoid keratosis/female\",\"unknown/female\",\"\",\"\",\"seborrheic keratosis/male\",\"unknown/male\",\"\",\"unknown/unknown\",\"lichenoid keratosis\",\"unknown\",\"melanoma\",\"unknown\",\"nevus\",\"nevus\",\"seborrheic keratosis\",\"melanoma\",\"atypical melanocytic proliferation\",\"solar lentigo/male\",\"lentigo NOS/male\",\"lentigo NOS/female\",\"solar lentigo/female\",\"atypical melanocytic proliferation/male\",\"lichenoid keratosis/male\",\"nevus/male\",\"seborrheic keratosis/male\",\"unknown/unknown\",\"lentigo NOS/female\",\"lichenoid keratosis/female\",\"melanoma/female\",\"nevus/female\",\"seborrheic keratosis/female\",\"solar lentigo/female\",\"lentigo NOS/male\",\"melanoma/male\",\"nevus/male\",\"seborrheic keratosis/male\",\"unknown/male\",\"melanoma/male\",\"seborrheic keratosis/female\",\"seborrheic keratosis/male\",\"melanoma/male\",\"nevus/female\",\"lichenoid keratosis/female\",\"nevus/male\",\"unknown/female\",\"melanoma/male\",\"lentigo NOS/male\",\"unknown/female\",\"nevus/male\",\"unknown/female\",\"melanoma/female\",\"lichenoid keratosis/male\",\"solar lentigo/male\",\"unknown/male\"],\"values\":[27124,77,2,3,4,3,6,85,1241,20,1,26,32,1,7,19,3,2,206,299,20,61,263,11,2,50,265,7257,42,13351,18,847,1,3,584,1,54,5193,5,1,89,4,739,11,57,3,20,21,18,1,2,3642,37,135,12,1897,44,20,16,65,220,13708,2874,2319,46,364,1,1,4,5,2,1,3,74,28,8,7,5,58,733,3,1,3,66,716,13,3149,1,10,3,6,23,1,1763,2347,172,6,6225,2,150,1,13,2,218],\"type\":\"sunburst\",\"textinfo\":\"label+percent parent\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Sunburst Chart Benign/Malignant > Sex > Location\"},\"sunburstcolorway\":[\"#1A1A1D\",\"#4E4E50\",\"#C5C6C7\",\"#6F2232\",\"#950740\",\"#C3073F\"],\"margin\":{\"t\":0,\"l\":0,\"r\":0,\"b\":0}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0d5757c3-249a-47d0-b05d-67be9a75fb15');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = px.sunburst(data_frame=train,\n",
        "                  path=['target', 'sex', 'location'],\n",
        "                  color='sex',\n",
        "                  color_discrete_sequence=black_red,\n",
        "                  maxdepth=-1,\n",
        "                  title='Sunburst Chart Benign/Malignant > Sex > Location')\n",
        "fig.update_traces(textinfo='label+percent parent')\n",
        "fig.update_layout(margin=dict(t=0, l=0, r=0, b=0))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "vp9nGXw_Skc7",
        "outputId": "6e75ebd6-3d5a-456f-d51c-05ff0fb3d105"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "sns.lineplot(x='age',\n",
        "             y='target',\n",
        "             data=train,\n",
        "             ax=ax[0],\n",
        "             hue='sex',\n",
        "             palette=black_red[2:5],\n",
        "             ci=None)\n",
        "sns.boxplot(x='target',\n",
        "            y='age',\n",
        "            data=train,\n",
        "            ax=ax[1],\n",
        "            hue='sex',\n",
        "            palette=black_red[2:5]\n",
        "           )\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "ax[0].set_title('Malignant Scan Frequency by Age')\n",
        "ax[1].set_title('Scan Results by Age and Sex')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "G10Y1crtSkc8",
        "outputId": "c586e8b4-b01a-4dc2-9423-40cbae032474"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x864 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(constrained_layout=True, figsize=(20, 12))\n",
        "grid = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n",
        "sns.kdeplot(train[train['target'] == 0]['age'],\n",
        "            shade=True,\n",
        "            ax=ax1,\n",
        "            color='#1A1A1D',\n",
        "            label='Benign')\n",
        "sns.kdeplot(train[train['target'] == 1]['age'],\n",
        "            shade=True,\n",
        "            ax=ax1,\n",
        "            color='#C3073F',\n",
        "            label='Malignant')\n",
        "ax2 = fig.add_subplot(grid[0, :])\n",
        "ax2.set_title('Age Distribution by Train/Test Observations')\n",
        "sns.kdeplot(train.age, label='Train', shade=True, ax=ax2, color='#1A1A1D')\n",
        "sns.kdeplot(test.age, label='Test', shade=True, ax=ax2, color='#C3073F')\n",
        "ax2.legend()\n",
        "ax3 = fig.add_subplot(grid[1, :])\n",
        "ax3.set_title('Age Distribution by Gender')\n",
        "sns.distplot(train[train.sex == 'female'].age,\n",
        "             ax=ax3,\n",
        "             label='Female',\n",
        "             color='#C3073F')\n",
        "sns.distplot(train[train.sex == 'male'].age,\n",
        "             ax=ax3,\n",
        "             label='Male',\n",
        "             color='#1A1A1D')\n",
        "ax3.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlaNIUVZSkc9"
      },
      "outputs": [],
      "source": [
        "sex_dummies = pd.get_dummies(train['sex'], prefix='sex')\n",
        "train = pd.concat([train, sex_dummies], axis=1)\n",
        "sex_dummies = pd.get_dummies(test['sex'], prefix='sex')\n",
        "test = pd.concat([test, sex_dummies], axis=1)\n",
        "train.drop(['sex'], axis=1, inplace=True)\n",
        "test.drop(['sex'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjI6qBS-Skc-"
      },
      "outputs": [],
      "source": [
        "anatom_dummies = pd.get_dummies(train['location'], prefix='anatom')\n",
        "train = pd.concat([train, anatom_dummies], axis=1)\n",
        "anatom_dummies = pd.get_dummies(test['location'], prefix='anatom')\n",
        "test = pd.concat([test, anatom_dummies], axis=1)\n",
        "train.drop('location', axis=1, inplace=True)\n",
        "test.drop(['location'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGKA4iT9Skc-"
      },
      "outputs": [],
      "source": [
        "for df in [train, test]:\n",
        "    df.drop('img_name', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezInl9iUdjZu"
      },
      "source": [
        "### Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "C7CSiXIbdjZu",
        "outputId": "fe3c2689-44e2-445b-9ed9-bd2fd581c09c"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>columns</th>\n      <th>percent_null</th>\n      <th>percent_zero</th>\n      <th>total_zero</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>image_name</th>\n      <td>image_name</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>patient_id</th>\n      <td>patient_id</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>sex</td>\n      <td>0.196220</td>\n      <td>0.000000</td>\n      <td>0.196220</td>\n    </tr>\n    <tr>\n      <th>age_approx</th>\n      <td>age_approx</td>\n      <td>0.205277</td>\n      <td>0.006038</td>\n      <td>0.211314</td>\n    </tr>\n    <tr>\n      <th>anatom_site_general_challenge</th>\n      <td>anatom_site_general_challenge</td>\n      <td>1.590895</td>\n      <td>0.000000</td>\n      <td>1.590895</td>\n    </tr>\n    <tr>\n      <th>diagnosis</th>\n      <td>diagnosis</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>benign_malignant</th>\n      <td>benign_malignant</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>target</th>\n      <td>target</td>\n      <td>0.000000</td>\n      <td>98.237034</td>\n      <td>98.237034</td>\n    </tr>\n    <tr>\n      <th>image_path</th>\n      <td>image_path</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                     columns  percent_null  \\\nimage_name                                        image_name      0.000000   \npatient_id                                        patient_id      0.000000   \nsex                                                      sex      0.196220   \nage_approx                                        age_approx      0.205277   \nanatom_site_general_challenge  anatom_site_general_challenge      1.590895   \ndiagnosis                                          diagnosis      0.000000   \nbenign_malignant                            benign_malignant      0.000000   \ntarget                                                target      0.000000   \nimage_path                                        image_path      0.000000   \n\n                               percent_zero  total_zero  \nimage_name                         0.000000    0.000000  \npatient_id                         0.000000    0.000000  \nsex                                0.000000    0.196220  \nage_approx                         0.006038    0.211314  \nanatom_site_general_challenge      0.000000    1.590895  \ndiagnosis                          0.000000    0.000000  \nbenign_malignant                   0.000000    0.000000  \ntarget                            98.237034   98.237034  \nimage_path                         0.000000    0.000000  "
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def check_for_missing_and_null(df):\n",
        "    null_df = pd.DataFrame({'columns': df.columns, \n",
        "                            'percent_null': df.isnull().sum() * 100 / len(df), \n",
        "                            'percent_zero': df.isin([0]).sum() * 100 / len(df),\n",
        "                            'total_zero': df.isnull().sum() * 100 / len(df) + df.isin([0]).sum() * 100 / len(df),\n",
        "                           })\n",
        "    return null_df\n",
        "check_for_missing_and_null(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuszpnbgdjZy"
      },
      "outputs": [],
      "source": [
        "train = train.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "UowDHn02djZy",
        "outputId": "fd60d213-4ecf-4df7-c646-2d7f91273f60"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 576x432 with 1 Axes>"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "x = plt.bar([\"Melanoma\",\"Benign\"],[len(train[train.target==1]), len(train[train.target==0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "bsBh6hYpdjZz",
        "outputId": "d5d968d4-554e-4c97-85af-b6e4bf631cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 15743 female patients in the dataset and 16788 male patients.\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFpCAYAAACBGWEUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAevElEQVR4nO3dcWzU52H4//flHK/MDQRIzkc1y0uYm0bdTPkjKlazW2J6OMY4OQionbRkcVqlUrpEHgVtbjUPPC9pO6uISFNrz6020q3KQoJRuHUYjiB7C022Lszzsi11F3dm4s4NGIJJjLF7vz9Q7yt+JmXYDobH75cUKX7u8+DnkfjozXN3Pkfy+XweSZIUjBvmegGSJGl2GXdJkgJj3CVJCoxxlyQpMMZdkqTAGHdJkgJj3CVJCoxxlyQpMMZdkqTAGHdJkgJj3CVJCoxxlyQpMMZdkqTAGHdJkgJj3CVJCoxxlyQpMMZdkqTAGHdJkgJj3CVJCoxxlyQpMMZdkqTAGHdJkgJTNNcLkKRLefjbrzI08t5cL0OaFWWLF7Drc5+8at/PuEu6Jg2NvMdbb5+d62VI1yWflpckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQrMZePe1NREVVUV69atu2j82Wefpaamhrq6Or7+9a8Xxtvb20kmk9TU1NDb21sY7+/vp76+nmQySWtrK/l8HoDx8XEaGxtJJpNs2rSJY8eOzdbeJEmaly4b9w0bNtDZ2XnR2A9+8AMymQwvvfQS6XSaz33ucwAMDAyQTqdJp9N0dnayfft2JicnAdi2bRstLS10d3czODhIT08PAM8//zwLFy7kwIEDPPLII7S1tc32HiVJmlcuG/e77rqLRYsWXTT2ve99j8cee4zi4mIAli5dCkAmk6Guro7i4mLKysooLy+nr6+P4eFhRkdHWblyJZFIhFQqRSaTAeDQoUOsX78egJqaGo4cOVI41UuSpCs3rdfcBwcH+ed//mc2bdrE7/zO79DX1wdALpcjHo8XristLSWXy00Zj8fj5HK5wpxly5YBUFRUxE033cTIyMi0NyRJ0nw3rV8cMzk5yTvvvMPf/u3f8m//9m80NjaSyWQueeKORCLvOw78wsckSdKVm9bJvbS0lGQySSQSobKykhtuuIGRkRHi8TjZbLZwXS6XIxaLTRnPZrPEYjHgwin++PHjAExMTHDmzBluvvnmmexJkqR5bVpx//SnP80PfvADAN566y3Onz/P4sWLqa6uJp1OMz4+ztDQEIODg1RWVhKLxSgpKeHo0aPk83m6urpYvXo1ANXV1ezZsweA/fv3s2rVKk/ukiTNwGWflt+8eTOvvfYaIyMjJBIJnnjiCR588EG+/OUvs27dOm688Ua++tWvEolEqKiooLa2lrVr1xKNRmlubiYajQIX3i3f1NTE2NgYiUSCRCIBwMaNG9m6dSvJZJJFixaxY8eOD3bHkiQFLpL3remSrkH3th3mrbfPzvUypFlx2y0lvLzlnqv2/ab1hrr54OFvv8rQyHtzvQxpxsoWL2DX5z4518uQdBUZ9/cxNPKepwZJ0nXJz5aXJCkwxl2SpMAYd0mSAmPcJUkKjHGXJCkwxl2SpMAYd0mSAmPcJUkKjHGXJCkwxl2SpMAYd0mSAmPcJUkKjHGXJCkwxl2SpMAYd0mSAmPcJUkKjHGXJCkwxl2SpMAYd0mSAmPcJUkKjHGXJCkwxl2SpMAYd0mSAmPcJUkKjHGXJCkwxl2SpMBcNu5NTU1UVVWxbt26KY99+9vf5o477uDkyZOFsfb2dpLJJDU1NfT29hbG+/v7qa+vJ5lM0traSj6fB2B8fJzGxkaSySSbNm3i2LFjs7EvSZLmrcvGfcOGDXR2dk4ZP378OK+88gof+chHCmMDAwOk02nS6TSdnZ1s376dyclJALZt20ZLSwvd3d0MDg7S09MDwPPPP8/ChQs5cOAAjzzyCG1tbbO1N0mS5qXLxv2uu+5i0aJFU8affvpptm7dSiQSKYxlMhnq6uooLi6mrKyM8vJy+vr6GB4eZnR0lJUrVxKJREilUmQyGQAOHTrE+vXrAaipqeHIkSOFU70kSbpy03rNPZPJEIvF+NjHPnbReC6XIx6PF74uLS0ll8tNGY/H4+RyucKcZcuWAVBUVMRNN93EyMjIdJYlSZKAoiud8N577/Gtb32L73znO1Meu9SJOxKJvO/4L5ojSZKm54pP7v/zP//DsWPHeOCBB6iuriabzbJhwwZ++tOfEo/HyWazhWtzuRyxWGzKeDabJRaLARdO8cePHwdgYmKCM2fOcPPNN890X5IkzVtXHPc77riDI0eOcOjQIQ4dOkQ8HufFF1/k1ltvpbq6mnQ6zfj4OENDQwwODlJZWUksFqOkpISjR4+Sz+fp6upi9erVAFRXV7Nnzx4A9u/fz6pVqzy5S5I0A5d9Wn7z5s289tprjIyMkEgkeOKJJ9i0adMlr62oqKC2tpa1a9cSjUZpbm4mGo0CF94t39TUxNjYGIlEgkQiAcDGjRvZunUryWSSRYsWsWPHjlncniRJ808k71vTL+netsO89fbZuV6GNGO33VLCy1vumetlXDHvQYXkat+HfkKdJEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYC4b96amJqqqqli3bl1h7Gtf+xr33Xcf9fX1fPGLX+Sdd94pPNbe3k4ymaSmpobe3t7CeH9/P/X19SSTSVpbW8nn8wCMj4/T2NhIMplk06ZNHDt2bDb3J0nSvHPZuG/YsIHOzs6Lxj71qU+xb98+XnrpJX71V3+V9vZ2AAYGBkin06TTaTo7O9m+fTuTk5MAbNu2jZaWFrq7uxkcHKSnpweA559/noULF3LgwAEeeeQR2traZnuPkiTNK5eN+1133cWiRYsuGrv77rspKioC4BOf+ATZbBaATCZDXV0dxcXFlJWVUV5eTl9fH8PDw4yOjrJy5UoikQipVIpMJgPAoUOHWL9+PQA1NTUcOXKkcKqXJElXbsavub/wwgskEgkAcrkc8Xi88FhpaSm5XG7KeDweJ5fLFeYsW7YMgKKiIm666SZGRkZmuixJkuatGcX9m9/8JtFolPvvvx/gkifuSCTyvuO/aI4kSZqeacd9z549HD58mLa2tkKM4/F44Sl6uHAqj8ViU8az2SyxWKww5/jx4wBMTExw5swZbr755ukuS5KkeW9ace/p6eEv/uIv+OY3v8mCBQsK49XV1aTTacbHxxkaGmJwcJDKykpisRglJSUcPXqUfD5PV1cXq1evLszZs2cPAPv372fVqlWe3CVJmoGiy12wefNmXnvtNUZGRkgkEjzxxBN0dHQwPj5OQ0MDACtWrKClpYWKigpqa2tZu3Yt0WiU5uZmotEocOHd8k1NTYyNjZFIJAqv02/cuJGtW7eSTCZZtGgRO3bs+AC3K0lS+CJ535p+Sfe2Heatt8/O9TKkGbvtlhJe3nLPXC/jinkPKiRX+z70E+okSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICc9m4NzU1UVVVxbp16wpjp06doqGhgTVr1tDQ0MDp06cLj7W3t5NMJqmpqaG3t7cw3t/fT319PclkktbWVvL5PADj4+M0NjaSTCbZtGkTx44dm839SZI071w27hs2bKCzs/OisY6ODqqqquju7qaqqoqOjg4ABgYGSKfTpNNpOjs72b59O5OTkwBs27aNlpYWuru7GRwcpKenB4Dnn3+ehQsXcuDAAR555BHa2tpme4+SJM0rl437XXfdxaJFiy4ay2QypFIpAFKpFAcPHiyM19XVUVxcTFlZGeXl5fT19TE8PMzo6CgrV64kEomQSqXIZDIAHDp0iPXr1wNQU1PDkSNHCqd6SZJ05ab1mvuJEyeIxWIAxGIxTp48CUAulyMejxeuKy0tJZfLTRmPx+PkcrnCnGXLlgFQVFTETTfdxMjIyPR2I0mSZvcNdZc6cUcikfcd/0VzJEnS9Ewr7kuXLmV4eBiA4eFhlixZAlw4kWez2cJ1uVyOWCw2ZTybzRZO/vF4nOPHjwMwMTHBmTNnuPnmm6e3G0mSNL24V1dX09XVBUBXVxerV68ujKfTacbHxxkaGmJwcJDKykpisRglJSUcPXqUfD4/Zc6ePXsA2L9/P6tWrfLkLknSDBRd7oLNmzfz2muvMTIyQiKR4IknnuCxxx6jsbGR3bt3s2zZMnbu3AlARUUFtbW1rF27lmg0SnNzM9FoFLjwbvmmpibGxsZIJBIkEgkANm7cyNatW0kmkyxatIgdO3Z8gNuVJCl8kbxvTb+ke9sO89bbZ+d6GdKM3XZLCS9vuWeul3HFvAcVkqt9H/oJdZIkBca4S5IUGOMuSVJgjLskSYEx7pIkBca4S5IUGOMuSVJgjLskSYEx7pIkBca4S5IUGOMuSVJgjLskSYEx7pIkBca4S5IUGOMuSVJgjLskSYEx7pIkBca4S5IUGOMuSVJgjLskSYEx7pIkBca4S5IUGOMuSVJgjLskSYEx7pIkBca4S5IUGOMuSVJgjLskSYGZUdz/8i//krq6OtatW8fmzZs5d+4cp06doqGhgTVr1tDQ0MDp06cL17e3t5NMJqmpqaG3t7cw3t/fT319PclkktbWVvL5/EyWJUnSvDbtuOdyOXbt2sULL7zAvn37mJycJJ1O09HRQVVVFd3d3VRVVdHR0QHAwMAA6XSadDpNZ2cn27dvZ3JyEoBt27bR0tJCd3c3g4OD9PT0zM7uJEmah2Z0cp+cnGRsbIyJiQnGxsaIxWJkMhlSqRQAqVSKgwcPApDJZKirq6O4uJiysjLKy8vp6+tjeHiY0dFRVq5cSSQSIZVKkclkZr4zSZLmqaLpTiwtLeXRRx/l3nvv5Zd+6Zf41Kc+xd13382JEyeIxWIAxGIxTp48CVw46a9YseKi+blcjqKiIuLxeGE8Ho+Ty+WmuyxJkua9aZ/cT58+TSaTIZPJ0Nvby3vvvcfevXvf9/pLvY4eiUTed1ySJE3PtOP+yiuv8Cu/8issWbKEG2+8kTVr1vD666+zdOlShoeHARgeHmbJkiXAhRN5NpstzM/lcsRisSnj2Wy2cPKXJElXbtpx/8hHPsK//uu/8t5775HP5zly5AjLly+nurqarq4uALq6uli9ejUA1dXVpNNpxsfHGRoaYnBwkMrKSmKxGCUlJRw9epR8Pn/RHEmSdOWm/Zr7ihUrqKmpYf369RQVFXHnnXfymc98hrNnz9LY2Mju3btZtmwZO3fuBKCiooLa2lrWrl1LNBqlubmZaDQKXHi3fFNTE2NjYyQSCRKJxOzsTpKkeSiS94fKL+netsO89fbZuV6GNGO33VLCy1vumetlXDHvQYXkat+HfkKdJEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYGYU93feeYcnn3yS++67j9raWl5//XVOnTpFQ0MDa9asoaGhgdOnTxeub29vJ5lMUlNTQ29vb2G8v7+f+vp6kskkra2t5PP5mSxLkqR5bUZx/9M//VN+8zd/k7//+79n7969LF++nI6ODqqqquju7qaqqoqOjg4ABgYGSKfTpNNpOjs72b59O5OTkwBs27aNlpYWuru7GRwcpKenZ+Y7kyRpnpp23EdHR/mnf/onNm7cCEBxcTELFy4kk8mQSqUASKVSHDx4EIBMJkNdXR3FxcWUlZVRXl5OX18fw8PDjI6OsnLlSiKRCKlUikwmMwtbkyRpfiqa7sShoSGWLFlCU1MT//mf/8nHP/5xvvKVr3DixAlisRgAsViMkydPApDL5VixYkVhfmlpKblcjqKiIuLxeGE8Ho+Ty+WmuyxJkua9aZ/cJyYmeOONN/jt3/5turq6WLBgQeEp+Eu51OvokUjkfcclSdL0TDvu8XiceDxeOI3fd999vPHGGyxdupTh4WEAhoeHWbJkSeH6bDZbmJ/L5YjFYlPGs9ls4eQvSZKu3LTjfuuttxKPx/nv//5vAI4cOcLy5cuprq6mq6sLgK6uLlavXg1AdXU16XSa8fFxhoaGGBwcpLKyklgsRklJCUePHiWfz180R5IkXblpv+YO8Ed/9Eds2bKF8+fPU1ZWxtNPP83PfvYzGhsb2b17N8uWLWPnzp0AVFRUUFtby9q1a4lGozQ3NxONRoEL75ZvampibGyMRCJBIpGY+c4kSZqnInl/qPyS7m07zFtvn53rZUgzdtstJby85Z65XsYV8x5USK72fegn1EmSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAVmxnGfnJwklUrxhS98AYBTp07R0NDAmjVraGho4PTp04Vr29vbSSaT1NTU0NvbWxjv7++nvr6eZDJJa2sr+Xx+psuSJGnemnHcd+3axfLlywtfd3R0UFVVRXd3N1VVVXR0dAAwMDBAOp0mnU7T2dnJ9u3bmZycBGDbtm20tLTQ3d3N4OAgPT09M12WJEnz1ozins1mOXz4MBs3biyMZTIZUqkUAKlUioMHDxbG6+rqKC4upqysjPLycvr6+hgeHmZ0dJSVK1cSiURIpVJkMpmZLEuSpHltRnF/6qmn2Lp1Kzfc8P/+mBMnThCLxQCIxWKcPHkSgFwuRzweL1xXWlpKLpebMh6Px8nlcjNZliRJ89q04/7yyy+zZMkSfv3Xf/3/dP2lXkePRCLvOy5JkqanaLoT/+Vf/oVDhw7R09PDuXPnGB0dZcuWLSxdupTh4WFisRjDw8MsWbIEuHAiz2azhfm5XI5YLDZlPJvNFk7+kiTpyk375P6lL32Jnp4eDh06xDe+8Q1WrVpFW1sb1dXVdHV1AdDV1cXq1asBqK6uJp1OMz4+ztDQEIODg1RWVhKLxSgpKeHo0aPk8/mL5kiSpCs37ZP7+3nsscdobGxk9+7dLFu2jJ07dwJQUVFBbW0ta9euJRqN0tzcTDQaBS68W76pqYmxsTESiQSJRGK2lyVJ0rwRyftD5Zd0b9th3nr77FwvQ5qx224p4eUt98z1Mq6Y96BCcrXvQz+hTpKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDTjvvx48d56KGHqK2tpa6ujr/6q78C4NSpUzQ0NLBmzRoaGho4ffp0YU57ezvJZJKamhp6e3sL4/39/dTX15NMJmltbSWfz89gS5IkzW/Tjns0GuUP//AP+f73v89zzz3H3/zN3zAwMEBHRwdVVVV0d3dTVVVFR0cHAAMDA6TTadLpNJ2dnWzfvp3JyUkAtm3bRktLC93d3QwODtLT0zM7u5MkaR6adtxjsRgf//jHAfjwhz/M7bffTi6XI5PJkEqlAEilUhw8eBCATCZDXV0dxcXFlJWVUV5eTl9fH8PDw4yOjrJy5UoikQipVIpMJjMLW5MkaX6aldfcjx07xn/8x3+wYsUKTpw4QSwWAy78A+DkyZMA5HI54vF4YU5paSm5XG7KeDweJ5fLzcayJEmal2Yc97Nnz/Lkk0/y5S9/mQ9/+MPve92lXkePRCLvOy5JkqZnRnE/f/48Tz75JPX19axZswaApUuXMjw8DMDw8DBLliwBLpzIs9lsYW4ulyMWi00Zz2azhZO/JEm6ctOOez6f5ytf+Qq33347DQ0NhfHq6mq6uroA6OrqYvXq1YXxdDrN+Pg4Q0NDDA4OUllZSSwWo6SkhKNHj5LP5y+aI0mSrlzRdCf+8Ic/ZO/evXz0ox/lgQceAGDz5s089thjNDY2snv3bpYtW8bOnTsBqKiooLa2lrVr1xKNRmlubiYajQIX3i3f1NTE2NgYiUSCRCIxC1uTJGl+iuT9ofJLurftMG+9fXaulyHN2G23lPDylnvmehlXzHtQIbna96GfUCdJUmCMuyRJgTHukiQFxrhLkhQY4y5JUmCMuyRJgTHukiQFxrhLkhQY4y5JUmCMuyRJgTHukiQFxrhLkhQY4y5JUmCMuyRJgTHukiQFxrhLkhQY4y5JUmCMuyRJgTHukiQFxrhLkhQY4y5JUmCMuyRJgTHukiQFxrhLkhQY4y5JUmCMuyRJgTHukiQFxrhLkhSYaybuPT091NTUkEwm6ejomOvlSJJ03bom4j45OUlLSwudnZ2k02n27dvHwMDAXC9LkqTr0jUR976+PsrLyykrK6O4uJi6ujoymcxcL0uSpOtS0VwvACCXyxGPxwtfl5aW0tfXN4crgrLFC+b0+0uz5Xr9u3y9rlu6lKv99/maiHs+n58yFolE5mAl/8+uz31yTr+/NN95D0rTd008LR+Px8lms4Wvc7kcsVhsDlckSdL165qI+2/8xm8wODjI0NAQ4+PjpNNpqqur53pZkiRdl66Jp+WLiopobm7m85//PJOTkzz44INUVFTM9bIkSbouRfKXesFbkiRdt66Jp+UlSdLsMe6SJAXGuEuSFBjjLklSYIy7JEmBMe6SJAXGuGva7rzzTh544IHCf8eOHfvAvld1dTUnT578wP58KTR33HEHW7duLXw9MTHBqlWr+MIXvvAL57366quXvUbXvmviQ2x0ffrQhz7E3r1753oZki7hl3/5l/nRj37E2NgYH/rQh/jHf/xHSktL53pZukqMu2ZVf38/X/3qV3n33XdZvHgxTz/9NLFYjIceeog777yTf//3f+fkyZN87Wtfo6OjgzfffJPa2lp+//d/H4DHH3+cbDbLuXPnePjhh/nMZz4z5Xvs3buXZ599lvPnz7NixQr++I//mGg0erW3Kl3zEokEhw8f5r777iOdTlNXV8cPf/hD4MKv2n7qqacK8X/qqae4/fbbL5r/7rvv8id/8ie8+eabTE5O8nu/93t8+tOfnout6Ar5tLymbWxsrPCU/Be/+EXOnz9Pa2srzzzzDC+++CIPPvggO3bsKFx/44038td//dd89rOf5fHHH6e5uZl9+/axZ88eRkZGAHjqqad48cUXeeGFF3j22WcL4z/34x//mO9///t873vfY+/evdxwww289NJLV3Xf0vVi7dq1/N3f/R3nzp3jv/7rv1ixYkXhsdtvv53vfve7dHV18eSTT150r/7ct771LVatWsULL7zArl27+LM/+zPefffdq7kFTZMnd03b//9p+TfffJM333yThoYGAH72s59x6623Fh7/+S8D+uhHP0pFRUXhN/+VlZWRzWZZvHgxzz77LAcOHADg+PHj/OQnP2Hx4sWFP+PIkSP09/ezceNG4MI/MJYuXfrBblS6Tn3sYx/j2LFj7Nu3j9/6rd+66LEzZ87wB3/wB/zkJz8hEolw/vz5KfP/4R/+gUOHDvGd73wHgHPnznH8+HGWL19+Vdav6TPumjX5fJ6Kigqee+65Sz5eXFwMwA033FD4/59/PTExwauvvsorr7zCc889x4IFC3jooYc4d+7clO+xfv16vvSlL31wG5ECUl1dzde//nV27drFqVOnCuM7d+7kk5/8JH/+53/OsWPHePjhhy85/5lnnpnydL2ufT4tr1lz2223cfLkSV5//XUAzp8/z49+9KP/8/wzZ86waNEiFixYwI9//GOOHj065Zqqqir279/PiRMnADh16hT/+7//OzsbkAK0ceNGHn/8ce64446Lxs+cOVN4g92ePXsuOffuu+/mu9/9Lj///WJvvPHGB7tYzRrjrllTXFzMM888Q1tbG/fffz+pVKoQ+v+LRCLBxMQE9fX17Ny5k0984hNTrvm1X/s1GhsbefTRR6mvr+fRRx/lpz/96WxuQwpKPB7nd3/3d6eMf/7zn+cb3/gGn/3sZ5mcnLzk3Mcff5yJiQnuv/9+1q1bx86dOz/o5WqW+CtfJUkKjCd3SZICY9wlSQqMcZckKTDGXZKkwBh3SZICY9wlSQqMcZckKTDGXZKkwPx/6bFaotZqS3AAAAAASUVORK5CYII=\n",
            "text/plain": "<Figure size 576x432 with 1 Axes>"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "female = train[train.sex == \"female\"]\n",
        "male = train[train.sex == \"male\"]\n",
        "plt.figure(figsize = (8,6))\n",
        "x = plt.bar(\n",
        "    [\"Female\",\"Male\"],\n",
        "    [len(female), len(male)]\n",
        ")\n",
        "print('There are', len(female), 'female patients in the dataset and', len(male), 'male patients.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "A-pyTo-R0_fz",
        "outputId": "7b8e46e2-b651-4235-af94-e0be8e2e9b13"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 576x432 with 1 Axes>"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "x = plt.bar(\n",
        "    [\"Benign & Female\",\"Malignant & Female\", \"Benign & Male\",\"Malignant & Male\"],\n",
        "    [len(benign_cases_female), len(malignant_cases_female), len(benign_cases_male), len(malignant_cases_male)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXy7Imvud29o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VByh6gsM9x2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUDKyAo0YGu4"
      },
      "source": [
        "#Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiyiiIneWM8-",
        "outputId": "107f1d78-1465-4b99-e939-97223648f9fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid rows in train 33126\n",
            "valid rows in test 10982\n",
            "rows in train 33126\n",
            "rows in test 10982\n",
            "Samples in train 0.5\n",
            "Remaining rows in train set 1168\n",
            "Max number of images from one patient in the train set: 8\n",
            "Max number of images from one patient in the test set: 240\n",
            "There are 787 unique patients in the training set\n",
            "There are 690 unique patients in the test set\n",
            "There are 0 patients in both the training and test sets\n",
            "Found 1168 non-validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from datetime import datetime, date\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "import keras\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input,ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "#from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, MaxPool2D, Conv2D\n",
        "from pandas_profiling import ProfileReport\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, confusion_matrix\n",
        "\n",
        "#random.seed(1)\n",
        "np.random.seed(1)\n",
        "os.environ['PYTHONHASHSEED'] = str(1)\n",
        "os.environ['TF_KERAS'] = str(1)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = str(1)\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = str(1)\n",
        "tf.random.set_seed(69)\n",
        "tf.experimental.numpy.random.seed(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_train_data():\n",
        "    # read the data from the train.csv file\n",
        "    train = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
        "    # add the image_path to the train set\n",
        "    train['image_path'] = train['image_name'].apply(lambda x: PATH_TO_IMAGES + \"/train/\" + x + IMAGE_TYPE)\n",
        "    # check if the we have an image \n",
        "    train['image_path'] = train.apply(lambda row : check_image(row['image_path']), axis = 1)\n",
        "    # if we do not have an image we will not include the data\n",
        "    train = train[train['image_path'] != False]\n",
        "    print(\"valid rows in train\", train.shape[0])\n",
        "    return train\n",
        "def get_test_data():\n",
        "    test = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\n",
        "    test['image_path'] = test['image_name'].apply(lambda x: PATH_TO_IMAGES + \"/test/\" + x + IMAGE_TYPE)\n",
        "    test['image_path'] = test.apply(lambda row : check_image(row['image_path']), axis = 1)\n",
        "    test = test[test['image_path'] != False]\n",
        "    print(\"valid rows in test\", test.shape[0])\n",
        "    return test\n",
        "def check_image(file_path):\n",
        "    img_file = Path(file_path)\n",
        "    if img_file.is_file():\n",
        "        return file_path\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Create a train and a validation dataset\n",
        "def create_splits(df, test_size, classToPredict):\n",
        "    train_data, val_data = train_test_split(df,  test_size = test_size, random_state = 1, stratify = df[classToPredict])\n",
        "    return train_data, val_data\n",
        "\n",
        "#plot the history of a tensorflow model\n",
        "def save_history(history, timestamp,Model_Name):\n",
        "    f = plt.figure()\n",
        "    f.set_figwidth(15)\n",
        "\n",
        "    f.add_subplot(1, 2, 1)\n",
        "    plt.plot(history['val_loss'], label='val loss')\n",
        "    plt.plot(history['loss'], label='train loss')\n",
        "    plt.legend()\n",
        "    plt.title(\"Model Loss\")\n",
        "\n",
        "    f.add_subplot(1, 2, 2)\n",
        "    plt.plot(history['val_accuracy'], label='val accuracy')\n",
        "    plt.plot(history['accuracy'], label='train accuracy')\n",
        "    plt.legend()\n",
        "    plt.title(\"Model Accuracy\")\n",
        "    if SAVE_OUTPUT:\n",
        "        plt.savefig(CascadeLearning+'/'+Model_Name+' '+ timestamp + \"-history.png\")\n",
        "        with open(CascadeLearning+'/' +Model_Name+' '+ timestamp + \"-history.json\", 'w') as f:\n",
        "            json.dump(history, f)\n",
        "\n",
        "#plot the auc curve\n",
        "def plot_auc(t_y, p_y):\n",
        "    fpr, tpr, thresholds = roc_curve(t_y, p_y, pos_label=1)\n",
        "    fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n",
        "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % ('Target', auc(fpr, tpr)))\n",
        "    c_ax.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "    c_ax.legend()\n",
        "    c_ax.set_xlabel('False Positive Rate')\n",
        "    c_ax.set_ylabel('True Positive Rate')\n",
        "    #plt.savefig('ResNet50 1st layer Model_100epochs Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "#Data augmentation\n",
        "#function to create a training image data generator\n",
        "def get_training_gen(df):\n",
        "    ## prepare images for training\n",
        "    train_idg = ImageDataGenerator(\n",
        "        rescale = 1 / 255.0,\n",
        "        horizontal_flip = True, \n",
        "        vertical_flip = True, \n",
        "        height_shift_range = 0.15, \n",
        "        width_shift_range = 0.15,\n",
        "        shear_range=0.15,\n",
        "        rotation_range = 90, \n",
        "        zoom_range = 0.20,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    train_gen = train_idg.flow_from_dataframe(\n",
        "        dataframe=df,\n",
        "        directory=None,\n",
        "        x_col='image_path',\n",
        "        y_col=['target_0','target_1'],\n",
        "        class_mode='raw',\n",
        "        shuffle=True,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validate_filenames = False\n",
        "    )\n",
        "\n",
        "    return train_gen\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "#function to create a validation image data generator\n",
        "def get_validation_gen(df):\n",
        "    ## prepare images for validation\n",
        "    val_idg = ImageDataGenerator(rescale=1. / 255.0)\n",
        "    val_gen = val_idg.flow_from_dataframe(\n",
        "        dataframe=df,\n",
        "        directory=None,\n",
        "        x_col='image_path',\n",
        "        y_col=['target_0','target_1'],\n",
        "        class_mode='raw',\n",
        "        shuffle=False,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validate_filenames = False\n",
        "    )\n",
        "\n",
        "    return val_gen\n",
        "##############################################################################################################################\n",
        "\n",
        "def load_pretrained_model_VGG():\n",
        "    base_model = VGG16(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    #base_model = tf.keras.Sequential(base_model.layers[:10])\n",
        "    # freeze the first 15 layers of the base model. All other layers are trainable.\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    for idx, layer in enumerate(base_model.layers[:]):\n",
        "        print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "    #model = base_model.layers[-165]    \n",
        "\n",
        "    return base_model\n",
        "\n",
        "def create_model_VGG():\n",
        "    print(\"create model\")\n",
        "    model = Sequential()\n",
        "    model.add(load_pretrained_model_VGG())  \n",
        "    model.add(layers.Flatten())\n",
        "#    model.add(layers.Dense(128, activation='relu'))\n",
        "#    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "def load_pretrained_model_MobileNet():\n",
        "    base_model = MobileNet(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    #base_model = tf.keras.Sequential(base_model.layers[:10])\n",
        "    # freeze the first 15 layers of the base model. All other layers are trainable.\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    for idx, layer in enumerate(base_model.layers[:10]):\n",
        "        print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "    #model = base_model.layers[-165]    \n",
        "\n",
        "    return base_model\n",
        "\n",
        "def create_model_MobileNet():\n",
        "    print(\"create model\")\n",
        "    model = Sequential()\n",
        "    model.add(load_pretrained_model_MobileNet())  \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "################################################################################################################################\n",
        "def load_pretrained_model_E2E():\n",
        "    base_model = ResNet50(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    #base_model = tf.keras.Sequential(base_model.layers[:10])\n",
        "    # freeze the first 15 layers of the base model. All other layers are trainable.\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    for idx, layer in enumerate(base_model.layers[:10]):\n",
        "        print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "    #model = base_model.layers[-165]    \n",
        "\n",
        "    return base_model\n",
        "def create_model_E2E():\n",
        "    print(\"create model\")\n",
        "    # Create a new sequentail model and add the pretrained model\n",
        "    model = Sequential()\n",
        "    # Add the pretrained model\n",
        "    model.add(load_pretrained_model_E2E())  \n",
        "    # Add a flatten layer to prepare the ouput of the cnn layer for the next layers\n",
        "    model.add(layers.Flatten())\n",
        "    # Add a dense (aka. fully-connected) layer. \n",
        "    # Add a dropout-layer which may prevent overfitting and improve generalization ability to unseen data.\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(32, activation='relu'))\n",
        "    # Use the Sigmoid activation function for binary predictions, softmax for n-classes\n",
        "    # We use the softmax function, because we have two classes (target_0 & target_1)\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "##################################################################################################################################\n",
        "def load_pretrained_model_ResNet():\n",
        "    base_model = ResNet50(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    #base_model = tf.keras.Sequential(base_model.layers[:10])\n",
        "    # freeze the first 15 layers of the base model. All other layers are trainable.\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    for idx, layer in enumerate(base_model.layers[:10]):\n",
        "        print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "\n",
        "    return base_model\n",
        "\n",
        "def create_model_ResNet():\n",
        "    print(\"create model\")\n",
        "    model = Sequential()\n",
        "    model.add(ResNet50)  \n",
        "    model.add(layers.Flatten())\n",
        "#    model.add(layers.Dense(512, activation='relu'))\n",
        "#    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "#################################################################################################################################\n",
        "\n",
        "def load_pretrained_model():\n",
        "    base_model = ResNet50(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    #base_model = tf.keras.Sequential(base_model.layers[:10])\n",
        "    # freeze the first 15 layers of the base model. All other layers are trainable.\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    for idx, layer in enumerate(base_model.layers[:10]):\n",
        "        print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "    #model = base_model.layers[-165]    \n",
        "\n",
        "    return base_model\n",
        "def create_model_Pretrained():\n",
        "    print(\"create model\")\n",
        "    model = Sequential()\n",
        "    model.add(load_pretrained_model())  \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "def create_model(load_pretrained_model):\n",
        "    print(\"create model\")\n",
        "    model = Sequential()\n",
        "    model.add(load_pretrained_model)  \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "def calc_f1(prec, recall):\n",
        "    return 2*(prec*recall)/(prec+recall) if recall and prec else 0\n",
        "def plot_confusion_matrix(cm, labels):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=55)\n",
        "    plt.yticks(tick_marks, labels)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig('Confusion_Matrix ResNet_100epochs 1st layer Model_40epochs',format='pdf')\n",
        "\n",
        "def pred_to_binary(pred):\n",
        "    if pred < threshold:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "########################################################################################################################################################################\n",
        "\n",
        "CascadeLearning='Cascade all Model Layers Graph'\n",
        "BASE_PATH = 'siim-isic-melanoma-classification'\n",
        "PATH_TO_IMAGES = 'siim-isic-melanoma-classification/jpeg' \n",
        "IMAGE_TYPE = \".jpg\"\n",
        "GOOGLE_COLAB = False\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 2\n",
        "VERBOSE_LEVEL = 2\n",
        "SAVE_OUTPUT = True\n",
        "IMG_SIZE = (224, 224)\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "Epochs_ResNet=150\n",
        "CWD = os.getcwd()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Data preparation\n",
        "#Because we removed some values from the dataset for the EDA, we load the train and test set again.\n",
        "train = get_train_data()\n",
        "test = get_test_data()\n",
        "\n",
        "# getting dummy variables for gender\n",
        "sex_dummies = pd.get_dummies(train['sex'], prefix='sex', dtype=\"int\")\n",
        "train = pd.concat([train, sex_dummies], axis=1)\n",
        "\n",
        "sex_dummies = pd.get_dummies(test['sex'], prefix='sex', dtype=\"int\")\n",
        "test = pd.concat([test, sex_dummies], axis=1)\n",
        "\n",
        "# getting dummy variables for anatom_site_general_challenge\n",
        "anatom_dummies = pd.get_dummies(train['anatom_site_general_challenge'], prefix='anatom', dtype=\"int\")\n",
        "train = pd.concat([train, anatom_dummies], axis=1)\n",
        "\n",
        "anatom_dummies = pd.get_dummies(test['anatom_site_general_challenge'], prefix='anatom', dtype=\"int\")\n",
        "test = pd.concat([test, anatom_dummies], axis=1)\n",
        "\n",
        "# getting dummy variables for target column\n",
        "target_dummies = pd.get_dummies(train['target'], prefix='target', dtype=\"int\")\n",
        "train = pd.concat([train, target_dummies], axis=1)\n",
        "\n",
        "# dropping not useful columns\n",
        "train.drop(['sex','diagnosis','benign_malignant','anatom_site_general_challenge'], axis=1, inplace=True)\n",
        "test.drop(['sex','anatom_site_general_challenge'], axis=1, inplace=True)\n",
        "\n",
        "# replace missing age values wiht the mean age\n",
        "train['age_approx'] = train['age_approx'].fillna(int(np.mean(train['age_approx'])))\n",
        "test['age_approx'] = test['age_approx'].fillna(int(np.mean(test['age_approx'])))\n",
        "\n",
        "# convert age to int\n",
        "train['age_approx'] = train['age_approx'].astype('int')\n",
        "test['age_approx'] = test['age_approx'].astype('int')\n",
        "\n",
        "print(\"rows in train\", train.shape[0])\n",
        "print(\"rows in test\", test.shape[0])\n",
        "\n",
        "#Balance the dataset\n",
        "#Because we have a highly imbalanced dataset we need to balance it.\n",
        "\n",
        "# 1 means 50 / 50 => equal amount of positive and negative cases in Training\n",
        "# 4 = 20%; 8 = ~11%; 12 = ~8%\n",
        "balance = 1\n",
        "p_inds = train[train.target == 1].index.tolist()\n",
        "np_inds = train[train.target == 0].index.tolist()\n",
        "\n",
        "np_sample = random.sample(np_inds, balance * len(p_inds))\n",
        "train = train.loc[p_inds + np_sample]\n",
        "print(\"Samples in train\", train['target'].sum()/len(train))\n",
        "print(\"Remaining rows in train set\", len(train))\n",
        "\n",
        "\n",
        "#Patient Overlap\n",
        "#Important to note is that there are patients with multiple images taken in both train and test datasets. We, therefore, need to check that the same patient images do not appear in the training and test set.\n",
        "print(\"Max number of images from one patient in the train set:\", np.max(train.patient_id.value_counts()))\n",
        "print(\"Max number of images from one patient in the test set:\", np.max(test.patient_id.value_counts()))\n",
        "\n",
        "# get the unique patient ids from the test and training set\n",
        "ids_train = set(train.patient_id.values)\n",
        "ids_test = set(test.patient_id.values)\n",
        "\n",
        "print(\"There are\", len(ids_train), \"unique patients in the training set\")\n",
        "print(\"There are\", len(ids_test), \"unique patients in the test set\")\n",
        "\n",
        "# Identify patient overlap by looking at the intersection between the sets\n",
        "patient_overlap = list(ids_train.intersection(ids_test))\n",
        "n_overlap = len(patient_overlap)\n",
        "print(\"There are\", n_overlap, \"patients in both the training and test sets\")\n",
        "\n",
        "#Images returned from the ImageDataGenerator\n",
        "train_gen = get_training_gen(train)\n",
        "t_x, t_y = next(train_gen)\n",
        "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
        "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
        "    c_ax.imshow(c_x, cmap = 'bone')\n",
        "    if c_y[0] == 1: \n",
        "        c_ax.set_title('MALIGNANT')\n",
        "    else:\n",
        "        c_ax.set_title('BENIGN')\n",
        "    c_ax.axis('off')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D_8NknvZbFf"
      },
      "source": [
        "#Training the E2E Model and 1-8 layer on Pretrained Model(150 Epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5YXk_b8QFntV",
        "outputId": "289478c2-ae15-4689-e41c-8e1961df2aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "layer 1 : input_2 is trainable: True\n",
            "layer 2 : conv1_pad is trainable: True\n",
            "layer 3 : conv1_conv is trainable: True\n",
            "layer 4 : conv1_bn is trainable: True\n",
            "layer 5 : conv1_relu is trainable: True\n",
            "layer 6 : pool1_pad is trainable: True\n",
            "layer 7 : pool1_pool is trainable: True\n",
            "layer 8 : conv2_block1_1_conv is trainable: True\n",
            "layer 9 : conv2_block1_1_bn is trainable: True\n",
            "layer 10 : conv2_block1_1_relu is trainable: True\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.72750, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 502s - loss: 0.8393 - accuracy: 0.5011 - auc: 0.5122 - val_loss: 0.7275 - val_accuracy: 0.5625 - val_auc: 0.6462 - 502s/epoch - 33s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss improved from 0.72750 to 0.72677, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 153s - loss: 0.8427 - accuracy: 0.4979 - auc: 0.5114 - val_loss: 0.7268 - val_accuracy: 0.5625 - val_auc: 0.5723 - 153s/epoch - 10s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.72677\n",
            "15/15 - 150s - loss: 0.8455 - accuracy: 0.5054 - auc: 0.5106 - val_loss: 0.7307 - val_accuracy: 0.5625 - val_auc: 0.5830 - 150s/epoch - 10s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.72677\n",
            "15/15 - 146s - loss: 0.8409 - accuracy: 0.4968 - auc: 0.5151 - val_loss: 0.7332 - val_accuracy: 0.5625 - val_auc: 0.5743 - 146s/epoch - 10s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.72677\n",
            "15/15 - 146s - loss: 0.8438 - accuracy: 0.4989 - auc: 0.5096 - val_loss: 0.7357 - val_accuracy: 0.5625 - val_auc: 0.5713 - 146s/epoch - 10s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.72677\n",
            "15/15 - 144s - loss: 0.8001 - accuracy: 0.5171 - auc: 0.5443 - val_loss: 0.7470 - val_accuracy: 0.5625 - val_auc: 0.6392 - 144s/epoch - 10s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.72677\n",
            "15/15 - 146s - loss: 0.8048 - accuracy: 0.5343 - auc: 0.5609 - val_loss: 0.7380 - val_accuracy: 0.5625 - val_auc: 0.5808 - 146s/epoch - 10s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.72677\n",
            "15/15 - 145s - loss: 0.8036 - accuracy: 0.5075 - auc: 0.5452 - val_loss: 0.7367 - val_accuracy: 0.5625 - val_auc: 0.5479 - 145s/epoch - 10s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.72677\n",
            "15/15 - 145s - loss: 0.8159 - accuracy: 0.4957 - auc: 0.5185 - val_loss: 0.7287 - val_accuracy: 0.5625 - val_auc: 0.5632 - 145s/epoch - 10s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss improved from 0.72677 to 0.72277, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 146s - loss: 0.7891 - accuracy: 0.5203 - auc: 0.5531 - val_loss: 0.7228 - val_accuracy: 0.5625 - val_auc: 0.5977 - 146s/epoch - 10s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.72277\n",
            "15/15 - 141s - loss: 0.7923 - accuracy: 0.5364 - auc: 0.5777 - val_loss: 0.7275 - val_accuracy: 0.5781 - val_auc: 0.5674 - 141s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.72277\n",
            "15/15 - 142s - loss: 0.7975 - accuracy: 0.5268 - auc: 0.5528 - val_loss: 0.7295 - val_accuracy: 0.5781 - val_auc: 0.5643 - 142s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.72277\n",
            "15/15 - 139s - loss: 0.7949 - accuracy: 0.5418 - auc: 0.5604 - val_loss: 0.7271 - val_accuracy: 0.5469 - val_auc: 0.6390 - 139s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.72277\n",
            "15/15 - 139s - loss: 0.7666 - accuracy: 0.5482 - auc: 0.5858 - val_loss: 0.7349 - val_accuracy: 0.5625 - val_auc: 0.4692 - 139s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.72277\n",
            "15/15 - 139s - loss: 0.8011 - accuracy: 0.5139 - auc: 0.5454 - val_loss: 0.7311 - val_accuracy: 0.4219 - val_auc: 0.3386 - 139s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.72277\n",
            "15/15 - 140s - loss: 0.7650 - accuracy: 0.5621 - auc: 0.5846 - val_loss: 0.7236 - val_accuracy: 0.5625 - val_auc: 0.5142 - 140s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.72277\n",
            "15/15 - 140s - loss: 0.7684 - accuracy: 0.5471 - auc: 0.5850 - val_loss: 0.7236 - val_accuracy: 0.5625 - val_auc: 0.5576 - 140s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.72277\n",
            "15/15 - 139s - loss: 0.7623 - accuracy: 0.5300 - auc: 0.5727 - val_loss: 0.7273 - val_accuracy: 0.6094 - val_auc: 0.5317 - 139s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.72277\n",
            "15/15 - 138s - loss: 0.7555 - accuracy: 0.5353 - auc: 0.5912 - val_loss: 0.7236 - val_accuracy: 0.5000 - val_auc: 0.4644 - 138s/epoch - 9s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.72277\n",
            "15/15 - 138s - loss: 0.7501 - accuracy: 0.5685 - auc: 0.6027 - val_loss: 0.7282 - val_accuracy: 0.4375 - val_auc: 0.3798 - 138s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.72277\n",
            "15/15 - 138s - loss: 0.7425 - accuracy: 0.5482 - auc: 0.6042 - val_loss: 0.7320 - val_accuracy: 0.4219 - val_auc: 0.3867 - 138s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.72277\n",
            "15/15 - 137s - loss: 0.7506 - accuracy: 0.5460 - auc: 0.5909 - val_loss: 0.7322 - val_accuracy: 0.3906 - val_auc: 0.3738 - 137s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.72277\n",
            "15/15 - 137s - loss: 0.7521 - accuracy: 0.5460 - auc: 0.5853 - val_loss: 0.7257 - val_accuracy: 0.3906 - val_auc: 0.3684 - 137s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.72277\n",
            "15/15 - 137s - loss: 0.7448 - accuracy: 0.5546 - auc: 0.6029 - val_loss: 0.7325 - val_accuracy: 0.4375 - val_auc: 0.3707 - 137s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.72277\n",
            "15/15 - 138s - loss: 0.7279 - accuracy: 0.5653 - auc: 0.6094 - val_loss: 0.7298 - val_accuracy: 0.4375 - val_auc: 0.3879 - 138s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.72277\n",
            "15/15 - 137s - loss: 0.7372 - accuracy: 0.5749 - auc: 0.6131 - val_loss: 0.7263 - val_accuracy: 0.4531 - val_auc: 0.4164 - 137s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.72277\n",
            "15/15 - 137s - loss: 0.7274 - accuracy: 0.5707 - auc: 0.6169 - val_loss: 0.7228 - val_accuracy: 0.4531 - val_auc: 0.4418 - 137s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.72277\n",
            "15/15 - 137s - loss: 0.7286 - accuracy: 0.5557 - auc: 0.6103 - val_loss: 0.7286 - val_accuracy: 0.4531 - val_auc: 0.4185 - 137s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.72277\n",
            "15/15 - 136s - loss: 0.7394 - accuracy: 0.5525 - auc: 0.6123 - val_loss: 0.7463 - val_accuracy: 0.4531 - val_auc: 0.3896 - 136s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.72277\n",
            "15/15 - 136s - loss: 0.7101 - accuracy: 0.5771 - auc: 0.6322 - val_loss: 0.7546 - val_accuracy: 0.4531 - val_auc: 0.3722 - 136s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.72277\n",
            "15/15 - 137s - loss: 0.7233 - accuracy: 0.5696 - auc: 0.6204 - val_loss: 0.7434 - val_accuracy: 0.4688 - val_auc: 0.3813 - 137s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.72277\n",
            "15/15 - 136s - loss: 0.7169 - accuracy: 0.5653 - auc: 0.6208 - val_loss: 0.7345 - val_accuracy: 0.4375 - val_auc: 0.3635 - 136s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss improved from 0.72277 to 0.71999, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 139s - loss: 0.7161 - accuracy: 0.5760 - auc: 0.6155 - val_loss: 0.7200 - val_accuracy: 0.4219 - val_auc: 0.3915 - 139s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.71999\n",
            "15/15 - 137s - loss: 0.6999 - accuracy: 0.5942 - auc: 0.6497 - val_loss: 0.7276 - val_accuracy: 0.4219 - val_auc: 0.3678 - 137s/epoch - 9s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.71999\n",
            "15/15 - 136s - loss: 0.7210 - accuracy: 0.5889 - auc: 0.6279 - val_loss: 0.7461 - val_accuracy: 0.4375 - val_auc: 0.3582 - 136s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.71999\n",
            "15/15 - 136s - loss: 0.6971 - accuracy: 0.5803 - auc: 0.6304 - val_loss: 0.7437 - val_accuracy: 0.4375 - val_auc: 0.3740 - 136s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.71999\n",
            "15/15 - 136s - loss: 0.6810 - accuracy: 0.6167 - auc: 0.6734 - val_loss: 0.7471 - val_accuracy: 0.4531 - val_auc: 0.3761 - 136s/epoch - 9s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.71999\n",
            "15/15 - 136s - loss: 0.6943 - accuracy: 0.5803 - auc: 0.6409 - val_loss: 0.7476 - val_accuracy: 0.4688 - val_auc: 0.3630 - 136s/epoch - 9s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.71999\n",
            "15/15 - 135s - loss: 0.7021 - accuracy: 0.5910 - auc: 0.6410 - val_loss: 0.7484 - val_accuracy: 0.4219 - val_auc: 0.3630 - 135s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.71999\n",
            "15/15 - 136s - loss: 0.6806 - accuracy: 0.5964 - auc: 0.6625 - val_loss: 0.7506 - val_accuracy: 0.3906 - val_auc: 0.3547 - 136s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.71999\n",
            "15/15 - 135s - loss: 0.7061 - accuracy: 0.6028 - auc: 0.6453 - val_loss: 0.7427 - val_accuracy: 0.4062 - val_auc: 0.3527 - 135s/epoch - 9s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.71999\n",
            "15/15 - 135s - loss: 0.6942 - accuracy: 0.5974 - auc: 0.6533 - val_loss: 0.7411 - val_accuracy: 0.3438 - val_auc: 0.3782 - 135s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.71999\n",
            "15/15 - 135s - loss: 0.6723 - accuracy: 0.6231 - auc: 0.6879 - val_loss: 0.7464 - val_accuracy: 0.3594 - val_auc: 0.3585 - 135s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.71999\n",
            "15/15 - 135s - loss: 0.6844 - accuracy: 0.6071 - auc: 0.6731 - val_loss: 0.7475 - val_accuracy: 0.3906 - val_auc: 0.3571 - 135s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.71999\n",
            "15/15 - 136s - loss: 0.6695 - accuracy: 0.5814 - auc: 0.6614 - val_loss: 0.7416 - val_accuracy: 0.4219 - val_auc: 0.3656 - 136s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.71999\n",
            "15/15 - 134s - loss: 0.6917 - accuracy: 0.5867 - auc: 0.6459 - val_loss: 0.7452 - val_accuracy: 0.3906 - val_auc: 0.3623 - 134s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.71999\n",
            "15/15 - 134s - loss: 0.6797 - accuracy: 0.6178 - auc: 0.6730 - val_loss: 0.7534 - val_accuracy: 0.4219 - val_auc: 0.3699 - 134s/epoch - 9s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.71999\n",
            "15/15 - 134s - loss: 0.6689 - accuracy: 0.6092 - auc: 0.6820 - val_loss: 0.7446 - val_accuracy: 0.4375 - val_auc: 0.3887 - 134s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.71999\n",
            "15/15 - 134s - loss: 0.6651 - accuracy: 0.6499 - auc: 0.7014 - val_loss: 0.7393 - val_accuracy: 0.4531 - val_auc: 0.4011 - 134s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.71999\n",
            "15/15 - 134s - loss: 0.6594 - accuracy: 0.6178 - auc: 0.6890 - val_loss: 0.7371 - val_accuracy: 0.4219 - val_auc: 0.4188 - 134s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.71999\n",
            "15/15 - 134s - loss: 0.6747 - accuracy: 0.6188 - auc: 0.6860 - val_loss: 0.7275 - val_accuracy: 0.5156 - val_auc: 0.4523 - 134s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss improved from 0.71999 to 0.71909, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6668 - accuracy: 0.6242 - auc: 0.6858 - val_loss: 0.7191 - val_accuracy: 0.4844 - val_auc: 0.4707 - 138s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss improved from 0.71909 to 0.71201, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 137s - loss: 0.6692 - accuracy: 0.6435 - auc: 0.7058 - val_loss: 0.7120 - val_accuracy: 0.4844 - val_auc: 0.4980 - 137s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss improved from 0.71201 to 0.70227, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6524 - accuracy: 0.6552 - auc: 0.7179 - val_loss: 0.7023 - val_accuracy: 0.5000 - val_auc: 0.5430 - 138s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss improved from 0.70227 to 0.69548, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 137s - loss: 0.6618 - accuracy: 0.6317 - auc: 0.6955 - val_loss: 0.6955 - val_accuracy: 0.5469 - val_auc: 0.5779 - 137s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss improved from 0.69548 to 0.69351, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6461 - accuracy: 0.6681 - auc: 0.7336 - val_loss: 0.6935 - val_accuracy: 0.5156 - val_auc: 0.5916 - 138s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss improved from 0.69351 to 0.68914, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 139s - loss: 0.6517 - accuracy: 0.6488 - auc: 0.7203 - val_loss: 0.6891 - val_accuracy: 0.5469 - val_auc: 0.6094 - 139s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss improved from 0.68914 to 0.68182, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6416 - accuracy: 0.6520 - auc: 0.7328 - val_loss: 0.6818 - val_accuracy: 0.5625 - val_auc: 0.6489 - 138s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss improved from 0.68182 to 0.67338, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6654 - accuracy: 0.6113 - auc: 0.6830 - val_loss: 0.6734 - val_accuracy: 0.5938 - val_auc: 0.6689 - 138s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss improved from 0.67338 to 0.67277, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6533 - accuracy: 0.6381 - auc: 0.7108 - val_loss: 0.6728 - val_accuracy: 0.5781 - val_auc: 0.6970 - 138s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss improved from 0.67277 to 0.66609, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6368 - accuracy: 0.6595 - auc: 0.7400 - val_loss: 0.6661 - val_accuracy: 0.6250 - val_auc: 0.7216 - 138s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss improved from 0.66609 to 0.66171, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 140s - loss: 0.6371 - accuracy: 0.6638 - auc: 0.7322 - val_loss: 0.6617 - val_accuracy: 0.6094 - val_auc: 0.7393 - 140s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss improved from 0.66171 to 0.66051, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 141s - loss: 0.6420 - accuracy: 0.6649 - auc: 0.7313 - val_loss: 0.6605 - val_accuracy: 0.6094 - val_auc: 0.7358 - 141s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.66051\n",
            "15/15 - 136s - loss: 0.6215 - accuracy: 0.6842 - auc: 0.7555 - val_loss: 0.6639 - val_accuracy: 0.6094 - val_auc: 0.7314 - 136s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.66051\n",
            "15/15 - 135s - loss: 0.6270 - accuracy: 0.6745 - auc: 0.7557 - val_loss: 0.6639 - val_accuracy: 0.5938 - val_auc: 0.7341 - 135s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss improved from 0.66051 to 0.65177, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 139s - loss: 0.6200 - accuracy: 0.6874 - auc: 0.7690 - val_loss: 0.6518 - val_accuracy: 0.6094 - val_auc: 0.7429 - 139s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss improved from 0.65177 to 0.65145, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 139s - loss: 0.6116 - accuracy: 0.7013 - auc: 0.7746 - val_loss: 0.6515 - val_accuracy: 0.6094 - val_auc: 0.7363 - 139s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss improved from 0.65145 to 0.64778, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6246 - accuracy: 0.6649 - auc: 0.7459 - val_loss: 0.6478 - val_accuracy: 0.6094 - val_auc: 0.7468 - 138s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss improved from 0.64778 to 0.64339, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6211 - accuracy: 0.6927 - auc: 0.7615 - val_loss: 0.6434 - val_accuracy: 0.6406 - val_auc: 0.7437 - 138s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss improved from 0.64339 to 0.63515, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 139s - loss: 0.6293 - accuracy: 0.6777 - auc: 0.7552 - val_loss: 0.6351 - val_accuracy: 0.6719 - val_auc: 0.7598 - 139s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss improved from 0.63515 to 0.62985, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6143 - accuracy: 0.6970 - auc: 0.7793 - val_loss: 0.6299 - val_accuracy: 0.6875 - val_auc: 0.7695 - 138s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss improved from 0.62985 to 0.62352, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6199 - accuracy: 0.6981 - auc: 0.7822 - val_loss: 0.6235 - val_accuracy: 0.7031 - val_auc: 0.7648 - 138s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss improved from 0.62352 to 0.62069, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 137s - loss: 0.6131 - accuracy: 0.7024 - auc: 0.7827 - val_loss: 0.6207 - val_accuracy: 0.7344 - val_auc: 0.7766 - 137s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.62069\n",
            "15/15 - 134s - loss: 0.6038 - accuracy: 0.7313 - auc: 0.8000 - val_loss: 0.6213 - val_accuracy: 0.6875 - val_auc: 0.7725 - 134s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss improved from 0.62069 to 0.61976, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 137s - loss: 0.6088 - accuracy: 0.7034 - auc: 0.7766 - val_loss: 0.6198 - val_accuracy: 0.6875 - val_auc: 0.7825 - 137s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss improved from 0.61976 to 0.61580, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 137s - loss: 0.5935 - accuracy: 0.7013 - auc: 0.7980 - val_loss: 0.6158 - val_accuracy: 0.7344 - val_auc: 0.7964 - 137s/epoch - 9s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss improved from 0.61580 to 0.61223, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.5918 - accuracy: 0.7206 - auc: 0.8046 - val_loss: 0.6122 - val_accuracy: 0.6719 - val_auc: 0.7972 - 138s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss improved from 0.61223 to 0.60910, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 137s - loss: 0.5928 - accuracy: 0.7259 - auc: 0.8083 - val_loss: 0.6091 - val_accuracy: 0.7344 - val_auc: 0.8103 - 137s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss improved from 0.60910 to 0.60870, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.6027 - accuracy: 0.7034 - auc: 0.7895 - val_loss: 0.6087 - val_accuracy: 0.7188 - val_auc: 0.8118 - 138s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.60870\n",
            "15/15 - 136s - loss: 0.5947 - accuracy: 0.7131 - auc: 0.7974 - val_loss: 0.6105 - val_accuracy: 0.7031 - val_auc: 0.7966 - 136s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.60870\n",
            "15/15 - 136s - loss: 0.5907 - accuracy: 0.7377 - auc: 0.8087 - val_loss: 0.6158 - val_accuracy: 0.6719 - val_auc: 0.7876 - 136s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss improved from 0.60870 to 0.60347, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.5759 - accuracy: 0.7302 - auc: 0.8244 - val_loss: 0.6035 - val_accuracy: 0.7344 - val_auc: 0.8080 - 138s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss improved from 0.60347 to 0.60308, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.5848 - accuracy: 0.7281 - auc: 0.8195 - val_loss: 0.6031 - val_accuracy: 0.7344 - val_auc: 0.7961 - 138s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.60308\n",
            "15/15 - 136s - loss: 0.5976 - accuracy: 0.7109 - auc: 0.7870 - val_loss: 0.6041 - val_accuracy: 0.7188 - val_auc: 0.7983 - 136s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss improved from 0.60308 to 0.59965, saving model to Cascade all Model Layers Graph/2022-08-24_09:35:54-model.hdf5\n",
            "15/15 - 138s - loss: 0.5720 - accuracy: 0.7473 - auc: 0.8377 - val_loss: 0.5996 - val_accuracy: 0.7188 - val_auc: 0.8108 - 138s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5702 - accuracy: 0.7420 - auc: 0.8396 - val_loss: 0.6061 - val_accuracy: 0.7188 - val_auc: 0.8025 - 135s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5715 - accuracy: 0.7634 - auc: 0.8440 - val_loss: 0.6116 - val_accuracy: 0.6875 - val_auc: 0.7844 - 134s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5643 - accuracy: 0.7634 - auc: 0.8424 - val_loss: 0.6167 - val_accuracy: 0.6875 - val_auc: 0.7887 - 135s/epoch - 9s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5656 - accuracy: 0.7698 - auc: 0.8516 - val_loss: 0.6124 - val_accuracy: 0.6875 - val_auc: 0.7865 - 134s/epoch - 9s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5644 - accuracy: 0.7559 - auc: 0.8426 - val_loss: 0.6122 - val_accuracy: 0.6875 - val_auc: 0.7734 - 134s/epoch - 9s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5728 - accuracy: 0.7580 - auc: 0.8389 - val_loss: 0.6170 - val_accuracy: 0.6719 - val_auc: 0.7693 - 134s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5687 - accuracy: 0.7677 - auc: 0.8403 - val_loss: 0.6178 - val_accuracy: 0.6719 - val_auc: 0.7878 - 134s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5517 - accuracy: 0.7923 - auc: 0.8557 - val_loss: 0.6346 - val_accuracy: 0.6562 - val_auc: 0.7449 - 134s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5566 - accuracy: 0.7580 - auc: 0.8408 - val_loss: 0.6301 - val_accuracy: 0.6719 - val_auc: 0.7307 - 134s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5601 - accuracy: 0.7773 - auc: 0.8520 - val_loss: 0.6373 - val_accuracy: 0.6094 - val_auc: 0.7589 - 134s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5531 - accuracy: 0.7859 - auc: 0.8534 - val_loss: 0.6300 - val_accuracy: 0.6406 - val_auc: 0.7661 - 134s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5532 - accuracy: 0.7709 - auc: 0.8593 - val_loss: 0.6286 - val_accuracy: 0.6562 - val_auc: 0.7666 - 135s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5575 - accuracy: 0.7719 - auc: 0.8478 - val_loss: 0.6304 - val_accuracy: 0.6562 - val_auc: 0.7483 - 135s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5400 - accuracy: 0.7944 - auc: 0.8670 - val_loss: 0.6311 - val_accuracy: 0.6406 - val_auc: 0.7668 - 135s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5345 - accuracy: 0.8009 - auc: 0.8788 - val_loss: 0.6394 - val_accuracy: 0.6250 - val_auc: 0.7490 - 134s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5377 - accuracy: 0.7709 - auc: 0.8602 - val_loss: 0.6386 - val_accuracy: 0.6250 - val_auc: 0.7463 - 134s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5360 - accuracy: 0.7998 - auc: 0.8719 - val_loss: 0.6459 - val_accuracy: 0.6250 - val_auc: 0.7104 - 134s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5396 - accuracy: 0.7880 - auc: 0.8620 - val_loss: 0.6334 - val_accuracy: 0.6406 - val_auc: 0.7380 - 134s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5139 - accuracy: 0.8212 - auc: 0.8930 - val_loss: 0.6284 - val_accuracy: 0.6250 - val_auc: 0.7466 - 135s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5250 - accuracy: 0.8116 - auc: 0.8828 - val_loss: 0.6391 - val_accuracy: 0.6094 - val_auc: 0.7329 - 134s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5381 - accuracy: 0.7934 - auc: 0.8711 - val_loss: 0.6489 - val_accuracy: 0.6094 - val_auc: 0.7317 - 134s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.59965\n",
            "15/15 - 136s - loss: 0.5329 - accuracy: 0.8073 - auc: 0.8782 - val_loss: 0.6476 - val_accuracy: 0.6250 - val_auc: 0.7153 - 136s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5301 - accuracy: 0.8051 - auc: 0.8784 - val_loss: 0.6484 - val_accuracy: 0.6250 - val_auc: 0.7103 - 134s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5205 - accuracy: 0.8180 - auc: 0.8857 - val_loss: 0.6311 - val_accuracy: 0.6719 - val_auc: 0.7180 - 135s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5150 - accuracy: 0.8255 - auc: 0.8906 - val_loss: 0.6327 - val_accuracy: 0.6719 - val_auc: 0.7271 - 135s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5218 - accuracy: 0.8116 - auc: 0.8835 - val_loss: 0.6199 - val_accuracy: 0.6719 - val_auc: 0.7601 - 134s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5141 - accuracy: 0.8126 - auc: 0.8908 - val_loss: 0.6256 - val_accuracy: 0.6562 - val_auc: 0.7549 - 135s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5015 - accuracy: 0.8426 - auc: 0.9032 - val_loss: 0.6358 - val_accuracy: 0.6250 - val_auc: 0.7332 - 134s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.59965\n",
            "15/15 - 135s - loss: 0.5147 - accuracy: 0.8105 - auc: 0.8881 - val_loss: 0.6480 - val_accuracy: 0.6094 - val_auc: 0.7056 - 135s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4907 - accuracy: 0.8362 - auc: 0.9137 - val_loss: 0.6516 - val_accuracy: 0.6094 - val_auc: 0.7209 - 134s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5121 - accuracy: 0.8201 - auc: 0.8889 - val_loss: 0.6459 - val_accuracy: 0.6094 - val_auc: 0.7327 - 134s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4984 - accuracy: 0.8330 - auc: 0.9076 - val_loss: 0.6290 - val_accuracy: 0.6562 - val_auc: 0.7324 - 134s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5017 - accuracy: 0.8212 - auc: 0.9033 - val_loss: 0.6363 - val_accuracy: 0.6562 - val_auc: 0.7161 - 134s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.5132 - accuracy: 0.8158 - auc: 0.8911 - val_loss: 0.6423 - val_accuracy: 0.6250 - val_auc: 0.7305 - 134s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4862 - accuracy: 0.8522 - auc: 0.9169 - val_loss: 0.6256 - val_accuracy: 0.6562 - val_auc: 0.7495 - 134s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4999 - accuracy: 0.8405 - auc: 0.9018 - val_loss: 0.6171 - val_accuracy: 0.6875 - val_auc: 0.7516 - 134s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4867 - accuracy: 0.8458 - auc: 0.9199 - val_loss: 0.6247 - val_accuracy: 0.6719 - val_auc: 0.7300 - 134s/epoch - 9s/step\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4792 - accuracy: 0.8576 - auc: 0.9202 - val_loss: 0.6392 - val_accuracy: 0.6094 - val_auc: 0.7256 - 134s/epoch - 9s/step\n",
            "Epoch 124/150\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4856 - accuracy: 0.8544 - auc: 0.9163 - val_loss: 0.6414 - val_accuracy: 0.6094 - val_auc: 0.7173 - 134s/epoch - 9s/step\n",
            "Epoch 125/150\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.59965\n",
            "15/15 - 134s - loss: 0.4703 - accuracy: 0.8608 - auc: 0.9237 - val_loss: 0.6457 - val_accuracy: 0.6094 - val_auc: 0.7212 - 134s/epoch - 9s/step\n",
            "Epoch 126/150\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4751 - accuracy: 0.8437 - auc: 0.9192 - val_loss: 0.6477 - val_accuracy: 0.6094 - val_auc: 0.7188 - 133s/epoch - 9s/step\n",
            "Epoch 127/150\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4515 - accuracy: 0.8672 - auc: 0.9381 - val_loss: 0.6391 - val_accuracy: 0.6406 - val_auc: 0.7136 - 133s/epoch - 9s/step\n",
            "Epoch 128/150\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4793 - accuracy: 0.8544 - auc: 0.9150 - val_loss: 0.6326 - val_accuracy: 0.6562 - val_auc: 0.7319 - 133s/epoch - 9s/step\n",
            "Epoch 129/150\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4670 - accuracy: 0.8608 - auc: 0.9230 - val_loss: 0.6413 - val_accuracy: 0.6094 - val_auc: 0.7283 - 133s/epoch - 9s/step\n",
            "Epoch 130/150\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4649 - accuracy: 0.8651 - auc: 0.9251 - val_loss: 0.6524 - val_accuracy: 0.5938 - val_auc: 0.7190 - 133s/epoch - 9s/step\n",
            "Epoch 131/150\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4738 - accuracy: 0.8597 - auc: 0.9217 - val_loss: 0.6528 - val_accuracy: 0.6250 - val_auc: 0.7278 - 133s/epoch - 9s/step\n",
            "Epoch 132/150\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4729 - accuracy: 0.8415 - auc: 0.9094 - val_loss: 0.6393 - val_accuracy: 0.6094 - val_auc: 0.7251 - 133s/epoch - 9s/step\n",
            "Epoch 133/150\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4555 - accuracy: 0.8565 - auc: 0.9275 - val_loss: 0.6550 - val_accuracy: 0.5938 - val_auc: 0.7041 - 133s/epoch - 9s/step\n",
            "Epoch 134/150\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4682 - accuracy: 0.8597 - auc: 0.9182 - val_loss: 0.6699 - val_accuracy: 0.6094 - val_auc: 0.7094 - 133s/epoch - 9s/step\n",
            "Epoch 135/150\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.59965\n",
            "15/15 - 133s - loss: 0.4639 - accuracy: 0.8801 - auc: 0.9314 - val_loss: 0.6734 - val_accuracy: 0.6250 - val_auc: 0.6794 - 133s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7236\n",
            "Recall: 0.7607\n",
            "Threshold: 0.3216\n",
            "F1 Score: 0.7417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10982/10982 [2:04:51<00:00,  1.47it/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_Name='E2E Model Saved'\n",
        "model = create_model_E2E()\n",
        "#model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history0 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history0.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./E2E_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfaLzyznNrBc"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx8F6dncNrBc"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNUCdODxNrBc"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHCyXW3BNrBd"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYob__o8NrBd"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9As0X0oXOqeu"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "\n",
        "plt.plot(history0.history['val_auc'], label='E2E Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YURC6mzSZauH",
        "outputId": "f4c148ca-3bf0-4ec2-d7f7-5dfaba61053d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "layer 1 : input_4 is trainable: False\n",
            "layer 2 : conv1_pad is trainable: False\n",
            "layer 3 : conv1_conv is trainable: False\n",
            "layer 4 : conv1_bn is trainable: False\n",
            "layer 5 : conv1_relu is trainable: False\n",
            "layer 6 : pool1_pad is trainable: False\n",
            "layer 7 : pool1_pool is trainable: False\n",
            "layer 8 : conv2_block1_1_conv is trainable: False\n",
            "layer 9 : conv2_block1_1_bn is trainable: False\n",
            "layer 10 : conv2_block1_1_relu is trainable: False\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.88352, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 149s - loss: 0.7258 - accuracy: 0.6221 - auc: 0.6546 - val_loss: 0.8835 - val_accuracy: 0.4531 - val_auc: 0.5815 - 149s/epoch - 10s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.88352\n",
            "15/15 - 142s - loss: 0.6552 - accuracy: 0.6670 - auc: 0.7294 - val_loss: 1.1886 - val_accuracy: 0.5938 - val_auc: 0.6934 - 142s/epoch - 9s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.88352\n",
            "15/15 - 142s - loss: 0.6118 - accuracy: 0.7077 - auc: 0.7739 - val_loss: 0.9960 - val_accuracy: 0.6406 - val_auc: 0.6794 - 142s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss improved from 0.88352 to 0.76138, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 143s - loss: 0.6315 - accuracy: 0.6831 - auc: 0.7494 - val_loss: 0.7614 - val_accuracy: 0.6094 - val_auc: 0.7261 - 143s/epoch - 10s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss improved from 0.76138 to 0.69520, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 143s - loss: 0.6043 - accuracy: 0.6884 - auc: 0.7681 - val_loss: 0.6952 - val_accuracy: 0.7188 - val_auc: 0.7795 - 143s/epoch - 10s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.69520\n",
            "15/15 - 139s - loss: 0.6121 - accuracy: 0.7056 - auc: 0.7690 - val_loss: 1.0666 - val_accuracy: 0.4688 - val_auc: 0.6174 - 139s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.69520\n",
            "15/15 - 139s - loss: 0.6020 - accuracy: 0.7120 - auc: 0.7841 - val_loss: 0.8228 - val_accuracy: 0.5938 - val_auc: 0.7209 - 139s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.69520\n",
            "15/15 - 139s - loss: 0.5888 - accuracy: 0.7002 - auc: 0.7939 - val_loss: 1.0453 - val_accuracy: 0.6250 - val_auc: 0.7236 - 139s/epoch - 9s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.69520\n",
            "15/15 - 138s - loss: 0.5843 - accuracy: 0.7152 - auc: 0.7945 - val_loss: 0.9054 - val_accuracy: 0.6250 - val_auc: 0.6538 - 138s/epoch - 9s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.69520\n",
            "15/15 - 139s - loss: 0.6065 - accuracy: 0.7056 - auc: 0.7771 - val_loss: 0.7151 - val_accuracy: 0.6719 - val_auc: 0.7620 - 139s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.69520\n",
            "15/15 - 138s - loss: 0.5941 - accuracy: 0.7291 - auc: 0.7976 - val_loss: 0.8128 - val_accuracy: 0.7344 - val_auc: 0.7629 - 138s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.69520\n",
            "15/15 - 138s - loss: 0.5830 - accuracy: 0.7345 - auc: 0.7992 - val_loss: 0.8722 - val_accuracy: 0.7031 - val_auc: 0.7961 - 138s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.69520\n",
            "15/15 - 138s - loss: 0.6019 - accuracy: 0.7195 - auc: 0.7813 - val_loss: 0.9984 - val_accuracy: 0.5625 - val_auc: 0.6970 - 138s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.69520\n",
            "15/15 - 139s - loss: 0.5884 - accuracy: 0.7141 - auc: 0.7906 - val_loss: 0.9098 - val_accuracy: 0.6875 - val_auc: 0.6951 - 139s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.69520\n",
            "15/15 - 139s - loss: 0.5749 - accuracy: 0.7441 - auc: 0.8086 - val_loss: 0.7341 - val_accuracy: 0.7188 - val_auc: 0.7759 - 139s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss improved from 0.69520 to 0.63638, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 140s - loss: 0.5972 - accuracy: 0.7334 - auc: 0.7880 - val_loss: 0.6364 - val_accuracy: 0.7031 - val_auc: 0.7814 - 140s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.63638\n",
            "15/15 - 137s - loss: 0.5873 - accuracy: 0.7056 - auc: 0.7949 - val_loss: 0.6431 - val_accuracy: 0.7188 - val_auc: 0.7936 - 137s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.63638\n",
            "15/15 - 137s - loss: 0.6022 - accuracy: 0.7206 - auc: 0.7897 - val_loss: 0.6847 - val_accuracy: 0.7344 - val_auc: 0.7966 - 137s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5784 - accuracy: 0.7452 - auc: 0.8058 - val_loss: 0.7254 - val_accuracy: 0.7031 - val_auc: 0.7517 - 138s/epoch - 9s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.63638\n",
            "15/15 - 137s - loss: 0.5950 - accuracy: 0.7141 - auc: 0.7836 - val_loss: 0.8168 - val_accuracy: 0.7500 - val_auc: 0.7900 - 137s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.63638\n",
            "15/15 - 137s - loss: 0.5752 - accuracy: 0.7323 - auc: 0.8055 - val_loss: 0.6564 - val_accuracy: 0.6875 - val_auc: 0.7524 - 137s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5921 - accuracy: 0.7238 - auc: 0.7927 - val_loss: 0.6428 - val_accuracy: 0.7031 - val_auc: 0.7600 - 138s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5684 - accuracy: 0.7355 - auc: 0.8035 - val_loss: 0.7025 - val_accuracy: 0.6406 - val_auc: 0.7268 - 138s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5745 - accuracy: 0.7291 - auc: 0.7989 - val_loss: 0.7687 - val_accuracy: 0.6875 - val_auc: 0.7510 - 138s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5834 - accuracy: 0.7355 - auc: 0.7964 - val_loss: 1.2508 - val_accuracy: 0.4844 - val_auc: 0.6011 - 138s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.63638\n",
            "15/15 - 137s - loss: 0.5601 - accuracy: 0.7698 - auc: 0.8192 - val_loss: 0.8044 - val_accuracy: 0.6719 - val_auc: 0.7126 - 137s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5727 - accuracy: 0.7388 - auc: 0.8099 - val_loss: 0.7589 - val_accuracy: 0.5781 - val_auc: 0.7305 - 138s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.63638\n",
            "15/15 - 137s - loss: 0.5962 - accuracy: 0.7302 - auc: 0.7960 - val_loss: 0.8216 - val_accuracy: 0.6875 - val_auc: 0.6960 - 137s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5886 - accuracy: 0.7430 - auc: 0.8028 - val_loss: 0.7885 - val_accuracy: 0.7031 - val_auc: 0.7773 - 138s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5705 - accuracy: 0.7281 - auc: 0.8050 - val_loss: 0.7354 - val_accuracy: 0.7031 - val_auc: 0.7668 - 138s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5890 - accuracy: 0.7291 - auc: 0.7951 - val_loss: 0.8096 - val_accuracy: 0.5938 - val_auc: 0.7302 - 138s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5691 - accuracy: 0.7388 - auc: 0.8017 - val_loss: 0.7690 - val_accuracy: 0.6875 - val_auc: 0.7896 - 138s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5838 - accuracy: 0.7248 - auc: 0.8019 - val_loss: 0.8344 - val_accuracy: 0.5938 - val_auc: 0.7368 - 139s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5769 - accuracy: 0.7355 - auc: 0.8069 - val_loss: 0.7562 - val_accuracy: 0.5938 - val_auc: 0.7115 - 138s/epoch - 9s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.6021 - accuracy: 0.7163 - auc: 0.7892 - val_loss: 0.8231 - val_accuracy: 0.6875 - val_auc: 0.7351 - 138s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5766 - accuracy: 0.7355 - auc: 0.7980 - val_loss: 0.9004 - val_accuracy: 0.7188 - val_auc: 0.7354 - 139s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5514 - accuracy: 0.7366 - auc: 0.8143 - val_loss: 0.6444 - val_accuracy: 0.7344 - val_auc: 0.7900 - 138s/epoch - 9s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5749 - accuracy: 0.7291 - auc: 0.8034 - val_loss: 0.7589 - val_accuracy: 0.6875 - val_auc: 0.7791 - 139s/epoch - 9s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5613 - accuracy: 0.7388 - auc: 0.8133 - val_loss: 0.7010 - val_accuracy: 0.7188 - val_auc: 0.7778 - 138s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5645 - accuracy: 0.7345 - auc: 0.8126 - val_loss: 1.0253 - val_accuracy: 0.5625 - val_auc: 0.6885 - 138s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5768 - accuracy: 0.7323 - auc: 0.8059 - val_loss: 0.6860 - val_accuracy: 0.7031 - val_auc: 0.7710 - 138s/epoch - 9s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5699 - accuracy: 0.7366 - auc: 0.8073 - val_loss: 0.7634 - val_accuracy: 0.6719 - val_auc: 0.7139 - 139s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5591 - accuracy: 0.7355 - auc: 0.8111 - val_loss: 0.7443 - val_accuracy: 0.5938 - val_auc: 0.7207 - 139s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5771 - accuracy: 0.7452 - auc: 0.8022 - val_loss: 0.6364 - val_accuracy: 0.7344 - val_auc: 0.7661 - 138s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5505 - accuracy: 0.7484 - auc: 0.8225 - val_loss: 0.7340 - val_accuracy: 0.7031 - val_auc: 0.7859 - 138s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5794 - accuracy: 0.7259 - auc: 0.7953 - val_loss: 0.7878 - val_accuracy: 0.6875 - val_auc: 0.7643 - 139s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5615 - accuracy: 0.7441 - auc: 0.8120 - val_loss: 0.7200 - val_accuracy: 0.5781 - val_auc: 0.7441 - 139s/epoch - 9s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.63638\n",
            "15/15 - 138s - loss: 0.5505 - accuracy: 0.7463 - auc: 0.8202 - val_loss: 0.8856 - val_accuracy: 0.5781 - val_auc: 0.7246 - 138s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5596 - accuracy: 0.7388 - auc: 0.8113 - val_loss: 0.6796 - val_accuracy: 0.7656 - val_auc: 0.7776 - 139s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5791 - accuracy: 0.7281 - auc: 0.7986 - val_loss: 0.7993 - val_accuracy: 0.6562 - val_auc: 0.6970 - 139s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.63638\n",
            "15/15 - 139s - loss: 0.5759 - accuracy: 0.7206 - auc: 0.7958 - val_loss: 0.6895 - val_accuracy: 0.7344 - val_auc: 0.7817 - 139s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss improved from 0.63638 to 0.62086, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 142s - loss: 0.5680 - accuracy: 0.7452 - auc: 0.8077 - val_loss: 0.6209 - val_accuracy: 0.7500 - val_auc: 0.8130 - 142s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.62086\n",
            "15/15 - 139s - loss: 0.5663 - accuracy: 0.7195 - auc: 0.8064 - val_loss: 0.6582 - val_accuracy: 0.7344 - val_auc: 0.7793 - 139s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.62086\n",
            "15/15 - 139s - loss: 0.5717 - accuracy: 0.7206 - auc: 0.8005 - val_loss: 0.6487 - val_accuracy: 0.7500 - val_auc: 0.7891 - 139s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.62086\n",
            "15/15 - 139s - loss: 0.5634 - accuracy: 0.7398 - auc: 0.8121 - val_loss: 0.7296 - val_accuracy: 0.6406 - val_auc: 0.7329 - 139s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.62086\n",
            "15/15 - 138s - loss: 0.5461 - accuracy: 0.7548 - auc: 0.8215 - val_loss: 0.6425 - val_accuracy: 0.7188 - val_auc: 0.7856 - 138s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.62086\n",
            "15/15 - 138s - loss: 0.5756 - accuracy: 0.7377 - auc: 0.8044 - val_loss: 0.9003 - val_accuracy: 0.6562 - val_auc: 0.6827 - 138s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.62086\n",
            "15/15 - 138s - loss: 0.5631 - accuracy: 0.7420 - auc: 0.8181 - val_loss: 0.7221 - val_accuracy: 0.7500 - val_auc: 0.7874 - 138s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.62086\n",
            "15/15 - 137s - loss: 0.5767 - accuracy: 0.7270 - auc: 0.7951 - val_loss: 0.7539 - val_accuracy: 0.6250 - val_auc: 0.7461 - 137s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.62086\n",
            "15/15 - 137s - loss: 0.5603 - accuracy: 0.7388 - auc: 0.8127 - val_loss: 0.9160 - val_accuracy: 0.6875 - val_auc: 0.7146 - 137s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.62086\n",
            "15/15 - 136s - loss: 0.5674 - accuracy: 0.7313 - auc: 0.8068 - val_loss: 0.7970 - val_accuracy: 0.5781 - val_auc: 0.7217 - 136s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.62086\n",
            "15/15 - 136s - loss: 0.5689 - accuracy: 0.7163 - auc: 0.8031 - val_loss: 0.7004 - val_accuracy: 0.6250 - val_auc: 0.7412 - 136s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss improved from 0.62086 to 0.61103, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 140s - loss: 0.5869 - accuracy: 0.7313 - auc: 0.8029 - val_loss: 0.6110 - val_accuracy: 0.7344 - val_auc: 0.8007 - 140s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5657 - accuracy: 0.7516 - auc: 0.8174 - val_loss: 0.6413 - val_accuracy: 0.7031 - val_auc: 0.7966 - 138s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5342 - accuracy: 0.7548 - auc: 0.8313 - val_loss: 0.6128 - val_accuracy: 0.7500 - val_auc: 0.7988 - 138s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5419 - accuracy: 0.7463 - auc: 0.8199 - val_loss: 0.6708 - val_accuracy: 0.6406 - val_auc: 0.7375 - 138s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5396 - accuracy: 0.7484 - auc: 0.8235 - val_loss: 0.7882 - val_accuracy: 0.6719 - val_auc: 0.7058 - 138s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5587 - accuracy: 0.7420 - auc: 0.8114 - val_loss: 0.9683 - val_accuracy: 0.5781 - val_auc: 0.6577 - 138s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5714 - accuracy: 0.7291 - auc: 0.8045 - val_loss: 0.7890 - val_accuracy: 0.6094 - val_auc: 0.7271 - 138s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5647 - accuracy: 0.7505 - auc: 0.8146 - val_loss: 0.6350 - val_accuracy: 0.7344 - val_auc: 0.7778 - 138s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5643 - accuracy: 0.7345 - auc: 0.8077 - val_loss: 0.7410 - val_accuracy: 0.5938 - val_auc: 0.7356 - 138s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5597 - accuracy: 0.7409 - auc: 0.8170 - val_loss: 1.3225 - val_accuracy: 0.5625 - val_auc: 0.6384 - 138s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5393 - accuracy: 0.7441 - auc: 0.8234 - val_loss: 0.7966 - val_accuracy: 0.7188 - val_auc: 0.7205 - 138s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5754 - accuracy: 0.7216 - auc: 0.7972 - val_loss: 0.9095 - val_accuracy: 0.5781 - val_auc: 0.7129 - 138s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5504 - accuracy: 0.7495 - auc: 0.8135 - val_loss: 0.8023 - val_accuracy: 0.7344 - val_auc: 0.7898 - 137s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5757 - accuracy: 0.7206 - auc: 0.7982 - val_loss: 0.6703 - val_accuracy: 0.6875 - val_auc: 0.7651 - 138s/epoch - 9s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5936 - accuracy: 0.7463 - auc: 0.8051 - val_loss: 0.7427 - val_accuracy: 0.6094 - val_auc: 0.7371 - 137s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5646 - accuracy: 0.7355 - auc: 0.8059 - val_loss: 0.6834 - val_accuracy: 0.7344 - val_auc: 0.7915 - 138s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5654 - accuracy: 0.7398 - auc: 0.8060 - val_loss: 1.2890 - val_accuracy: 0.5156 - val_auc: 0.6025 - 138s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5331 - accuracy: 0.7441 - auc: 0.8257 - val_loss: 0.6850 - val_accuracy: 0.7812 - val_auc: 0.8147 - 137s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5538 - accuracy: 0.7398 - auc: 0.8142 - val_loss: 0.6884 - val_accuracy: 0.7188 - val_auc: 0.7920 - 137s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5423 - accuracy: 0.7355 - auc: 0.8195 - val_loss: 0.7435 - val_accuracy: 0.7656 - val_auc: 0.8086 - 137s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5891 - accuracy: 0.7227 - auc: 0.8023 - val_loss: 0.9395 - val_accuracy: 0.5625 - val_auc: 0.7095 - 137s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5586 - accuracy: 0.7334 - auc: 0.8101 - val_loss: 0.7307 - val_accuracy: 0.7031 - val_auc: 0.7136 - 137s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5411 - accuracy: 0.7409 - auc: 0.8213 - val_loss: 0.6915 - val_accuracy: 0.7344 - val_auc: 0.7764 - 137s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5546 - accuracy: 0.7484 - auc: 0.8139 - val_loss: 0.7020 - val_accuracy: 0.7188 - val_auc: 0.7703 - 138s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5493 - accuracy: 0.7377 - auc: 0.8194 - val_loss: 0.6369 - val_accuracy: 0.7031 - val_auc: 0.7852 - 137s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5551 - accuracy: 0.7709 - auc: 0.8269 - val_loss: 0.7576 - val_accuracy: 0.6094 - val_auc: 0.7312 - 137s/epoch - 9s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5596 - accuracy: 0.7409 - auc: 0.8126 - val_loss: 0.9026 - val_accuracy: 0.5781 - val_auc: 0.7107 - 137s/epoch - 9s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5772 - accuracy: 0.7206 - auc: 0.8020 - val_loss: 0.8036 - val_accuracy: 0.7188 - val_auc: 0.7490 - 137s/epoch - 9s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.61103\n",
            "15/15 - 138s - loss: 0.5513 - accuracy: 0.7409 - auc: 0.8153 - val_loss: 0.7861 - val_accuracy: 0.7188 - val_auc: 0.7378 - 138s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5651 - accuracy: 0.7409 - auc: 0.8117 - val_loss: 0.6161 - val_accuracy: 0.7344 - val_auc: 0.7837 - 137s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5426 - accuracy: 0.7355 - auc: 0.8224 - val_loss: 0.8344 - val_accuracy: 0.5625 - val_auc: 0.7317 - 137s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.61103\n",
            "15/15 - 137s - loss: 0.5459 - accuracy: 0.7527 - auc: 0.8218 - val_loss: 0.6569 - val_accuracy: 0.6250 - val_auc: 0.7427 - 137s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss improved from 0.61103 to 0.60187, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 140s - loss: 0.5738 - accuracy: 0.7430 - auc: 0.8033 - val_loss: 0.6019 - val_accuracy: 0.7656 - val_auc: 0.8184 - 140s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss improved from 0.60187 to 0.60124, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 142s - loss: 0.5532 - accuracy: 0.7463 - auc: 0.8210 - val_loss: 0.6012 - val_accuracy: 0.7188 - val_auc: 0.7827 - 142s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss improved from 0.60124 to 0.58663, saving model to Cascade all Model Layers Graph/2022-08-24_17:12:35-model.hdf5\n",
            "15/15 - 141s - loss: 0.5369 - accuracy: 0.7559 - auc: 0.8266 - val_loss: 0.5866 - val_accuracy: 0.7969 - val_auc: 0.8115 - 141s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5422 - accuracy: 0.7537 - auc: 0.8252 - val_loss: 0.9342 - val_accuracy: 0.5938 - val_auc: 0.6694 - 138s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5804 - accuracy: 0.7345 - auc: 0.8035 - val_loss: 0.6038 - val_accuracy: 0.7656 - val_auc: 0.8030 - 138s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5538 - accuracy: 0.7473 - auc: 0.8139 - val_loss: 0.7264 - val_accuracy: 0.5938 - val_auc: 0.7341 - 137s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5444 - accuracy: 0.7495 - auc: 0.8194 - val_loss: 0.6079 - val_accuracy: 0.6875 - val_auc: 0.7787 - 137s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5653 - accuracy: 0.7495 - auc: 0.8112 - val_loss: 0.7461 - val_accuracy: 0.6875 - val_auc: 0.7559 - 137s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5261 - accuracy: 0.7580 - auc: 0.8338 - val_loss: 0.6019 - val_accuracy: 0.7656 - val_auc: 0.8037 - 137s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5245 - accuracy: 0.7762 - auc: 0.8350 - val_loss: 0.8309 - val_accuracy: 0.5781 - val_auc: 0.7241 - 137s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5669 - accuracy: 0.7323 - auc: 0.8013 - val_loss: 0.7649 - val_accuracy: 0.7500 - val_auc: 0.7935 - 137s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5596 - accuracy: 0.7409 - auc: 0.8129 - val_loss: 0.6392 - val_accuracy: 0.7344 - val_auc: 0.7939 - 137s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5875 - accuracy: 0.7313 - auc: 0.7971 - val_loss: 0.6459 - val_accuracy: 0.6406 - val_auc: 0.7527 - 138s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5527 - accuracy: 0.7398 - auc: 0.8188 - val_loss: 1.3730 - val_accuracy: 0.5156 - val_auc: 0.6177 - 138s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5514 - accuracy: 0.7409 - auc: 0.8167 - val_loss: 0.6248 - val_accuracy: 0.7656 - val_auc: 0.7981 - 136s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5563 - accuracy: 0.7270 - auc: 0.8073 - val_loss: 1.0592 - val_accuracy: 0.5938 - val_auc: 0.7302 - 137s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5352 - accuracy: 0.7687 - auc: 0.8256 - val_loss: 0.6430 - val_accuracy: 0.6719 - val_auc: 0.7717 - 136s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5643 - accuracy: 0.7441 - auc: 0.8031 - val_loss: 0.5900 - val_accuracy: 0.7969 - val_auc: 0.8109 - 137s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5385 - accuracy: 0.7602 - auc: 0.8230 - val_loss: 0.8172 - val_accuracy: 0.6250 - val_auc: 0.6805 - 137s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5466 - accuracy: 0.7420 - auc: 0.8204 - val_loss: 0.6191 - val_accuracy: 0.7656 - val_auc: 0.8071 - 137s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5506 - accuracy: 0.7302 - auc: 0.8116 - val_loss: 0.7286 - val_accuracy: 0.6094 - val_auc: 0.7344 - 137s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5646 - accuracy: 0.7409 - auc: 0.8094 - val_loss: 0.6430 - val_accuracy: 0.7500 - val_auc: 0.7810 - 138s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5594 - accuracy: 0.7527 - auc: 0.8150 - val_loss: 0.6061 - val_accuracy: 0.7656 - val_auc: 0.7996 - 138s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5482 - accuracy: 0.7484 - auc: 0.8179 - val_loss: 0.6638 - val_accuracy: 0.6406 - val_auc: 0.7415 - 137s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5415 - accuracy: 0.7398 - auc: 0.8195 - val_loss: 0.7239 - val_accuracy: 0.7188 - val_auc: 0.7458 - 138s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5358 - accuracy: 0.7484 - auc: 0.8239 - val_loss: 0.7691 - val_accuracy: 0.6875 - val_auc: 0.7058 - 138s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.58663\n",
            "15/15 - 139s - loss: 0.5435 - accuracy: 0.7516 - auc: 0.8203 - val_loss: 0.9285 - val_accuracy: 0.6250 - val_auc: 0.6672 - 139s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5610 - accuracy: 0.7580 - auc: 0.8167 - val_loss: 0.6041 - val_accuracy: 0.7500 - val_auc: 0.8118 - 138s/epoch - 9s/step\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5538 - accuracy: 0.7463 - auc: 0.8177 - val_loss: 0.6990 - val_accuracy: 0.6562 - val_auc: 0.7523 - 138s/epoch - 9s/step\n",
            "Epoch 124/150\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5460 - accuracy: 0.7441 - auc: 0.8183 - val_loss: 0.8282 - val_accuracy: 0.5938 - val_auc: 0.7205 - 138s/epoch - 9s/step\n",
            "Epoch 125/150\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5557 - accuracy: 0.7612 - auc: 0.8180 - val_loss: 0.6420 - val_accuracy: 0.7031 - val_auc: 0.7756 - 138s/epoch - 9s/step\n",
            "Epoch 126/150\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5556 - accuracy: 0.7484 - auc: 0.8120 - val_loss: 0.7405 - val_accuracy: 0.6875 - val_auc: 0.7207 - 137s/epoch - 9s/step\n",
            "Epoch 127/150\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5457 - accuracy: 0.7270 - auc: 0.8175 - val_loss: 0.6191 - val_accuracy: 0.6875 - val_auc: 0.7704 - 137s/epoch - 9s/step\n",
            "Epoch 128/150\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5202 - accuracy: 0.7548 - auc: 0.8330 - val_loss: 0.6763 - val_accuracy: 0.6562 - val_auc: 0.7571 - 137s/epoch - 9s/step\n",
            "Epoch 129/150\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5413 - accuracy: 0.7580 - auc: 0.8199 - val_loss: 0.6068 - val_accuracy: 0.7656 - val_auc: 0.8009 - 137s/epoch - 9s/step\n",
            "Epoch 130/150\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5464 - accuracy: 0.7548 - auc: 0.8182 - val_loss: 0.7813 - val_accuracy: 0.6875 - val_auc: 0.7092 - 137s/epoch - 9s/step\n",
            "Epoch 131/150\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5564 - accuracy: 0.7313 - auc: 0.8152 - val_loss: 0.7179 - val_accuracy: 0.7500 - val_auc: 0.7756 - 137s/epoch - 9s/step\n",
            "Epoch 132/150\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5356 - accuracy: 0.7505 - auc: 0.8303 - val_loss: 1.1183 - val_accuracy: 0.5625 - val_auc: 0.6836 - 137s/epoch - 9s/step\n",
            "Epoch 133/150\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5336 - accuracy: 0.7570 - auc: 0.8288 - val_loss: 0.7795 - val_accuracy: 0.7344 - val_auc: 0.7588 - 138s/epoch - 9s/step\n",
            "Epoch 134/150\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.58663\n",
            "15/15 - 138s - loss: 0.5641 - accuracy: 0.7430 - auc: 0.8073 - val_loss: 0.8619 - val_accuracy: 0.6719 - val_auc: 0.6914 - 138s/epoch - 9s/step\n",
            "Epoch 135/150\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5471 - accuracy: 0.7505 - auc: 0.8229 - val_loss: 0.6679 - val_accuracy: 0.6562 - val_auc: 0.7546 - 137s/epoch - 9s/step\n",
            "Epoch 136/150\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5409 - accuracy: 0.7409 - auc: 0.8170 - val_loss: 0.6166 - val_accuracy: 0.7969 - val_auc: 0.7971 - 136s/epoch - 9s/step\n",
            "Epoch 137/150\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5527 - accuracy: 0.7430 - auc: 0.8162 - val_loss: 0.6139 - val_accuracy: 0.7344 - val_auc: 0.7827 - 136s/epoch - 9s/step\n",
            "Epoch 138/150\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5390 - accuracy: 0.7645 - auc: 0.8185 - val_loss: 0.7809 - val_accuracy: 0.5938 - val_auc: 0.7336 - 137s/epoch - 9s/step\n",
            "Epoch 139/150\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5443 - accuracy: 0.7548 - auc: 0.8234 - val_loss: 0.7701 - val_accuracy: 0.7031 - val_auc: 0.7092 - 137s/epoch - 9s/step\n",
            "Epoch 140/150\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5490 - accuracy: 0.7505 - auc: 0.8191 - val_loss: 0.5921 - val_accuracy: 0.7812 - val_auc: 0.8113 - 137s/epoch - 9s/step\n",
            "Epoch 141/150\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5368 - accuracy: 0.7516 - auc: 0.8280 - val_loss: 0.6656 - val_accuracy: 0.5938 - val_auc: 0.7330 - 136s/epoch - 9s/step\n",
            "Epoch 142/150\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5328 - accuracy: 0.7645 - auc: 0.8301 - val_loss: 0.7749 - val_accuracy: 0.6406 - val_auc: 0.7485 - 136s/epoch - 9s/step\n",
            "Epoch 143/150\n",
            "\n",
            "Epoch 143: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5403 - accuracy: 0.7570 - auc: 0.8264 - val_loss: 0.7898 - val_accuracy: 0.7031 - val_auc: 0.7473 - 137s/epoch - 9s/step\n",
            "Epoch 144/150\n",
            "\n",
            "Epoch 144: val_loss did not improve from 0.58663\n",
            "15/15 - 137s - loss: 0.5492 - accuracy: 0.7345 - auc: 0.8146 - val_loss: 0.6737 - val_accuracy: 0.7344 - val_auc: 0.7590 - 137s/epoch - 9s/step\n",
            "Epoch 145/150\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5519 - accuracy: 0.7377 - auc: 0.8202 - val_loss: 0.9341 - val_accuracy: 0.6250 - val_auc: 0.6807 - 136s/epoch - 9s/step\n",
            "Epoch 146/150\n",
            "\n",
            "Epoch 146: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5279 - accuracy: 0.7602 - auc: 0.8320 - val_loss: 0.6705 - val_accuracy: 0.7344 - val_auc: 0.7804 - 136s/epoch - 9s/step\n",
            "Epoch 147/150\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.58663\n",
            "15/15 - 136s - loss: 0.5469 - accuracy: 0.7612 - auc: 0.8224 - val_loss: 1.2644 - val_accuracy: 0.5625 - val_auc: 0.6440 - 136s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [00:50<00:00,  4.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7059\n",
            "Recall: 0.9231\n",
            "Threshold: 0.269\n",
            "F1 Score: 0.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_Name='Pretrained plus 1st layer Model Saved'\n",
        "model = create_model_Pretrained()\n",
        "#model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history1 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history1.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvuziZ8sNqUT"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoYvZIAnNtDx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gqv5tc8OOLR"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1.history['accuracy'], label='Layer 1 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E and 1 Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71RhZrZYOOLR"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E and 1 Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuHBJmobOOLS"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.plot(history1.history['loss'], label='Layer 1 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E and 1 Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcYIR3I2OOLS"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1.history['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E and 1 Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpd-2jajOOLS"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.plot(history1.history['auc'], label='Layer 1 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E and 1 Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-FowGfCOOLS"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1.history['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' E2E and 1 Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tvtCTMpDN0qP",
        "outputId": "c645e013-ccb0-45b4-9581-5fd83a4a5fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 2)                 26799074  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,800,228\n",
            "Trainable params: 26,662,628\n",
            "Non-trainable params: 137,600\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "15/15 - 347s - loss: 0.6712 - accuracy: 0.6660 - auc: 0.7137 - val_loss: 0.6873 - val_accuracy: 0.5625 - val_auc: 0.5732 - 347s/epoch - 23s/step\n",
            "Epoch 2/150\n",
            "15/15 - 144s - loss: 0.6295 - accuracy: 0.6852 - auc: 0.7646 - val_loss: 0.7286 - val_accuracy: 0.5625 - val_auc: 0.5205 - 144s/epoch - 10s/step\n",
            "Epoch 3/150\n",
            "15/15 - 142s - loss: 0.6389 - accuracy: 0.6959 - auc: 0.7703 - val_loss: 0.7242 - val_accuracy: 0.5625 - val_auc: 0.5039 - 142s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "15/15 - 141s - loss: 0.6344 - accuracy: 0.6938 - auc: 0.7658 - val_loss: 0.7538 - val_accuracy: 0.5625 - val_auc: 0.5527 - 141s/epoch - 9s/step\n",
            "Epoch 5/150\n",
            "15/15 - 141s - loss: 0.6162 - accuracy: 0.7163 - auc: 0.7846 - val_loss: 0.7552 - val_accuracy: 0.5469 - val_auc: 0.5796 - 141s/epoch - 9s/step\n",
            "Epoch 6/150\n",
            "15/15 - 141s - loss: 0.5860 - accuracy: 0.7516 - auc: 0.8203 - val_loss: 0.7613 - val_accuracy: 0.5469 - val_auc: 0.5566 - 141s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "15/15 - 142s - loss: 0.5617 - accuracy: 0.7602 - auc: 0.8386 - val_loss: 0.7551 - val_accuracy: 0.5625 - val_auc: 0.5701 - 142s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "15/15 - 142s - loss: 0.5299 - accuracy: 0.7944 - auc: 0.8689 - val_loss: 0.7848 - val_accuracy: 0.5625 - val_auc: 0.5391 - 142s/epoch - 9s/step\n",
            "Epoch 9/150\n",
            "15/15 - 142s - loss: 0.5247 - accuracy: 0.8105 - auc: 0.8758 - val_loss: 0.7713 - val_accuracy: 0.5625 - val_auc: 0.5569 - 142s/epoch - 9s/step\n",
            "Epoch 10/150\n",
            "15/15 - 142s - loss: 0.5291 - accuracy: 0.8041 - auc: 0.8677 - val_loss: 0.8249 - val_accuracy: 0.5625 - val_auc: 0.5439 - 142s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "15/15 - 140s - loss: 0.5015 - accuracy: 0.8298 - auc: 0.8918 - val_loss: 0.8167 - val_accuracy: 0.5625 - val_auc: 0.5837 - 140s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "15/15 - 140s - loss: 0.5030 - accuracy: 0.8233 - auc: 0.8891 - val_loss: 0.7921 - val_accuracy: 0.5625 - val_auc: 0.5811 - 140s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "15/15 - 140s - loss: 0.4772 - accuracy: 0.8394 - auc: 0.9058 - val_loss: 0.8144 - val_accuracy: 0.5625 - val_auc: 0.5991 - 140s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "15/15 - 141s - loss: 0.4679 - accuracy: 0.8415 - auc: 0.9068 - val_loss: 0.8244 - val_accuracy: 0.5625 - val_auc: 0.5449 - 141s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "15/15 - 141s - loss: 0.4479 - accuracy: 0.8587 - auc: 0.9225 - val_loss: 0.8180 - val_accuracy: 0.5625 - val_auc: 0.5220 - 141s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "15/15 - 141s - loss: 0.4669 - accuracy: 0.8522 - auc: 0.9059 - val_loss: 0.8371 - val_accuracy: 0.5625 - val_auc: 0.5352 - 141s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "15/15 - 140s - loss: 0.4730 - accuracy: 0.8373 - auc: 0.8923 - val_loss: 0.8355 - val_accuracy: 0.5625 - val_auc: 0.5632 - 140s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "15/15 - 141s - loss: 0.4308 - accuracy: 0.8704 - auc: 0.9220 - val_loss: 0.8243 - val_accuracy: 0.5625 - val_auc: 0.5781 - 141s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "15/15 - 140s - loss: 0.4101 - accuracy: 0.8822 - auc: 0.9337 - val_loss: 0.8566 - val_accuracy: 0.5625 - val_auc: 0.5615 - 140s/epoch - 9s/step\n",
            "Epoch 20/150\n",
            "15/15 - 138s - loss: 0.4336 - accuracy: 0.8630 - auc: 0.9113 - val_loss: 0.8958 - val_accuracy: 0.5625 - val_auc: 0.5479 - 138s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "15/15 - 138s - loss: 0.4122 - accuracy: 0.8865 - auc: 0.9290 - val_loss: 0.8829 - val_accuracy: 0.5625 - val_auc: 0.5376 - 138s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "15/15 - 138s - loss: 0.4028 - accuracy: 0.8854 - auc: 0.9366 - val_loss: 0.8765 - val_accuracy: 0.5625 - val_auc: 0.5679 - 138s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "15/15 - 138s - loss: 0.3921 - accuracy: 0.8887 - auc: 0.9368 - val_loss: 0.9024 - val_accuracy: 0.5625 - val_auc: 0.5957 - 138s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "15/15 - 138s - loss: 0.3974 - accuracy: 0.8897 - auc: 0.9289 - val_loss: 0.8771 - val_accuracy: 0.5625 - val_auc: 0.5928 - 138s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "15/15 - 137s - loss: 0.3737 - accuracy: 0.9111 - auc: 0.9464 - val_loss: 0.8883 - val_accuracy: 0.5625 - val_auc: 0.6138 - 137s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "15/15 - 137s - loss: 0.3745 - accuracy: 0.9036 - auc: 0.9365 - val_loss: 0.8607 - val_accuracy: 0.5625 - val_auc: 0.6223 - 137s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "15/15 - 135s - loss: 0.3621 - accuracy: 0.9047 - auc: 0.9482 - val_loss: 0.8309 - val_accuracy: 0.5938 - val_auc: 0.6152 - 135s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "15/15 - 133s - loss: 0.3666 - accuracy: 0.8876 - auc: 0.9412 - val_loss: 0.8354 - val_accuracy: 0.6094 - val_auc: 0.6157 - 133s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "15/15 - 133s - loss: 0.3520 - accuracy: 0.8983 - auc: 0.9494 - val_loss: 0.8324 - val_accuracy: 0.5938 - val_auc: 0.6455 - 133s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "15/15 - 132s - loss: 0.3463 - accuracy: 0.9004 - auc: 0.9576 - val_loss: 0.7906 - val_accuracy: 0.6250 - val_auc: 0.6665 - 132s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "15/15 - 133s - loss: 0.3328 - accuracy: 0.9122 - auc: 0.9586 - val_loss: 0.6928 - val_accuracy: 0.6719 - val_auc: 0.7168 - 133s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "15/15 - 135s - loss: 0.3201 - accuracy: 0.9229 - auc: 0.9623 - val_loss: 0.7109 - val_accuracy: 0.6406 - val_auc: 0.7219 - 135s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "15/15 - 134s - loss: 0.3248 - accuracy: 0.9101 - auc: 0.9585 - val_loss: 0.6753 - val_accuracy: 0.6875 - val_auc: 0.7192 - 134s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "15/15 - 134s - loss: 0.3006 - accuracy: 0.9261 - auc: 0.9698 - val_loss: 0.6837 - val_accuracy: 0.6719 - val_auc: 0.7302 - 134s/epoch - 9s/step\n",
            "Epoch 35/150\n",
            "15/15 - 134s - loss: 0.3108 - accuracy: 0.9208 - auc: 0.9605 - val_loss: 0.6555 - val_accuracy: 0.7031 - val_auc: 0.7236 - 134s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "15/15 - 134s - loss: 0.3061 - accuracy: 0.9283 - auc: 0.9572 - val_loss: 0.6373 - val_accuracy: 0.7344 - val_auc: 0.7422 - 134s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "15/15 - 134s - loss: 0.2870 - accuracy: 0.9240 - auc: 0.9700 - val_loss: 0.6292 - val_accuracy: 0.6875 - val_auc: 0.7561 - 134s/epoch - 9s/step\n",
            "Epoch 38/150\n",
            "15/15 - 133s - loss: 0.2719 - accuracy: 0.9358 - auc: 0.9719 - val_loss: 0.5589 - val_accuracy: 0.7500 - val_auc: 0.8120 - 133s/epoch - 9s/step\n",
            "Epoch 39/150\n",
            "15/15 - 136s - loss: 0.2755 - accuracy: 0.9293 - auc: 0.9715 - val_loss: 0.5883 - val_accuracy: 0.7188 - val_auc: 0.7961 - 136s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "15/15 - 139s - loss: 0.2777 - accuracy: 0.9368 - auc: 0.9686 - val_loss: 0.5181 - val_accuracy: 0.7500 - val_auc: 0.8401 - 139s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "15/15 - 139s - loss: 0.2477 - accuracy: 0.9465 - auc: 0.9836 - val_loss: 0.5327 - val_accuracy: 0.7656 - val_auc: 0.8430 - 139s/epoch - 9s/step\n",
            "Epoch 42/150\n",
            "15/15 - 138s - loss: 0.2729 - accuracy: 0.9304 - auc: 0.9694 - val_loss: 0.4920 - val_accuracy: 0.7969 - val_auc: 0.8508 - 138s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "15/15 - 139s - loss: 0.2496 - accuracy: 0.9497 - auc: 0.9771 - val_loss: 0.4705 - val_accuracy: 0.7656 - val_auc: 0.8689 - 139s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "15/15 - 138s - loss: 0.2411 - accuracy: 0.9433 - auc: 0.9791 - val_loss: 0.4631 - val_accuracy: 0.8125 - val_auc: 0.8801 - 138s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "15/15 - 139s - loss: 0.2432 - accuracy: 0.9454 - auc: 0.9762 - val_loss: 0.4654 - val_accuracy: 0.8125 - val_auc: 0.8672 - 139s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "15/15 - 140s - loss: 0.2334 - accuracy: 0.9486 - auc: 0.9788 - val_loss: 0.4816 - val_accuracy: 0.7969 - val_auc: 0.8767 - 140s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "15/15 - 139s - loss: 0.2182 - accuracy: 0.9593 - auc: 0.9815 - val_loss: 0.4763 - val_accuracy: 0.7969 - val_auc: 0.8716 - 139s/epoch - 9s/step\n",
            "Epoch 48/150\n",
            "15/15 - 139s - loss: 0.2157 - accuracy: 0.9625 - auc: 0.9839 - val_loss: 0.4862 - val_accuracy: 0.7812 - val_auc: 0.8743 - 139s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "15/15 - 141s - loss: 0.1946 - accuracy: 0.9625 - auc: 0.9906 - val_loss: 0.3848 - val_accuracy: 0.8438 - val_auc: 0.9094 - 141s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "15/15 - 141s - loss: 0.2201 - accuracy: 0.9465 - auc: 0.9805 - val_loss: 0.3792 - val_accuracy: 0.8594 - val_auc: 0.9104 - 141s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "15/15 - 140s - loss: 0.2217 - accuracy: 0.9486 - auc: 0.9775 - val_loss: 0.3546 - val_accuracy: 0.8438 - val_auc: 0.9214 - 140s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "15/15 - 139s - loss: 0.2064 - accuracy: 0.9582 - auc: 0.9839 - val_loss: 0.4106 - val_accuracy: 0.8438 - val_auc: 0.9001 - 139s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "15/15 - 140s - loss: 0.2078 - accuracy: 0.9561 - auc: 0.9826 - val_loss: 0.4245 - val_accuracy: 0.8438 - val_auc: 0.8859 - 140s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "15/15 - 142s - loss: 0.2065 - accuracy: 0.9550 - auc: 0.9813 - val_loss: 0.3698 - val_accuracy: 0.8125 - val_auc: 0.9205 - 142s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "15/15 - 142s - loss: 0.2055 - accuracy: 0.9529 - auc: 0.9813 - val_loss: 0.3602 - val_accuracy: 0.8594 - val_auc: 0.9270 - 142s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "15/15 - 142s - loss: 0.1978 - accuracy: 0.9604 - auc: 0.9848 - val_loss: 0.3786 - val_accuracy: 0.8438 - val_auc: 0.9062 - 142s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "15/15 - 142s - loss: 0.1975 - accuracy: 0.9572 - auc: 0.9828 - val_loss: 0.3818 - val_accuracy: 0.8281 - val_auc: 0.9077 - 142s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "15/15 - 142s - loss: 0.1895 - accuracy: 0.9604 - auc: 0.9834 - val_loss: 0.3961 - val_accuracy: 0.8125 - val_auc: 0.8989 - 142s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "15/15 - 142s - loss: 0.1841 - accuracy: 0.9625 - auc: 0.9842 - val_loss: 0.4565 - val_accuracy: 0.8125 - val_auc: 0.8738 - 142s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "15/15 - 140s - loss: 0.1743 - accuracy: 0.9625 - auc: 0.9883 - val_loss: 0.4603 - val_accuracy: 0.7969 - val_auc: 0.8804 - 140s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "15/15 - 141s - loss: 0.1736 - accuracy: 0.9690 - auc: 0.9880 - val_loss: 0.4698 - val_accuracy: 0.7969 - val_auc: 0.8708 - 141s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "15/15 - 142s - loss: 0.1637 - accuracy: 0.9690 - auc: 0.9914 - val_loss: 0.3944 - val_accuracy: 0.8281 - val_auc: 0.9114 - 142s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "15/15 - 141s - loss: 0.1613 - accuracy: 0.9679 - auc: 0.9921 - val_loss: 0.3751 - val_accuracy: 0.8594 - val_auc: 0.9111 - 141s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "15/15 - 140s - loss: 0.1609 - accuracy: 0.9668 - auc: 0.9905 - val_loss: 0.4679 - val_accuracy: 0.8125 - val_auc: 0.8779 - 140s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "15/15 - 140s - loss: 0.1485 - accuracy: 0.9754 - auc: 0.9915 - val_loss: 0.3868 - val_accuracy: 0.8281 - val_auc: 0.8931 - 140s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "15/15 - 140s - loss: 0.1588 - accuracy: 0.9700 - auc: 0.9854 - val_loss: 0.4296 - val_accuracy: 0.8281 - val_auc: 0.9036 - 140s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "15/15 - 139s - loss: 0.1529 - accuracy: 0.9700 - auc: 0.9889 - val_loss: 0.4266 - val_accuracy: 0.8125 - val_auc: 0.9043 - 139s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "15/15 - 140s - loss: 0.1410 - accuracy: 0.9743 - auc: 0.9928 - val_loss: 0.3674 - val_accuracy: 0.8438 - val_auc: 0.9065 - 140s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "15/15 - 140s - loss: 0.1512 - accuracy: 0.9732 - auc: 0.9902 - val_loss: 0.3380 - val_accuracy: 0.8906 - val_auc: 0.9165 - 140s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "15/15 - 139s - loss: 0.1538 - accuracy: 0.9668 - auc: 0.9875 - val_loss: 0.3791 - val_accuracy: 0.8438 - val_auc: 0.9095 - 139s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "15/15 - 140s - loss: 0.1387 - accuracy: 0.9732 - auc: 0.9939 - val_loss: 0.3304 - val_accuracy: 0.8594 - val_auc: 0.9309 - 140s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "15/15 - 138s - loss: 0.1517 - accuracy: 0.9679 - auc: 0.9869 - val_loss: 0.3581 - val_accuracy: 0.8750 - val_auc: 0.9131 - 138s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "15/15 - 140s - loss: 0.1386 - accuracy: 0.9657 - auc: 0.9911 - val_loss: 0.3720 - val_accuracy: 0.8281 - val_auc: 0.9241 - 140s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "15/15 - 140s - loss: 0.1384 - accuracy: 0.9764 - auc: 0.9890 - val_loss: 0.4517 - val_accuracy: 0.7969 - val_auc: 0.9136 - 140s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "15/15 - 142s - loss: 0.1288 - accuracy: 0.9775 - auc: 0.9941 - val_loss: 0.4918 - val_accuracy: 0.8125 - val_auc: 0.8896 - 142s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "15/15 - 143s - loss: 0.1228 - accuracy: 0.9797 - auc: 0.9938 - val_loss: 0.3894 - val_accuracy: 0.8281 - val_auc: 0.9089 - 143s/epoch - 10s/step\n",
            "Epoch 77/150\n",
            "15/15 - 142s - loss: 0.1482 - accuracy: 0.9647 - auc: 0.9869 - val_loss: 0.3687 - val_accuracy: 0.8750 - val_auc: 0.9241 - 142s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "15/15 - 140s - loss: 0.1289 - accuracy: 0.9754 - auc: 0.9907 - val_loss: 0.4221 - val_accuracy: 0.8438 - val_auc: 0.9019 - 140s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "15/15 - 140s - loss: 0.1321 - accuracy: 0.9722 - auc: 0.9922 - val_loss: 0.5094 - val_accuracy: 0.7969 - val_auc: 0.8643 - 140s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "15/15 - 139s - loss: 0.1218 - accuracy: 0.9807 - auc: 0.9918 - val_loss: 0.3857 - val_accuracy: 0.8750 - val_auc: 0.9067 - 139s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "15/15 - 140s - loss: 0.1213 - accuracy: 0.9786 - auc: 0.9939 - val_loss: 0.3536 - val_accuracy: 0.8594 - val_auc: 0.9216 - 140s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "15/15 - 140s - loss: 0.1369 - accuracy: 0.9722 - auc: 0.9891 - val_loss: 0.4485 - val_accuracy: 0.8438 - val_auc: 0.8796 - 140s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "15/15 - 140s - loss: 0.1141 - accuracy: 0.9797 - auc: 0.9926 - val_loss: 0.4368 - val_accuracy: 0.8281 - val_auc: 0.8831 - 140s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "15/15 - 140s - loss: 0.1156 - accuracy: 0.9807 - auc: 0.9917 - val_loss: 0.5375 - val_accuracy: 0.8438 - val_auc: 0.8296 - 140s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "15/15 - 140s - loss: 0.1148 - accuracy: 0.9797 - auc: 0.9927 - val_loss: 0.5346 - val_accuracy: 0.8125 - val_auc: 0.8259 - 140s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "15/15 - 140s - loss: 0.1137 - accuracy: 0.9829 - auc: 0.9914 - val_loss: 0.5688 - val_accuracy: 0.8125 - val_auc: 0.8267 - 140s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "15/15 - 142s - loss: 0.1141 - accuracy: 0.9797 - auc: 0.9910 - val_loss: 0.5791 - val_accuracy: 0.7812 - val_auc: 0.8257 - 142s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "15/15 - 144s - loss: 0.1059 - accuracy: 0.9872 - auc: 0.9943 - val_loss: 0.4802 - val_accuracy: 0.8125 - val_auc: 0.8779 - 144s/epoch - 10s/step\n",
            "Epoch 89/150\n",
            "15/15 - 144s - loss: 0.1063 - accuracy: 0.9818 - auc: 0.9945 - val_loss: 0.5055 - val_accuracy: 0.7812 - val_auc: 0.8716 - 144s/epoch - 10s/step\n",
            "Epoch 90/150\n",
            "15/15 - 144s - loss: 0.1250 - accuracy: 0.9732 - auc: 0.9889 - val_loss: 0.5088 - val_accuracy: 0.8125 - val_auc: 0.8679 - 144s/epoch - 10s/step\n",
            "Epoch 91/150\n",
            "15/15 - 142s - loss: 0.1015 - accuracy: 0.9818 - auc: 0.9947 - val_loss: 0.5149 - val_accuracy: 0.8438 - val_auc: 0.8525 - 142s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "15/15 - 141s - loss: 0.0978 - accuracy: 0.9861 - auc: 0.9942 - val_loss: 0.5531 - val_accuracy: 0.8125 - val_auc: 0.8440 - 141s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "15/15 - 140s - loss: 0.0996 - accuracy: 0.9839 - auc: 0.9927 - val_loss: 0.4977 - val_accuracy: 0.8125 - val_auc: 0.8784 - 140s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "15/15 - 140s - loss: 0.0881 - accuracy: 0.9904 - auc: 0.9978 - val_loss: 0.4237 - val_accuracy: 0.8281 - val_auc: 0.8994 - 140s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "15/15 - 140s - loss: 0.0850 - accuracy: 0.9904 - auc: 0.9982 - val_loss: 0.4676 - val_accuracy: 0.8125 - val_auc: 0.8828 - 140s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "15/15 - 140s - loss: 0.0933 - accuracy: 0.9829 - auc: 0.9973 - val_loss: 0.4710 - val_accuracy: 0.8438 - val_auc: 0.8740 - 140s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "15/15 - 140s - loss: 0.0987 - accuracy: 0.9829 - auc: 0.9939 - val_loss: 0.4626 - val_accuracy: 0.8281 - val_auc: 0.8691 - 140s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "15/15 - 140s - loss: 0.1209 - accuracy: 0.9743 - auc: 0.9890 - val_loss: 0.4667 - val_accuracy: 0.8125 - val_auc: 0.8960 - 140s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "15/15 - 140s - loss: 0.1173 - accuracy: 0.9807 - auc: 0.9863 - val_loss: 0.5347 - val_accuracy: 0.8281 - val_auc: 0.8657 - 140s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "15/15 - 140s - loss: 0.1140 - accuracy: 0.9711 - auc: 0.9922 - val_loss: 0.4602 - val_accuracy: 0.8594 - val_auc: 0.8896 - 140s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "15/15 - 140s - loss: 0.1095 - accuracy: 0.9754 - auc: 0.9905 - val_loss: 0.5119 - val_accuracy: 0.8281 - val_auc: 0.8545 - 140s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "15/15 - 139s - loss: 0.1021 - accuracy: 0.9764 - auc: 0.9941 - val_loss: 0.4619 - val_accuracy: 0.7969 - val_auc: 0.8948 - 139s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "15/15 - 140s - loss: 0.0922 - accuracy: 0.9861 - auc: 0.9925 - val_loss: 0.4634 - val_accuracy: 0.7969 - val_auc: 0.8867 - 140s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "15/15 - 140s - loss: 0.0853 - accuracy: 0.9850 - auc: 0.9965 - val_loss: 0.4566 - val_accuracy: 0.8438 - val_auc: 0.8948 - 140s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "15/15 - 140s - loss: 0.0986 - accuracy: 0.9818 - auc: 0.9934 - val_loss: 0.4176 - val_accuracy: 0.8438 - val_auc: 0.8970 - 140s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "15/15 - 140s - loss: 0.0910 - accuracy: 0.9818 - auc: 0.9970 - val_loss: 0.3152 - val_accuracy: 0.9219 - val_auc: 0.9204 - 140s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "15/15 - 140s - loss: 0.0832 - accuracy: 0.9829 - auc: 0.9963 - val_loss: 0.3724 - val_accuracy: 0.8750 - val_auc: 0.9106 - 140s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "15/15 - 140s - loss: 0.0826 - accuracy: 0.9839 - auc: 0.9962 - val_loss: 0.3787 - val_accuracy: 0.8750 - val_auc: 0.9121 - 140s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "15/15 - 140s - loss: 0.0716 - accuracy: 0.9872 - auc: 0.9973 - val_loss: 0.4212 - val_accuracy: 0.8750 - val_auc: 0.8940 - 140s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "15/15 - 139s - loss: 0.0752 - accuracy: 0.9882 - auc: 0.9960 - val_loss: 0.5048 - val_accuracy: 0.8438 - val_auc: 0.8557 - 139s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "15/15 - 140s - loss: 0.0819 - accuracy: 0.9850 - auc: 0.9964 - val_loss: 0.4642 - val_accuracy: 0.8281 - val_auc: 0.8789 - 140s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "15/15 - 141s - loss: 0.0790 - accuracy: 0.9882 - auc: 0.9957 - val_loss: 0.4084 - val_accuracy: 0.8438 - val_auc: 0.9031 - 141s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "15/15 - 141s - loss: 0.0834 - accuracy: 0.9850 - auc: 0.9962 - val_loss: 0.4171 - val_accuracy: 0.8594 - val_auc: 0.9028 - 141s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "15/15 - 141s - loss: 0.0836 - accuracy: 0.9850 - auc: 0.9941 - val_loss: 0.3972 - val_accuracy: 0.8438 - val_auc: 0.9202 - 141s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "15/15 - 140s - loss: 0.0758 - accuracy: 0.9850 - auc: 0.9980 - val_loss: 0.4762 - val_accuracy: 0.8438 - val_auc: 0.8828 - 140s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "15/15 - 140s - loss: 0.0694 - accuracy: 0.9904 - auc: 0.9981 - val_loss: 0.5173 - val_accuracy: 0.8281 - val_auc: 0.8689 - 140s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "15/15 - 141s - loss: 0.0706 - accuracy: 0.9904 - auc: 0.9948 - val_loss: 0.4810 - val_accuracy: 0.8438 - val_auc: 0.8696 - 141s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "15/15 - 141s - loss: 0.0641 - accuracy: 0.9925 - auc: 0.9971 - val_loss: 0.4317 - val_accuracy: 0.8594 - val_auc: 0.8870 - 141s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "15/15 - 140s - loss: 0.0577 - accuracy: 0.9936 - auc: 0.9996 - val_loss: 0.4311 - val_accuracy: 0.8594 - val_auc: 0.8872 - 140s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "15/15 - 140s - loss: 0.0792 - accuracy: 0.9850 - auc: 0.9953 - val_loss: 0.5193 - val_accuracy: 0.8125 - val_auc: 0.8872 - 140s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "15/15 - 140s - loss: 0.0704 - accuracy: 0.9839 - auc: 0.9982 - val_loss: 0.5302 - val_accuracy: 0.8125 - val_auc: 0.8721 - 140s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "15/15 - 140s - loss: 0.0831 - accuracy: 0.9850 - auc: 0.9932 - val_loss: 0.6430 - val_accuracy: 0.8125 - val_auc: 0.8208 - 140s/epoch - 9s/step\n",
            "Epoch 123/150\n",
            "15/15 - 140s - loss: 0.0853 - accuracy: 0.9797 - auc: 0.9930 - val_loss: 0.6194 - val_accuracy: 0.8125 - val_auc: 0.8306 - 140s/epoch - 9s/step\n",
            "Epoch 124/150\n",
            "15/15 - 142s - loss: 0.0745 - accuracy: 0.9850 - auc: 0.9937 - val_loss: 0.6353 - val_accuracy: 0.7969 - val_auc: 0.8469 - 142s/epoch - 9s/step\n",
            "Epoch 125/150\n",
            "15/15 - 140s - loss: 0.0672 - accuracy: 0.9893 - auc: 0.9972 - val_loss: 0.5430 - val_accuracy: 0.8438 - val_auc: 0.8687 - 140s/epoch - 9s/step\n",
            "Epoch 126/150\n",
            "15/15 - 140s - loss: 0.0690 - accuracy: 0.9882 - auc: 0.9981 - val_loss: 0.5790 - val_accuracy: 0.8438 - val_auc: 0.8467 - 140s/epoch - 9s/step\n",
            "Epoch 127/150\n",
            "15/15 - 141s - loss: 0.0699 - accuracy: 0.9872 - auc: 0.9961 - val_loss: 0.5925 - val_accuracy: 0.8438 - val_auc: 0.8525 - 141s/epoch - 9s/step\n",
            "Epoch 128/150\n",
            "15/15 - 140s - loss: 0.0817 - accuracy: 0.9839 - auc: 0.9931 - val_loss: 0.5572 - val_accuracy: 0.8281 - val_auc: 0.8611 - 140s/epoch - 9s/step\n",
            "Epoch 129/150\n",
            "15/15 - 140s - loss: 0.0656 - accuracy: 0.9904 - auc: 0.9961 - val_loss: 0.6326 - val_accuracy: 0.7812 - val_auc: 0.8396 - 140s/epoch - 9s/step\n",
            "Epoch 130/150\n",
            "15/15 - 140s - loss: 0.0626 - accuracy: 0.9882 - auc: 0.9962 - val_loss: 0.5485 - val_accuracy: 0.8125 - val_auc: 0.8643 - 140s/epoch - 9s/step\n",
            "Epoch 131/150\n",
            "15/15 - 140s - loss: 0.0701 - accuracy: 0.9882 - auc: 0.9950 - val_loss: 0.5445 - val_accuracy: 0.8125 - val_auc: 0.8652 - 140s/epoch - 9s/step\n",
            "Epoch 132/150\n",
            "15/15 - 141s - loss: 0.0604 - accuracy: 0.9893 - auc: 0.9963 - val_loss: 0.5132 - val_accuracy: 0.8125 - val_auc: 0.8706 - 141s/epoch - 9s/step\n",
            "Epoch 133/150\n",
            "15/15 - 140s - loss: 0.0565 - accuracy: 0.9914 - auc: 0.9965 - val_loss: 0.5603 - val_accuracy: 0.8281 - val_auc: 0.8572 - 140s/epoch - 9s/step\n",
            "Epoch 134/150\n",
            "15/15 - 140s - loss: 0.0479 - accuracy: 0.9957 - auc: 0.9998 - val_loss: 0.5564 - val_accuracy: 0.8438 - val_auc: 0.8645 - 140s/epoch - 9s/step\n",
            "Epoch 135/150\n",
            "15/15 - 140s - loss: 0.0626 - accuracy: 0.9882 - auc: 0.9973 - val_loss: 0.5392 - val_accuracy: 0.8281 - val_auc: 0.8662 - 140s/epoch - 9s/step\n",
            "Epoch 136/150\n",
            "15/15 - 141s - loss: 0.0637 - accuracy: 0.9872 - auc: 0.9972 - val_loss: 0.4982 - val_accuracy: 0.8594 - val_auc: 0.8757 - 141s/epoch - 9s/step\n",
            "Epoch 137/150\n",
            "15/15 - 140s - loss: 0.0754 - accuracy: 0.9850 - auc: 0.9926 - val_loss: 0.5581 - val_accuracy: 0.8438 - val_auc: 0.8545 - 140s/epoch - 9s/step\n",
            "Epoch 138/150\n",
            "15/15 - 140s - loss: 0.0744 - accuracy: 0.9893 - auc: 0.9926 - val_loss: 0.4984 - val_accuracy: 0.8281 - val_auc: 0.8748 - 140s/epoch - 9s/step\n",
            "Epoch 139/150\n",
            "15/15 - 140s - loss: 0.0511 - accuracy: 0.9936 - auc: 0.9987 - val_loss: 0.4510 - val_accuracy: 0.8438 - val_auc: 0.8877 - 140s/epoch - 9s/step\n",
            "Epoch 140/150\n",
            "15/15 - 140s - loss: 0.0529 - accuracy: 0.9946 - auc: 0.9976 - val_loss: 0.4547 - val_accuracy: 0.8438 - val_auc: 0.8884 - 140s/epoch - 9s/step\n",
            "Epoch 141/150\n",
            "15/15 - 139s - loss: 0.0735 - accuracy: 0.9839 - auc: 0.9948 - val_loss: 0.4455 - val_accuracy: 0.8750 - val_auc: 0.8962 - 139s/epoch - 9s/step\n",
            "Epoch 142/150\n",
            "15/15 - 140s - loss: 0.0849 - accuracy: 0.9807 - auc: 0.9911 - val_loss: 0.5652 - val_accuracy: 0.8281 - val_auc: 0.8616 - 140s/epoch - 9s/step\n",
            "Epoch 143/150\n",
            "15/15 - 140s - loss: 0.0637 - accuracy: 0.9829 - auc: 0.9981 - val_loss: 0.6784 - val_accuracy: 0.8125 - val_auc: 0.8225 - 140s/epoch - 9s/step\n",
            "Epoch 144/150\n",
            "15/15 - 140s - loss: 0.0978 - accuracy: 0.9786 - auc: 0.9878 - val_loss: 0.6140 - val_accuracy: 0.8281 - val_auc: 0.8574 - 140s/epoch - 9s/step\n",
            "Epoch 145/150\n",
            "15/15 - 140s - loss: 0.0618 - accuracy: 0.9882 - auc: 0.9952 - val_loss: 0.5533 - val_accuracy: 0.8438 - val_auc: 0.8699 - 140s/epoch - 9s/step\n",
            "Epoch 146/150\n",
            "15/15 - 140s - loss: 0.0799 - accuracy: 0.9829 - auc: 0.9903 - val_loss: 0.6399 - val_accuracy: 0.7969 - val_auc: 0.8691 - 140s/epoch - 9s/step\n",
            "Epoch 147/150\n",
            "15/15 - 140s - loss: 0.0602 - accuracy: 0.9904 - auc: 0.9942 - val_loss: 0.5952 - val_accuracy: 0.8281 - val_auc: 0.8616 - 140s/epoch - 9s/step\n",
            "Epoch 148/150\n",
            "15/15 - 140s - loss: 0.0599 - accuracy: 0.9893 - auc: 0.9972 - val_loss: 0.6369 - val_accuracy: 0.7969 - val_auc: 0.8518 - 140s/epoch - 9s/step\n",
            "Epoch 149/150\n",
            "15/15 - 140s - loss: 0.0546 - accuracy: 0.9904 - auc: 0.9953 - val_loss: 0.5401 - val_accuracy: 0.8281 - val_auc: 0.8655 - 140s/epoch - 9s/step\n",
            "Epoch 150/150\n",
            "15/15 - 140s - loss: 0.0547 - accuracy: 0.9904 - auc: 0.9974 - val_loss: 0.6151 - val_accuracy: 0.7969 - val_auc: 0.8481 - 140s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [01:32<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7664\n",
            "Recall: 0.8974\n",
            "Threshold: 0.2691\n",
            "F1 Score: 0.8268\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n\\n\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_Name='Resnet plus 1st layer Model Saved'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 2nd layer Model Saved'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history2 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history2.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXFsOqafKGfQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dst_RtXx2fFg"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1.history['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2.history['accuracy'], label='Layer 2 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 2 Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy-TJvOa2fFh"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 2 Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8VTau_x2fFh"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.plot(history1.history['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2.history['loss'], label='Layer 2 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 2 Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FZcwszf2fFh"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1.history['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 2 Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ10NOFd2fFh"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.plot(history1.history['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2.history['auc'], label='Layer 2 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 2 Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hLfwKLX2fFh"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1.history['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2.history['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 2 Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J-apR0kOzZ0",
        "outputId": "6e80f5ea-24ab-4371-e943-746e73825859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 2)                 26800228  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,801,382\n",
            "Trainable params: 26,663,526\n",
            "Non-trainable params: 137,856\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "15/15 - 150s - loss: 1.2402 - accuracy: 0.1124 - auc: 0.0470 - val_loss: 0.7302 - val_accuracy: 0.1562 - val_auc: 0.2048 - 150s/epoch - 10s/step\n",
            "Epoch 2/150\n",
            "15/15 - 141s - loss: 1.1510 - accuracy: 0.1756 - auc: 0.1137 - val_loss: 0.9003 - val_accuracy: 0.1562 - val_auc: 0.1682 - 141s/epoch - 9s/step\n",
            "Epoch 3/150\n",
            "15/15 - 141s - loss: 1.0851 - accuracy: 0.2281 - auc: 0.1875 - val_loss: 0.9029 - val_accuracy: 0.2656 - val_auc: 0.1912 - 141s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "15/15 - 141s - loss: 0.9947 - accuracy: 0.3201 - auc: 0.2756 - val_loss: 0.8730 - val_accuracy: 0.3125 - val_auc: 0.2783 - 141s/epoch - 9s/step\n",
            "Epoch 5/150\n",
            "15/15 - 140s - loss: 0.9163 - accuracy: 0.3994 - auc: 0.3823 - val_loss: 0.7369 - val_accuracy: 0.5312 - val_auc: 0.4688 - 140s/epoch - 9s/step\n",
            "Epoch 6/150\n",
            "15/15 - 141s - loss: 0.7843 - accuracy: 0.5310 - auc: 0.5352 - val_loss: 0.6905 - val_accuracy: 0.6094 - val_auc: 0.5933 - 141s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "15/15 - 140s - loss: 0.7802 - accuracy: 0.5289 - auc: 0.5185 - val_loss: 0.6762 - val_accuracy: 0.6094 - val_auc: 0.6477 - 140s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "15/15 - 141s - loss: 0.7355 - accuracy: 0.5364 - auc: 0.5578 - val_loss: 0.6524 - val_accuracy: 0.6875 - val_auc: 0.7195 - 141s/epoch - 9s/step\n",
            "Epoch 9/150\n",
            "15/15 - 141s - loss: 0.7269 - accuracy: 0.5546 - auc: 0.5700 - val_loss: 0.6345 - val_accuracy: 0.7344 - val_auc: 0.7566 - 141s/epoch - 9s/step\n",
            "Epoch 10/150\n",
            "15/15 - 140s - loss: 0.6957 - accuracy: 0.6060 - auc: 0.6435 - val_loss: 0.6110 - val_accuracy: 0.7344 - val_auc: 0.7703 - 140s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "15/15 - 140s - loss: 0.7110 - accuracy: 0.5921 - auc: 0.6305 - val_loss: 0.6067 - val_accuracy: 0.7344 - val_auc: 0.7770 - 140s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "15/15 - 140s - loss: 0.6968 - accuracy: 0.6092 - auc: 0.6524 - val_loss: 0.5909 - val_accuracy: 0.7656 - val_auc: 0.8096 - 140s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "15/15 - 140s - loss: 0.6919 - accuracy: 0.6135 - auc: 0.6488 - val_loss: 0.5833 - val_accuracy: 0.7812 - val_auc: 0.8313 - 140s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "15/15 - 140s - loss: 0.6799 - accuracy: 0.6113 - auc: 0.6685 - val_loss: 0.5707 - val_accuracy: 0.7969 - val_auc: 0.8562 - 140s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "15/15 - 141s - loss: 0.6683 - accuracy: 0.6338 - auc: 0.6906 - val_loss: 0.5577 - val_accuracy: 0.8125 - val_auc: 0.8596 - 141s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "15/15 - 141s - loss: 0.6693 - accuracy: 0.6563 - auc: 0.7069 - val_loss: 0.5628 - val_accuracy: 0.7656 - val_auc: 0.8447 - 141s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "15/15 - 140s - loss: 0.6715 - accuracy: 0.6617 - auc: 0.7054 - val_loss: 0.5572 - val_accuracy: 0.7969 - val_auc: 0.8318 - 140s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "15/15 - 141s - loss: 0.6466 - accuracy: 0.6874 - auc: 0.7314 - val_loss: 0.5562 - val_accuracy: 0.7812 - val_auc: 0.8220 - 141s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "15/15 - 141s - loss: 0.6222 - accuracy: 0.7034 - auc: 0.7610 - val_loss: 0.5515 - val_accuracy: 0.7969 - val_auc: 0.8281 - 141s/epoch - 9s/step\n",
            "Epoch 20/150\n",
            "15/15 - 140s - loss: 0.6048 - accuracy: 0.7120 - auc: 0.7850 - val_loss: 0.5609 - val_accuracy: 0.7500 - val_auc: 0.8374 - 140s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "15/15 - 141s - loss: 0.6106 - accuracy: 0.7141 - auc: 0.7756 - val_loss: 0.5622 - val_accuracy: 0.7656 - val_auc: 0.7966 - 141s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "15/15 - 140s - loss: 0.6096 - accuracy: 0.7173 - auc: 0.7789 - val_loss: 0.5563 - val_accuracy: 0.7656 - val_auc: 0.8059 - 140s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "15/15 - 140s - loss: 0.6025 - accuracy: 0.7195 - auc: 0.7869 - val_loss: 0.5201 - val_accuracy: 0.8281 - val_auc: 0.8462 - 140s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "15/15 - 141s - loss: 0.5969 - accuracy: 0.7559 - auc: 0.7974 - val_loss: 0.5182 - val_accuracy: 0.7969 - val_auc: 0.8574 - 141s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "15/15 - 141s - loss: 0.5935 - accuracy: 0.7516 - auc: 0.7949 - val_loss: 0.5541 - val_accuracy: 0.7500 - val_auc: 0.8590 - 141s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "15/15 - 140s - loss: 0.5581 - accuracy: 0.7634 - auc: 0.8325 - val_loss: 0.5265 - val_accuracy: 0.7969 - val_auc: 0.8076 - 140s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "15/15 - 141s - loss: 0.5596 - accuracy: 0.7966 - auc: 0.8330 - val_loss: 0.5301 - val_accuracy: 0.7969 - val_auc: 0.8176 - 141s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "15/15 - 141s - loss: 0.5085 - accuracy: 0.8212 - auc: 0.8820 - val_loss: 0.5303 - val_accuracy: 0.7812 - val_auc: 0.8035 - 141s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "15/15 - 141s - loss: 0.5344 - accuracy: 0.8137 - auc: 0.8478 - val_loss: 0.5217 - val_accuracy: 0.7969 - val_auc: 0.8018 - 141s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "15/15 - 141s - loss: 0.4938 - accuracy: 0.8587 - auc: 0.8863 - val_loss: 0.4835 - val_accuracy: 0.8438 - val_auc: 0.8528 - 141s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "15/15 - 141s - loss: 0.4965 - accuracy: 0.8394 - auc: 0.8812 - val_loss: 0.4861 - val_accuracy: 0.8125 - val_auc: 0.8750 - 141s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "15/15 - 141s - loss: 0.5158 - accuracy: 0.8362 - auc: 0.8590 - val_loss: 0.4777 - val_accuracy: 0.8281 - val_auc: 0.8335 - 141s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "15/15 - 141s - loss: 0.5156 - accuracy: 0.8373 - auc: 0.8583 - val_loss: 0.4544 - val_accuracy: 0.8281 - val_auc: 0.8892 - 141s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "15/15 - 141s - loss: 0.5209 - accuracy: 0.8019 - auc: 0.8496 - val_loss: 0.4444 - val_accuracy: 0.8438 - val_auc: 0.8853 - 141s/epoch - 9s/step\n",
            "Epoch 35/150\n",
            "15/15 - 140s - loss: 0.5134 - accuracy: 0.8233 - auc: 0.8577 - val_loss: 0.4682 - val_accuracy: 0.8281 - val_auc: 0.8489 - 140s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "15/15 - 141s - loss: 0.5162 - accuracy: 0.8223 - auc: 0.8479 - val_loss: 0.4376 - val_accuracy: 0.8438 - val_auc: 0.8708 - 141s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "15/15 - 140s - loss: 0.4949 - accuracy: 0.8426 - auc: 0.8639 - val_loss: 0.4295 - val_accuracy: 0.8594 - val_auc: 0.8762 - 140s/epoch - 9s/step\n",
            "Epoch 38/150\n",
            "15/15 - 141s - loss: 0.4782 - accuracy: 0.8501 - auc: 0.8793 - val_loss: 0.5086 - val_accuracy: 0.7969 - val_auc: 0.8154 - 141s/epoch - 9s/step\n",
            "Epoch 39/150\n",
            "15/15 - 141s - loss: 0.4846 - accuracy: 0.8373 - auc: 0.8684 - val_loss: 0.4979 - val_accuracy: 0.7969 - val_auc: 0.8171 - 141s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "15/15 - 140s - loss: 0.4815 - accuracy: 0.8480 - auc: 0.8751 - val_loss: 0.4928 - val_accuracy: 0.7969 - val_auc: 0.8237 - 140s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "15/15 - 142s - loss: 0.4790 - accuracy: 0.8522 - auc: 0.8716 - val_loss: 0.4305 - val_accuracy: 0.8438 - val_auc: 0.8987 - 142s/epoch - 9s/step\n",
            "Epoch 42/150\n",
            "15/15 - 141s - loss: 0.4760 - accuracy: 0.8533 - auc: 0.8718 - val_loss: 0.4089 - val_accuracy: 0.8594 - val_auc: 0.9038 - 141s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "15/15 - 140s - loss: 0.4942 - accuracy: 0.8266 - auc: 0.8595 - val_loss: 0.4446 - val_accuracy: 0.8281 - val_auc: 0.8850 - 140s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "15/15 - 141s - loss: 0.4762 - accuracy: 0.8490 - auc: 0.8662 - val_loss: 0.4582 - val_accuracy: 0.8281 - val_auc: 0.8367 - 141s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "15/15 - 141s - loss: 0.4620 - accuracy: 0.8522 - auc: 0.8803 - val_loss: 0.4307 - val_accuracy: 0.8438 - val_auc: 0.8516 - 141s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "15/15 - 141s - loss: 0.4460 - accuracy: 0.8619 - auc: 0.8885 - val_loss: 0.4386 - val_accuracy: 0.8438 - val_auc: 0.8701 - 141s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "15/15 - 142s - loss: 0.4295 - accuracy: 0.8833 - auc: 0.8920 - val_loss: 0.4449 - val_accuracy: 0.8438 - val_auc: 0.8569 - 142s/epoch - 9s/step\n",
            "Epoch 48/150\n",
            "15/15 - 141s - loss: 0.4538 - accuracy: 0.8726 - auc: 0.8783 - val_loss: 0.4739 - val_accuracy: 0.8125 - val_auc: 0.8423 - 141s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "15/15 - 141s - loss: 0.4141 - accuracy: 0.8919 - auc: 0.9090 - val_loss: 0.4416 - val_accuracy: 0.8281 - val_auc: 0.8547 - 141s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "15/15 - 140s - loss: 0.4325 - accuracy: 0.8747 - auc: 0.8938 - val_loss: 0.4780 - val_accuracy: 0.8125 - val_auc: 0.8450 - 140s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "15/15 - 140s - loss: 0.4159 - accuracy: 0.8940 - auc: 0.9023 - val_loss: 0.5008 - val_accuracy: 0.7969 - val_auc: 0.8245 - 140s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "15/15 - 141s - loss: 0.4226 - accuracy: 0.8854 - auc: 0.8919 - val_loss: 0.5651 - val_accuracy: 0.7500 - val_auc: 0.7708 - 141s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "15/15 - 141s - loss: 0.4111 - accuracy: 0.8919 - auc: 0.9001 - val_loss: 0.4659 - val_accuracy: 0.8281 - val_auc: 0.8328 - 141s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "15/15 - 140s - loss: 0.4003 - accuracy: 0.8929 - auc: 0.9042 - val_loss: 0.4617 - val_accuracy: 0.8125 - val_auc: 0.8695 - 140s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "15/15 - 141s - loss: 0.4020 - accuracy: 0.8961 - auc: 0.8997 - val_loss: 0.4791 - val_accuracy: 0.7969 - val_auc: 0.8362 - 141s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "15/15 - 141s - loss: 0.3891 - accuracy: 0.9004 - auc: 0.9095 - val_loss: 0.3657 - val_accuracy: 0.8906 - val_auc: 0.8804 - 141s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "15/15 - 140s - loss: 0.3927 - accuracy: 0.9026 - auc: 0.9092 - val_loss: 0.4003 - val_accuracy: 0.8594 - val_auc: 0.8813 - 140s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "15/15 - 140s - loss: 0.3651 - accuracy: 0.9090 - auc: 0.9222 - val_loss: 0.4434 - val_accuracy: 0.8438 - val_auc: 0.8569 - 140s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "15/15 - 141s - loss: 0.3919 - accuracy: 0.8887 - auc: 0.9086 - val_loss: 0.4614 - val_accuracy: 0.8125 - val_auc: 0.8733 - 141s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "15/15 - 142s - loss: 0.3800 - accuracy: 0.9069 - auc: 0.9116 - val_loss: 0.4717 - val_accuracy: 0.8125 - val_auc: 0.8733 - 142s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "15/15 - 141s - loss: 0.3656 - accuracy: 0.9122 - auc: 0.9153 - val_loss: 0.5330 - val_accuracy: 0.7812 - val_auc: 0.8113 - 141s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "15/15 - 141s - loss: 0.3371 - accuracy: 0.9197 - auc: 0.9331 - val_loss: 0.4625 - val_accuracy: 0.8281 - val_auc: 0.8174 - 141s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "15/15 - 140s - loss: 0.3719 - accuracy: 0.9101 - auc: 0.9090 - val_loss: 0.4948 - val_accuracy: 0.7969 - val_auc: 0.8204 - 140s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "15/15 - 142s - loss: 0.3683 - accuracy: 0.9026 - auc: 0.9131 - val_loss: 0.4838 - val_accuracy: 0.8125 - val_auc: 0.8430 - 142s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "15/15 - 142s - loss: 0.4037 - accuracy: 0.8801 - auc: 0.8913 - val_loss: 0.3717 - val_accuracy: 0.8750 - val_auc: 0.8999 - 142s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "15/15 - 141s - loss: 0.4304 - accuracy: 0.8672 - auc: 0.8779 - val_loss: 0.4008 - val_accuracy: 0.8594 - val_auc: 0.8950 - 141s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "15/15 - 142s - loss: 0.4336 - accuracy: 0.8737 - auc: 0.8725 - val_loss: 0.4940 - val_accuracy: 0.7969 - val_auc: 0.8235 - 142s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "15/15 - 142s - loss: 0.4165 - accuracy: 0.8822 - auc: 0.8804 - val_loss: 0.4980 - val_accuracy: 0.7969 - val_auc: 0.8167 - 142s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "15/15 - 142s - loss: 0.3371 - accuracy: 0.9176 - auc: 0.9280 - val_loss: 0.5218 - val_accuracy: 0.7969 - val_auc: 0.8037 - 142s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "15/15 - 140s - loss: 0.3516 - accuracy: 0.9069 - auc: 0.9171 - val_loss: 0.3819 - val_accuracy: 0.8750 - val_auc: 0.8831 - 140s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "15/15 - 140s - loss: 0.3708 - accuracy: 0.9047 - auc: 0.9040 - val_loss: 0.4950 - val_accuracy: 0.7969 - val_auc: 0.8411 - 140s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "15/15 - 140s - loss: 0.3679 - accuracy: 0.8940 - auc: 0.9135 - val_loss: 0.4715 - val_accuracy: 0.8281 - val_auc: 0.8196 - 140s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "15/15 - 139s - loss: 0.3605 - accuracy: 0.9015 - auc: 0.9154 - val_loss: 0.4424 - val_accuracy: 0.8438 - val_auc: 0.8401 - 139s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "15/15 - 137s - loss: 0.3783 - accuracy: 0.8972 - auc: 0.9057 - val_loss: 0.4400 - val_accuracy: 0.8438 - val_auc: 0.8486 - 137s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "15/15 - 137s - loss: 0.3255 - accuracy: 0.9208 - auc: 0.9299 - val_loss: 0.5240 - val_accuracy: 0.7969 - val_auc: 0.8374 - 137s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "15/15 - 137s - loss: 0.3324 - accuracy: 0.9165 - auc: 0.9233 - val_loss: 0.4503 - val_accuracy: 0.8281 - val_auc: 0.8503 - 137s/epoch - 9s/step\n",
            "Epoch 77/150\n",
            "15/15 - 139s - loss: 0.3089 - accuracy: 0.9336 - auc: 0.9339 - val_loss: 0.4380 - val_accuracy: 0.8438 - val_auc: 0.8716 - 139s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "15/15 - 139s - loss: 0.3341 - accuracy: 0.9176 - auc: 0.9202 - val_loss: 0.5343 - val_accuracy: 0.7812 - val_auc: 0.8254 - 139s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "15/15 - 139s - loss: 0.3317 - accuracy: 0.9165 - auc: 0.9230 - val_loss: 0.4488 - val_accuracy: 0.8125 - val_auc: 0.8723 - 139s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "15/15 - 139s - loss: 0.3547 - accuracy: 0.9133 - auc: 0.9097 - val_loss: 0.4088 - val_accuracy: 0.8438 - val_auc: 0.8862 - 139s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "15/15 - 137s - loss: 0.3057 - accuracy: 0.9283 - auc: 0.9324 - val_loss: 0.3546 - val_accuracy: 0.8438 - val_auc: 0.9043 - 137s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "15/15 - 136s - loss: 0.3486 - accuracy: 0.9004 - auc: 0.9188 - val_loss: 0.5098 - val_accuracy: 0.7969 - val_auc: 0.8408 - 136s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "15/15 - 136s - loss: 0.2950 - accuracy: 0.9293 - auc: 0.9407 - val_loss: 0.5662 - val_accuracy: 0.7812 - val_auc: 0.8086 - 136s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "15/15 - 136s - loss: 0.3255 - accuracy: 0.9154 - auc: 0.9244 - val_loss: 0.5938 - val_accuracy: 0.7656 - val_auc: 0.7974 - 136s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "15/15 - 136s - loss: 0.2860 - accuracy: 0.9315 - auc: 0.9483 - val_loss: 0.5881 - val_accuracy: 0.7656 - val_auc: 0.8413 - 136s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "15/15 - 137s - loss: 0.2813 - accuracy: 0.9390 - auc: 0.9425 - val_loss: 0.6068 - val_accuracy: 0.7656 - val_auc: 0.7971 - 137s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "15/15 - 137s - loss: 0.2649 - accuracy: 0.9443 - auc: 0.9501 - val_loss: 0.5130 - val_accuracy: 0.8125 - val_auc: 0.8792 - 137s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "15/15 - 136s - loss: 0.2859 - accuracy: 0.9358 - auc: 0.9385 - val_loss: 0.4906 - val_accuracy: 0.8125 - val_auc: 0.8608 - 136s/epoch - 9s/step\n",
            "Epoch 89/150\n",
            "15/15 - 136s - loss: 0.2573 - accuracy: 0.9422 - auc: 0.9525 - val_loss: 0.4156 - val_accuracy: 0.8594 - val_auc: 0.8909 - 136s/epoch - 9s/step\n",
            "Epoch 90/150\n",
            "15/15 - 136s - loss: 0.2806 - accuracy: 0.9368 - auc: 0.9359 - val_loss: 0.5428 - val_accuracy: 0.7969 - val_auc: 0.8704 - 136s/epoch - 9s/step\n",
            "Epoch 91/150\n",
            "15/15 - 136s - loss: 0.2861 - accuracy: 0.9336 - auc: 0.9372 - val_loss: 0.4414 - val_accuracy: 0.8438 - val_auc: 0.8799 - 136s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "15/15 - 136s - loss: 0.2824 - accuracy: 0.9368 - auc: 0.9376 - val_loss: 0.4806 - val_accuracy: 0.7812 - val_auc: 0.8970 - 136s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "15/15 - 136s - loss: 0.2717 - accuracy: 0.9379 - auc: 0.9430 - val_loss: 0.3897 - val_accuracy: 0.8750 - val_auc: 0.9224 - 136s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "15/15 - 137s - loss: 0.2593 - accuracy: 0.9433 - auc: 0.9484 - val_loss: 0.3920 - val_accuracy: 0.8594 - val_auc: 0.9058 - 137s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "15/15 - 137s - loss: 0.2533 - accuracy: 0.9486 - auc: 0.9499 - val_loss: 0.3431 - val_accuracy: 0.8750 - val_auc: 0.9412 - 137s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "15/15 - 136s - loss: 0.2781 - accuracy: 0.9347 - auc: 0.9371 - val_loss: 0.4395 - val_accuracy: 0.8438 - val_auc: 0.8767 - 136s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "15/15 - 136s - loss: 0.2663 - accuracy: 0.9400 - auc: 0.9418 - val_loss: 0.4647 - val_accuracy: 0.8281 - val_auc: 0.8792 - 136s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "15/15 - 136s - loss: 0.2686 - accuracy: 0.9390 - auc: 0.9424 - val_loss: 0.4814 - val_accuracy: 0.8125 - val_auc: 0.8728 - 136s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "15/15 - 136s - loss: 0.2211 - accuracy: 0.9529 - auc: 0.9653 - val_loss: 0.4778 - val_accuracy: 0.8125 - val_auc: 0.8887 - 136s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "15/15 - 135s - loss: 0.2162 - accuracy: 0.9593 - auc: 0.9655 - val_loss: 0.5647 - val_accuracy: 0.7812 - val_auc: 0.8320 - 135s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "15/15 - 135s - loss: 0.2087 - accuracy: 0.9615 - auc: 0.9677 - val_loss: 0.4679 - val_accuracy: 0.8281 - val_auc: 0.8445 - 135s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "15/15 - 135s - loss: 0.2212 - accuracy: 0.9561 - auc: 0.9605 - val_loss: 0.5273 - val_accuracy: 0.8125 - val_auc: 0.8389 - 135s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "15/15 - 135s - loss: 0.2143 - accuracy: 0.9561 - auc: 0.9645 - val_loss: 0.5358 - val_accuracy: 0.8125 - val_auc: 0.8345 - 135s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "15/15 - 136s - loss: 0.2220 - accuracy: 0.9529 - auc: 0.9605 - val_loss: 0.4903 - val_accuracy: 0.8281 - val_auc: 0.8540 - 136s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "15/15 - 136s - loss: 0.2533 - accuracy: 0.9379 - auc: 0.9476 - val_loss: 0.5913 - val_accuracy: 0.7969 - val_auc: 0.7905 - 136s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "15/15 - 135s - loss: 0.2324 - accuracy: 0.9475 - auc: 0.9586 - val_loss: 0.6450 - val_accuracy: 0.7500 - val_auc: 0.7852 - 135s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "15/15 - 135s - loss: 0.2233 - accuracy: 0.9540 - auc: 0.9536 - val_loss: 0.6090 - val_accuracy: 0.7656 - val_auc: 0.8225 - 135s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "15/15 - 136s - loss: 0.2135 - accuracy: 0.9561 - auc: 0.9605 - val_loss: 0.6237 - val_accuracy: 0.7812 - val_auc: 0.7866 - 136s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "15/15 - 135s - loss: 0.2291 - accuracy: 0.9486 - auc: 0.9548 - val_loss: 0.6239 - val_accuracy: 0.7812 - val_auc: 0.7935 - 135s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "15/15 - 135s - loss: 0.1978 - accuracy: 0.9625 - auc: 0.9680 - val_loss: 0.6108 - val_accuracy: 0.7812 - val_auc: 0.8057 - 135s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "15/15 - 136s - loss: 0.1861 - accuracy: 0.9690 - auc: 0.9685 - val_loss: 0.5645 - val_accuracy: 0.7812 - val_auc: 0.8472 - 136s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "15/15 - 136s - loss: 0.2105 - accuracy: 0.9550 - auc: 0.9646 - val_loss: 0.5764 - val_accuracy: 0.7969 - val_auc: 0.8472 - 136s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "15/15 - 135s - loss: 0.2119 - accuracy: 0.9540 - auc: 0.9629 - val_loss: 0.4917 - val_accuracy: 0.8438 - val_auc: 0.8274 - 135s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "15/15 - 137s - loss: 0.2079 - accuracy: 0.9529 - auc: 0.9598 - val_loss: 0.5387 - val_accuracy: 0.8125 - val_auc: 0.8557 - 137s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "15/15 - 136s - loss: 0.2286 - accuracy: 0.9475 - auc: 0.9546 - val_loss: 0.5685 - val_accuracy: 0.7969 - val_auc: 0.8079 - 136s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "15/15 - 136s - loss: 0.2177 - accuracy: 0.9529 - auc: 0.9572 - val_loss: 0.6415 - val_accuracy: 0.7812 - val_auc: 0.7878 - 136s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "15/15 - 135s - loss: 0.1962 - accuracy: 0.9647 - auc: 0.9667 - val_loss: 0.6955 - val_accuracy: 0.7500 - val_auc: 0.8230 - 135s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "15/15 - 136s - loss: 0.1956 - accuracy: 0.9615 - auc: 0.9627 - val_loss: 0.7604 - val_accuracy: 0.7344 - val_auc: 0.7688 - 136s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "15/15 - 136s - loss: 0.2137 - accuracy: 0.9518 - auc: 0.9582 - val_loss: 0.5202 - val_accuracy: 0.8125 - val_auc: 0.8403 - 136s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "15/15 - 135s - loss: 0.1809 - accuracy: 0.9636 - auc: 0.9677 - val_loss: 0.4921 - val_accuracy: 0.8125 - val_auc: 0.8516 - 135s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "15/15 - 134s - loss: 0.1669 - accuracy: 0.9700 - auc: 0.9745 - val_loss: 0.5545 - val_accuracy: 0.8125 - val_auc: 0.8242 - 134s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "15/15 - 134s - loss: 0.1839 - accuracy: 0.9636 - auc: 0.9668 - val_loss: 0.5804 - val_accuracy: 0.8125 - val_auc: 0.8167 - 134s/epoch - 9s/step\n",
            "Epoch 123/150\n",
            "15/15 - 135s - loss: 0.1675 - accuracy: 0.9700 - auc: 0.9730 - val_loss: 0.6495 - val_accuracy: 0.7812 - val_auc: 0.7871 - 135s/epoch - 9s/step\n",
            "Epoch 124/150\n",
            "15/15 - 134s - loss: 0.1918 - accuracy: 0.9582 - auc: 0.9677 - val_loss: 0.6686 - val_accuracy: 0.7656 - val_auc: 0.7832 - 134s/epoch - 9s/step\n",
            "Epoch 125/150\n",
            "15/15 - 134s - loss: 0.1978 - accuracy: 0.9550 - auc: 0.9642 - val_loss: 0.5903 - val_accuracy: 0.7969 - val_auc: 0.8191 - 134s/epoch - 9s/step\n",
            "Epoch 126/150\n",
            "15/15 - 134s - loss: 0.1611 - accuracy: 0.9700 - auc: 0.9757 - val_loss: 0.5079 - val_accuracy: 0.8281 - val_auc: 0.8635 - 134s/epoch - 9s/step\n",
            "Epoch 127/150\n",
            "15/15 - 134s - loss: 0.2032 - accuracy: 0.9582 - auc: 0.9582 - val_loss: 0.4892 - val_accuracy: 0.8438 - val_auc: 0.8643 - 134s/epoch - 9s/step\n",
            "Epoch 128/150\n",
            "15/15 - 134s - loss: 0.1881 - accuracy: 0.9582 - auc: 0.9657 - val_loss: 0.6407 - val_accuracy: 0.7812 - val_auc: 0.8149 - 134s/epoch - 9s/step\n",
            "Epoch 129/150\n",
            "15/15 - 135s - loss: 0.2326 - accuracy: 0.9433 - auc: 0.9477 - val_loss: 0.7137 - val_accuracy: 0.7656 - val_auc: 0.7776 - 135s/epoch - 9s/step\n",
            "Epoch 130/150\n",
            "15/15 - 134s - loss: 0.2567 - accuracy: 0.9358 - auc: 0.9425 - val_loss: 0.6351 - val_accuracy: 0.7969 - val_auc: 0.8076 - 134s/epoch - 9s/step\n",
            "Epoch 131/150\n",
            "15/15 - 134s - loss: 0.2193 - accuracy: 0.9475 - auc: 0.9534 - val_loss: 0.6077 - val_accuracy: 0.7969 - val_auc: 0.8467 - 134s/epoch - 9s/step\n",
            "Epoch 132/150\n",
            "15/15 - 134s - loss: 0.2139 - accuracy: 0.9507 - auc: 0.9536 - val_loss: 0.6603 - val_accuracy: 0.7812 - val_auc: 0.8027 - 134s/epoch - 9s/step\n",
            "Epoch 133/150\n",
            "15/15 - 135s - loss: 0.2359 - accuracy: 0.9443 - auc: 0.9493 - val_loss: 0.7163 - val_accuracy: 0.7656 - val_auc: 0.7781 - 135s/epoch - 9s/step\n",
            "Epoch 134/150\n",
            "15/15 - 135s - loss: 0.2151 - accuracy: 0.9443 - auc: 0.9586 - val_loss: 0.7423 - val_accuracy: 0.7656 - val_auc: 0.7659 - 135s/epoch - 9s/step\n",
            "Epoch 135/150\n",
            "15/15 - 135s - loss: 0.2442 - accuracy: 0.9390 - auc: 0.9437 - val_loss: 0.7601 - val_accuracy: 0.7500 - val_auc: 0.7689 - 135s/epoch - 9s/step\n",
            "Epoch 136/150\n",
            "15/15 - 136s - loss: 0.1640 - accuracy: 0.9668 - auc: 0.9732 - val_loss: 0.6337 - val_accuracy: 0.7812 - val_auc: 0.8257 - 136s/epoch - 9s/step\n",
            "Epoch 137/150\n",
            "15/15 - 134s - loss: 0.1644 - accuracy: 0.9690 - auc: 0.9720 - val_loss: 0.6428 - val_accuracy: 0.7969 - val_auc: 0.7991 - 134s/epoch - 9s/step\n",
            "Epoch 138/150\n",
            "15/15 - 135s - loss: 0.1739 - accuracy: 0.9636 - auc: 0.9700 - val_loss: 0.6568 - val_accuracy: 0.7812 - val_auc: 0.8179 - 135s/epoch - 9s/step\n",
            "Epoch 139/150\n",
            "15/15 - 136s - loss: 0.1837 - accuracy: 0.9636 - auc: 0.9641 - val_loss: 0.6021 - val_accuracy: 0.7656 - val_auc: 0.8308 - 136s/epoch - 9s/step\n",
            "Epoch 140/150\n",
            "15/15 - 136s - loss: 0.1603 - accuracy: 0.9700 - auc: 0.9737 - val_loss: 0.5933 - val_accuracy: 0.8125 - val_auc: 0.8220 - 136s/epoch - 9s/step\n",
            "Epoch 141/150\n",
            "15/15 - 136s - loss: 0.1622 - accuracy: 0.9690 - auc: 0.9720 - val_loss: 0.5614 - val_accuracy: 0.8281 - val_auc: 0.8352 - 136s/epoch - 9s/step\n",
            "Epoch 142/150\n",
            "15/15 - 135s - loss: 0.1499 - accuracy: 0.9732 - auc: 0.9776 - val_loss: 0.4544 - val_accuracy: 0.8594 - val_auc: 0.8669 - 135s/epoch - 9s/step\n",
            "Epoch 143/150\n",
            "15/15 - 134s - loss: 0.1239 - accuracy: 0.9807 - auc: 0.9851 - val_loss: 0.4350 - val_accuracy: 0.8594 - val_auc: 0.8669 - 134s/epoch - 9s/step\n",
            "Epoch 144/150\n",
            "15/15 - 135s - loss: 0.1156 - accuracy: 0.9818 - auc: 0.9875 - val_loss: 0.5282 - val_accuracy: 0.8281 - val_auc: 0.8611 - 135s/epoch - 9s/step\n",
            "Epoch 145/150\n",
            "15/15 - 135s - loss: 0.1494 - accuracy: 0.9722 - auc: 0.9734 - val_loss: 0.4736 - val_accuracy: 0.8281 - val_auc: 0.8843 - 135s/epoch - 9s/step\n",
            "Epoch 146/150\n",
            "15/15 - 135s - loss: 0.1233 - accuracy: 0.9797 - auc: 0.9834 - val_loss: 0.3195 - val_accuracy: 0.9062 - val_auc: 0.9138 - 135s/epoch - 9s/step\n",
            "Epoch 147/150\n",
            "15/15 - 135s - loss: 0.1464 - accuracy: 0.9743 - auc: 0.9730 - val_loss: 0.3245 - val_accuracy: 0.8906 - val_auc: 0.9253 - 135s/epoch - 9s/step\n",
            "Epoch 148/150\n",
            "15/15 - 135s - loss: 0.1592 - accuracy: 0.9647 - auc: 0.9735 - val_loss: 0.4576 - val_accuracy: 0.8594 - val_auc: 0.8862 - 135s/epoch - 9s/step\n",
            "Epoch 149/150\n",
            "15/15 - 134s - loss: 0.1352 - accuracy: 0.9775 - auc: 0.9782 - val_loss: 0.4980 - val_accuracy: 0.8438 - val_auc: 0.8801 - 134s/epoch - 9s/step\n",
            "Epoch 150/150\n",
            "15/15 - 135s - loss: 0.1502 - accuracy: 0.9711 - auc: 0.9751 - val_loss: 0.6709 - val_accuracy: 0.7656 - val_auc: 0.8015 - 135s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [00:51<00:00,  4.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.771\n",
            "Recall: 0.8632\n",
            "Threshold: 0.2695\n",
            "F1 Score: 0.8145\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n\\n\\n'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_Name='Pretrained plus 2nd layer Model Saved'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 3rd layer Model Saved'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history3 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history3.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2xzmvOv2UgJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_Mpc8PF2Uz3"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1.history['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2.history['accuracy'], label='Layer 2 accuracy')\n",
        "plt.plot(history3.history['accuracy'], label='Layer 3 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 3 Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyOrF9_A2Uz3"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3.history['val_accuracy'], label='Layer 3 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 3 Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PKC32ch2Uz4"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.plot(history1.history['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2.history['loss'], label='Layer 2 Loss')\n",
        "plt.plot(history3.history['loss'], label='Layer 3 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 3 Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXtJBs0N2Uz4"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1.history['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3.history['val_loss'], label='Layer 3 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 3 Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGgRanbx2Uz4"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.plot(history1.history['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2.history['auc'], label='Layer 2 Auc')\n",
        "plt.plot(history3.history['auc'], label='Layer 3 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 3 Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3554ABW2Uz4"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1.history['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2.history['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3.history['val_auc'], label='Layer 3 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 3 Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jqtxe_BEOzZ1",
        "outputId": "f98d0187-ca20-4860-b767-5297a6f4c443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_6 (Sequential)   (None, 2)                 74973830  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,974,984\n",
            "Trainable params: 51,385,480\n",
            "Non-trainable params: 23,589,504\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.54636, saving model to Cascade all Model Layers Graph/2022-08-25_10:49:19-model.hdf5\n",
            "15/15 - 276s - loss: 0.6284 - accuracy: 0.7377 - auc: 0.7635 - val_loss: 0.5464 - val_accuracy: 0.8438 - val_auc: 0.8525 - 276s/epoch - 18s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.54636\n",
            "15/15 - 142s - loss: 0.6183 - accuracy: 0.7355 - auc: 0.7684 - val_loss: 0.6524 - val_accuracy: 0.6406 - val_auc: 0.7620 - 142s/epoch - 9s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.54636\n",
            "15/15 - 139s - loss: 0.6250 - accuracy: 0.7366 - auc: 0.7659 - val_loss: 0.6663 - val_accuracy: 0.6562 - val_auc: 0.7686 - 139s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss improved from 0.54636 to 0.47073, saving model to Cascade all Model Layers Graph/2022-08-25_10:49:19-model.hdf5\n",
            "15/15 - 142s - loss: 0.6262 - accuracy: 0.7366 - auc: 0.7663 - val_loss: 0.4707 - val_accuracy: 0.7969 - val_auc: 0.8730 - 142s/epoch - 9s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.47073\n",
            "15/15 - 138s - loss: 0.5953 - accuracy: 0.7420 - auc: 0.7867 - val_loss: 0.5305 - val_accuracy: 0.7656 - val_auc: 0.8467 - 138s/epoch - 9s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.47073\n",
            "15/15 - 137s - loss: 0.6369 - accuracy: 0.7281 - auc: 0.7581 - val_loss: 0.5234 - val_accuracy: 0.7656 - val_auc: 0.8728 - 137s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss improved from 0.47073 to 0.44573, saving model to Cascade all Model Layers Graph/2022-08-25_10:49:19-model.hdf5\n",
            "15/15 - 141s - loss: 0.5980 - accuracy: 0.7430 - auc: 0.7867 - val_loss: 0.4457 - val_accuracy: 0.8438 - val_auc: 0.8481 - 141s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.44573\n",
            "15/15 - 142s - loss: 0.5708 - accuracy: 0.7698 - auc: 0.8013 - val_loss: 0.6989 - val_accuracy: 0.6875 - val_auc: 0.7126 - 142s/epoch - 9s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.44573\n",
            "15/15 - 140s - loss: 0.6128 - accuracy: 0.7334 - auc: 0.7683 - val_loss: 0.4677 - val_accuracy: 0.7969 - val_auc: 0.8611 - 140s/epoch - 9s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.44573\n",
            "15/15 - 140s - loss: 0.6013 - accuracy: 0.7430 - auc: 0.7807 - val_loss: 0.4833 - val_accuracy: 0.7812 - val_auc: 0.8528 - 140s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.44573\n",
            "15/15 - 140s - loss: 0.6130 - accuracy: 0.7377 - auc: 0.7699 - val_loss: 0.4912 - val_accuracy: 0.7812 - val_auc: 0.8687 - 140s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.44573\n",
            "15/15 - 139s - loss: 0.6050 - accuracy: 0.7420 - auc: 0.7764 - val_loss: 0.5824 - val_accuracy: 0.7188 - val_auc: 0.8022 - 139s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.44573\n",
            "15/15 - 137s - loss: 0.6187 - accuracy: 0.7291 - auc: 0.7640 - val_loss: 0.5946 - val_accuracy: 0.6875 - val_auc: 0.8044 - 137s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.44573\n",
            "15/15 - 137s - loss: 0.6206 - accuracy: 0.7227 - auc: 0.7674 - val_loss: 0.4846 - val_accuracy: 0.7969 - val_auc: 0.8557 - 137s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.44573\n",
            "15/15 - 137s - loss: 0.6205 - accuracy: 0.7420 - auc: 0.7681 - val_loss: 0.5896 - val_accuracy: 0.7188 - val_auc: 0.7888 - 137s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.44573\n",
            "15/15 - 137s - loss: 0.5948 - accuracy: 0.7430 - auc: 0.7871 - val_loss: 0.5239 - val_accuracy: 0.7500 - val_auc: 0.8474 - 137s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.44573\n",
            "15/15 - 137s - loss: 0.5973 - accuracy: 0.7366 - auc: 0.7815 - val_loss: 0.5283 - val_accuracy: 0.7500 - val_auc: 0.8376 - 137s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.44573\n",
            "15/15 - 137s - loss: 0.6072 - accuracy: 0.7409 - auc: 0.7790 - val_loss: 0.5104 - val_accuracy: 0.7656 - val_auc: 0.8450 - 137s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.44573\n",
            "15/15 - 137s - loss: 0.6068 - accuracy: 0.7420 - auc: 0.7758 - val_loss: 0.5455 - val_accuracy: 0.7500 - val_auc: 0.8201 - 137s/epoch - 9s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.44573\n",
            "15/15 - 135s - loss: 0.6083 - accuracy: 0.7302 - auc: 0.7741 - val_loss: 0.4769 - val_accuracy: 0.8281 - val_auc: 0.8396 - 135s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.44573\n",
            "15/15 - 136s - loss: 0.6044 - accuracy: 0.7323 - auc: 0.7781 - val_loss: 0.5369 - val_accuracy: 0.7656 - val_auc: 0.8313 - 136s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.44573\n",
            "15/15 - 135s - loss: 0.5866 - accuracy: 0.7495 - auc: 0.7921 - val_loss: 0.5859 - val_accuracy: 0.7031 - val_auc: 0.7988 - 135s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.44573\n",
            "15/15 - 135s - loss: 0.6173 - accuracy: 0.7420 - auc: 0.7710 - val_loss: 0.4632 - val_accuracy: 0.8125 - val_auc: 0.8472 - 135s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.44573\n",
            "15/15 - 136s - loss: 0.5848 - accuracy: 0.7580 - auc: 0.7941 - val_loss: 0.6732 - val_accuracy: 0.6875 - val_auc: 0.7405 - 136s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.44573\n",
            "15/15 - 136s - loss: 0.6158 - accuracy: 0.7334 - auc: 0.7749 - val_loss: 0.5035 - val_accuracy: 0.7969 - val_auc: 0.8196 - 136s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.44573\n",
            "15/15 - 136s - loss: 0.6027 - accuracy: 0.7420 - auc: 0.7791 - val_loss: 0.5254 - val_accuracy: 0.7500 - val_auc: 0.8774 - 136s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.44573\n",
            "15/15 - 135s - loss: 0.6500 - accuracy: 0.7206 - auc: 0.7423 - val_loss: 0.5632 - val_accuracy: 0.7656 - val_auc: 0.7939 - 135s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.44573\n",
            "15/15 - 135s - loss: 0.5800 - accuracy: 0.7602 - auc: 0.7921 - val_loss: 0.5450 - val_accuracy: 0.7344 - val_auc: 0.8364 - 135s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.44573\n",
            "15/15 - 134s - loss: 0.5975 - accuracy: 0.7345 - auc: 0.7771 - val_loss: 0.5145 - val_accuracy: 0.7656 - val_auc: 0.8523 - 134s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.44573\n",
            "15/15 - 134s - loss: 0.6096 - accuracy: 0.7398 - auc: 0.7724 - val_loss: 0.5019 - val_accuracy: 0.7812 - val_auc: 0.8711 - 134s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss improved from 0.44573 to 0.42221, saving model to Cascade all Model Layers Graph/2022-08-25_10:49:19-model.hdf5\n",
            "15/15 - 137s - loss: 0.6082 - accuracy: 0.7334 - auc: 0.7728 - val_loss: 0.4222 - val_accuracy: 0.8594 - val_auc: 0.8657 - 137s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.6212 - accuracy: 0.7334 - auc: 0.7641 - val_loss: 0.4489 - val_accuracy: 0.8281 - val_auc: 0.8701 - 135s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5780 - accuracy: 0.7645 - auc: 0.7961 - val_loss: 0.4643 - val_accuracy: 0.8125 - val_auc: 0.8586 - 134s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.6129 - accuracy: 0.7323 - auc: 0.7700 - val_loss: 0.6393 - val_accuracy: 0.7188 - val_auc: 0.7559 - 135s/epoch - 9s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5688 - accuracy: 0.7602 - auc: 0.8018 - val_loss: 0.4464 - val_accuracy: 0.8438 - val_auc: 0.8638 - 134s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6008 - accuracy: 0.7409 - auc: 0.7790 - val_loss: 0.6072 - val_accuracy: 0.7344 - val_auc: 0.7827 - 134s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6364 - accuracy: 0.7152 - auc: 0.7522 - val_loss: 0.4840 - val_accuracy: 0.7656 - val_auc: 0.8887 - 134s/epoch - 9s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6277 - accuracy: 0.7291 - auc: 0.7562 - val_loss: 0.4234 - val_accuracy: 0.8594 - val_auc: 0.8679 - 134s/epoch - 9s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.6130 - accuracy: 0.7430 - auc: 0.7722 - val_loss: 0.5057 - val_accuracy: 0.7500 - val_auc: 0.8835 - 135s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5924 - accuracy: 0.7495 - auc: 0.7829 - val_loss: 0.4800 - val_accuracy: 0.7812 - val_auc: 0.8704 - 135s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5977 - accuracy: 0.7366 - auc: 0.7771 - val_loss: 0.5241 - val_accuracy: 0.7656 - val_auc: 0.8521 - 135s/epoch - 9s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5913 - accuracy: 0.7559 - auc: 0.7856 - val_loss: 0.4961 - val_accuracy: 0.7812 - val_auc: 0.8440 - 135s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5773 - accuracy: 0.7655 - auc: 0.7937 - val_loss: 0.4737 - val_accuracy: 0.8125 - val_auc: 0.8333 - 134s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5976 - accuracy: 0.7484 - auc: 0.7809 - val_loss: 0.5005 - val_accuracy: 0.7812 - val_auc: 0.8137 - 134s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5891 - accuracy: 0.7505 - auc: 0.7872 - val_loss: 0.5792 - val_accuracy: 0.7188 - val_auc: 0.7859 - 134s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5955 - accuracy: 0.7441 - auc: 0.7822 - val_loss: 0.4561 - val_accuracy: 0.8281 - val_auc: 0.8362 - 134s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6133 - accuracy: 0.7484 - auc: 0.7676 - val_loss: 0.4825 - val_accuracy: 0.8281 - val_auc: 0.8193 - 134s/epoch - 9s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5898 - accuracy: 0.7527 - auc: 0.7868 - val_loss: 0.5294 - val_accuracy: 0.7344 - val_auc: 0.8447 - 135s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6010 - accuracy: 0.7441 - auc: 0.7747 - val_loss: 0.4569 - val_accuracy: 0.8281 - val_auc: 0.8511 - 134s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5585 - accuracy: 0.7666 - auc: 0.8115 - val_loss: 0.6031 - val_accuracy: 0.7500 - val_auc: 0.7817 - 134s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6155 - accuracy: 0.7452 - auc: 0.7700 - val_loss: 0.6531 - val_accuracy: 0.7188 - val_auc: 0.7236 - 134s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.42221\n",
            "15/15 - 136s - loss: 0.5978 - accuracy: 0.7495 - auc: 0.7829 - val_loss: 0.6523 - val_accuracy: 0.6406 - val_auc: 0.7974 - 136s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.42221\n",
            "15/15 - 137s - loss: 0.5698 - accuracy: 0.7602 - auc: 0.8022 - val_loss: 0.4949 - val_accuracy: 0.7656 - val_auc: 0.8567 - 137s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.42221\n",
            "15/15 - 137s - loss: 0.5899 - accuracy: 0.7559 - auc: 0.7871 - val_loss: 0.5538 - val_accuracy: 0.7500 - val_auc: 0.8042 - 137s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.42221\n",
            "15/15 - 136s - loss: 0.5919 - accuracy: 0.7334 - auc: 0.7869 - val_loss: 0.4490 - val_accuracy: 0.8438 - val_auc: 0.8464 - 136s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.42221\n",
            "15/15 - 137s - loss: 0.6046 - accuracy: 0.7441 - auc: 0.7732 - val_loss: 0.4715 - val_accuracy: 0.7812 - val_auc: 0.8752 - 137s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.42221\n",
            "15/15 - 136s - loss: 0.6081 - accuracy: 0.7313 - auc: 0.7748 - val_loss: 0.4665 - val_accuracy: 0.8281 - val_auc: 0.8457 - 136s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.42221\n",
            "15/15 - 136s - loss: 0.5685 - accuracy: 0.7591 - auc: 0.7996 - val_loss: 0.4528 - val_accuracy: 0.8281 - val_auc: 0.8574 - 136s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5813 - accuracy: 0.7559 - auc: 0.7922 - val_loss: 0.4631 - val_accuracy: 0.7969 - val_auc: 0.8730 - 135s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5819 - accuracy: 0.7505 - auc: 0.7923 - val_loss: 0.6762 - val_accuracy: 0.6406 - val_auc: 0.7327 - 134s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5941 - accuracy: 0.7527 - auc: 0.7818 - val_loss: 0.4656 - val_accuracy: 0.8125 - val_auc: 0.8828 - 134s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5935 - accuracy: 0.7473 - auc: 0.7810 - val_loss: 0.5802 - val_accuracy: 0.7031 - val_auc: 0.8230 - 132s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5634 - accuracy: 0.7677 - auc: 0.8041 - val_loss: 0.4624 - val_accuracy: 0.8125 - val_auc: 0.8679 - 132s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.6068 - accuracy: 0.7377 - auc: 0.7761 - val_loss: 0.4611 - val_accuracy: 0.8125 - val_auc: 0.8752 - 132s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.6046 - accuracy: 0.7388 - auc: 0.7755 - val_loss: 0.4770 - val_accuracy: 0.8125 - val_auc: 0.8301 - 132s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.6244 - accuracy: 0.7398 - auc: 0.7577 - val_loss: 0.6876 - val_accuracy: 0.6875 - val_auc: 0.7356 - 132s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.5932 - accuracy: 0.7463 - auc: 0.7835 - val_loss: 0.5783 - val_accuracy: 0.7031 - val_auc: 0.8206 - 131s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.6294 - accuracy: 0.7430 - auc: 0.7530 - val_loss: 0.4590 - val_accuracy: 0.8125 - val_auc: 0.8655 - 132s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6085 - accuracy: 0.7345 - auc: 0.7700 - val_loss: 0.4335 - val_accuracy: 0.8281 - val_auc: 0.8625 - 134s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.5839 - accuracy: 0.7495 - auc: 0.7893 - val_loss: 0.5083 - val_accuracy: 0.7500 - val_auc: 0.8789 - 131s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5997 - accuracy: 0.7441 - auc: 0.7770 - val_loss: 0.4485 - val_accuracy: 0.8125 - val_auc: 0.8689 - 132s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5734 - accuracy: 0.7559 - auc: 0.7937 - val_loss: 0.4786 - val_accuracy: 0.8125 - val_auc: 0.8577 - 132s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5652 - accuracy: 0.7548 - auc: 0.8030 - val_loss: 0.4705 - val_accuracy: 0.8125 - val_auc: 0.8669 - 134s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.6004 - accuracy: 0.7430 - auc: 0.7733 - val_loss: 0.4583 - val_accuracy: 0.8125 - val_auc: 0.8684 - 135s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5779 - accuracy: 0.7441 - auc: 0.7939 - val_loss: 0.4578 - val_accuracy: 0.8125 - val_auc: 0.8694 - 135s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.42221\n",
            "15/15 - 133s - loss: 0.5971 - accuracy: 0.7430 - auc: 0.7784 - val_loss: 0.4489 - val_accuracy: 0.8125 - val_auc: 0.8599 - 133s/epoch - 9s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.6017 - accuracy: 0.7441 - auc: 0.7755 - val_loss: 0.4692 - val_accuracy: 0.8125 - val_auc: 0.8601 - 132s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5784 - accuracy: 0.7441 - auc: 0.7916 - val_loss: 0.4766 - val_accuracy: 0.7812 - val_auc: 0.8708 - 132s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.42221\n",
            "15/15 - 133s - loss: 0.5840 - accuracy: 0.7516 - auc: 0.7869 - val_loss: 0.4742 - val_accuracy: 0.7812 - val_auc: 0.8726 - 133s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5828 - accuracy: 0.7430 - auc: 0.7854 - val_loss: 0.4479 - val_accuracy: 0.8281 - val_auc: 0.8621 - 134s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6012 - accuracy: 0.7334 - auc: 0.7748 - val_loss: 0.6728 - val_accuracy: 0.7031 - val_auc: 0.7651 - 134s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5879 - accuracy: 0.7355 - auc: 0.7823 - val_loss: 0.9007 - val_accuracy: 0.6094 - val_auc: 0.6116 - 135s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5784 - accuracy: 0.7505 - auc: 0.7938 - val_loss: 0.4465 - val_accuracy: 0.8281 - val_auc: 0.8672 - 135s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5698 - accuracy: 0.7527 - auc: 0.7990 - val_loss: 0.4508 - val_accuracy: 0.8125 - val_auc: 0.8638 - 135s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5792 - accuracy: 0.7602 - auc: 0.7913 - val_loss: 0.4653 - val_accuracy: 0.8125 - val_auc: 0.8655 - 135s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5967 - accuracy: 0.7505 - auc: 0.7762 - val_loss: 0.4715 - val_accuracy: 0.8125 - val_auc: 0.8508 - 135s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.6008 - accuracy: 0.7388 - auc: 0.7740 - val_loss: 0.5034 - val_accuracy: 0.7500 - val_auc: 0.8713 - 135s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5817 - accuracy: 0.7420 - auc: 0.7902 - val_loss: 0.5242 - val_accuracy: 0.7812 - val_auc: 0.8450 - 135s/epoch - 9s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5835 - accuracy: 0.7527 - auc: 0.7931 - val_loss: 0.4460 - val_accuracy: 0.8281 - val_auc: 0.8577 - 135s/epoch - 9s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5725 - accuracy: 0.7548 - auc: 0.7960 - val_loss: 0.4721 - val_accuracy: 0.7969 - val_auc: 0.8511 - 135s/epoch - 9s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5771 - accuracy: 0.7505 - auc: 0.7970 - val_loss: 0.5925 - val_accuracy: 0.6719 - val_auc: 0.8032 - 134s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6039 - accuracy: 0.7452 - auc: 0.7717 - val_loss: 0.5398 - val_accuracy: 0.7500 - val_auc: 0.8149 - 134s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5956 - accuracy: 0.7495 - auc: 0.7762 - val_loss: 0.4781 - val_accuracy: 0.7812 - val_auc: 0.8628 - 135s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.6119 - accuracy: 0.7452 - auc: 0.7673 - val_loss: 0.4724 - val_accuracy: 0.8125 - val_auc: 0.8345 - 135s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5891 - accuracy: 0.7484 - auc: 0.7838 - val_loss: 0.4829 - val_accuracy: 0.7969 - val_auc: 0.8455 - 135s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5905 - accuracy: 0.7559 - auc: 0.7782 - val_loss: 0.6542 - val_accuracy: 0.6562 - val_auc: 0.7700 - 135s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5787 - accuracy: 0.7473 - auc: 0.7923 - val_loss: 0.4766 - val_accuracy: 0.7969 - val_auc: 0.8657 - 134s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5650 - accuracy: 0.7537 - auc: 0.8041 - val_loss: 0.4665 - val_accuracy: 0.7812 - val_auc: 0.8660 - 132s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.5769 - accuracy: 0.7495 - auc: 0.7921 - val_loss: 0.6688 - val_accuracy: 0.6719 - val_auc: 0.7664 - 131s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.5659 - accuracy: 0.7580 - auc: 0.8012 - val_loss: 0.5087 - val_accuracy: 0.7656 - val_auc: 0.8125 - 131s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.6009 - accuracy: 0.7441 - auc: 0.7729 - val_loss: 0.4916 - val_accuracy: 0.8125 - val_auc: 0.8381 - 131s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.5892 - accuracy: 0.7420 - auc: 0.7828 - val_loss: 0.4516 - val_accuracy: 0.8125 - val_auc: 0.8643 - 131s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.42221\n",
            "15/15 - 133s - loss: 0.5818 - accuracy: 0.7516 - auc: 0.7883 - val_loss: 0.8435 - val_accuracy: 0.6250 - val_auc: 0.6726 - 133s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5781 - accuracy: 0.7602 - auc: 0.7922 - val_loss: 0.9271 - val_accuracy: 0.5938 - val_auc: 0.6013 - 134s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5697 - accuracy: 0.7388 - auc: 0.7980 - val_loss: 0.5274 - val_accuracy: 0.7969 - val_auc: 0.7969 - 134s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6003 - accuracy: 0.7409 - auc: 0.7760 - val_loss: 0.5303 - val_accuracy: 0.7969 - val_auc: 0.8157 - 134s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5934 - accuracy: 0.7388 - auc: 0.7802 - val_loss: 0.5424 - val_accuracy: 0.7344 - val_auc: 0.8259 - 132s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.42221\n",
            "15/15 - 133s - loss: 0.5696 - accuracy: 0.7527 - auc: 0.7982 - val_loss: 0.5249 - val_accuracy: 0.7656 - val_auc: 0.8306 - 133s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6073 - accuracy: 0.7345 - auc: 0.7706 - val_loss: 0.5357 - val_accuracy: 0.7500 - val_auc: 0.8220 - 134s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5696 - accuracy: 0.7612 - auc: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7656 - val_auc: 0.8315 - 135s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.5740 - accuracy: 0.7623 - auc: 0.7966 - val_loss: 0.5284 - val_accuracy: 0.7656 - val_auc: 0.8320 - 131s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5891 - accuracy: 0.7527 - auc: 0.7828 - val_loss: 0.5199 - val_accuracy: 0.7500 - val_auc: 0.8479 - 134s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5768 - accuracy: 0.7495 - auc: 0.7920 - val_loss: 0.4948 - val_accuracy: 0.7969 - val_auc: 0.8250 - 134s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5600 - accuracy: 0.7634 - auc: 0.8051 - val_loss: 0.9343 - val_accuracy: 0.5938 - val_auc: 0.5842 - 134s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.42221\n",
            "15/15 - 133s - loss: 0.5671 - accuracy: 0.7495 - auc: 0.8015 - val_loss: 0.9280 - val_accuracy: 0.5938 - val_auc: 0.5842 - 133s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.42221\n",
            "15/15 - 131s - loss: 0.6079 - accuracy: 0.7291 - auc: 0.7724 - val_loss: 0.8631 - val_accuracy: 0.5938 - val_auc: 0.6565 - 131s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.42221\n",
            "15/15 - 132s - loss: 0.5760 - accuracy: 0.7570 - auc: 0.7923 - val_loss: 0.4908 - val_accuracy: 0.7656 - val_auc: 0.8479 - 132s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.42221\n",
            "15/15 - 133s - loss: 0.5838 - accuracy: 0.7548 - auc: 0.7863 - val_loss: 0.4693 - val_accuracy: 0.8125 - val_auc: 0.8560 - 133s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5822 - accuracy: 0.7452 - auc: 0.7850 - val_loss: 0.4534 - val_accuracy: 0.8594 - val_auc: 0.8582 - 134s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.42221\n",
            "15/15 - 136s - loss: 0.5909 - accuracy: 0.7473 - auc: 0.7853 - val_loss: 0.5616 - val_accuracy: 0.7344 - val_auc: 0.8120 - 136s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5829 - accuracy: 0.7537 - auc: 0.7824 - val_loss: 0.4996 - val_accuracy: 0.7812 - val_auc: 0.8491 - 135s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5762 - accuracy: 0.7559 - auc: 0.7909 - val_loss: 0.5183 - val_accuracy: 0.7656 - val_auc: 0.8599 - 135s/epoch - 9s/step\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5731 - accuracy: 0.7505 - auc: 0.7975 - val_loss: 0.4836 - val_accuracy: 0.7969 - val_auc: 0.8428 - 135s/epoch - 9s/step\n",
            "Epoch 124/150\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5963 - accuracy: 0.7420 - auc: 0.7793 - val_loss: 0.4577 - val_accuracy: 0.7969 - val_auc: 0.8420 - 135s/epoch - 9s/step\n",
            "Epoch 125/150\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5886 - accuracy: 0.7473 - auc: 0.7824 - val_loss: 0.5168 - val_accuracy: 0.7656 - val_auc: 0.8438 - 134s/epoch - 9s/step\n",
            "Epoch 126/150\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5675 - accuracy: 0.7591 - auc: 0.7977 - val_loss: 0.5284 - val_accuracy: 0.7500 - val_auc: 0.8132 - 134s/epoch - 9s/step\n",
            "Epoch 127/150\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.6018 - accuracy: 0.7355 - auc: 0.7728 - val_loss: 0.5116 - val_accuracy: 0.7812 - val_auc: 0.8345 - 134s/epoch - 9s/step\n",
            "Epoch 128/150\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5711 - accuracy: 0.7623 - auc: 0.7949 - val_loss: 0.5160 - val_accuracy: 0.7656 - val_auc: 0.8542 - 135s/epoch - 9s/step\n",
            "Epoch 129/150\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5523 - accuracy: 0.7623 - auc: 0.8097 - val_loss: 0.4787 - val_accuracy: 0.8281 - val_auc: 0.8298 - 135s/epoch - 9s/step\n",
            "Epoch 130/150\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5721 - accuracy: 0.7548 - auc: 0.7924 - val_loss: 0.5039 - val_accuracy: 0.7969 - val_auc: 0.8237 - 135s/epoch - 9s/step\n",
            "Epoch 131/150\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.42221\n",
            "15/15 - 134s - loss: 0.5852 - accuracy: 0.7452 - auc: 0.7858 - val_loss: 0.5516 - val_accuracy: 0.7500 - val_auc: 0.8022 - 134s/epoch - 9s/step\n",
            "Epoch 132/150\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.42221\n",
            "15/15 - 135s - loss: 0.5953 - accuracy: 0.7452 - auc: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7969 - val_auc: 0.8186 - 135s/epoch - 9s/step\n",
            "Epoch 133/150\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.42221\n",
            "15/15 - 137s - loss: 0.5769 - accuracy: 0.7527 - auc: 0.7904 - val_loss: 0.5164 - val_accuracy: 0.7500 - val_auc: 0.8528 - 137s/epoch - 9s/step\n",
            "Epoch 134/150\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5659 - accuracy: 0.7623 - auc: 0.8028 - val_loss: 0.5021 - val_accuracy: 0.7812 - val_auc: 0.8362 - 139s/epoch - 9s/step\n",
            "Epoch 135/150\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.42221\n",
            "15/15 - 138s - loss: 0.5696 - accuracy: 0.7570 - auc: 0.7925 - val_loss: 0.4755 - val_accuracy: 0.7812 - val_auc: 0.8425 - 138s/epoch - 9s/step\n",
            "Epoch 136/150\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.42221\n",
            "15/15 - 138s - loss: 0.5703 - accuracy: 0.7473 - auc: 0.7947 - val_loss: 0.5273 - val_accuracy: 0.7500 - val_auc: 0.8416 - 138s/epoch - 9s/step\n",
            "Epoch 137/150\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.42221\n",
            "15/15 - 138s - loss: 0.5651 - accuracy: 0.7441 - auc: 0.7984 - val_loss: 0.5274 - val_accuracy: 0.7656 - val_auc: 0.8464 - 138s/epoch - 9s/step\n",
            "Epoch 138/150\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.42221\n",
            "15/15 - 138s - loss: 0.5985 - accuracy: 0.7537 - auc: 0.7733 - val_loss: 0.4641 - val_accuracy: 0.7812 - val_auc: 0.8481 - 138s/epoch - 9s/step\n",
            "Epoch 139/150\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5694 - accuracy: 0.7623 - auc: 0.7943 - val_loss: 0.4689 - val_accuracy: 0.7812 - val_auc: 0.8589 - 139s/epoch - 9s/step\n",
            "Epoch 140/150\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5724 - accuracy: 0.7612 - auc: 0.7949 - val_loss: 0.5060 - val_accuracy: 0.7656 - val_auc: 0.8638 - 139s/epoch - 9s/step\n",
            "Epoch 141/150\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5425 - accuracy: 0.7623 - auc: 0.8151 - val_loss: 0.4768 - val_accuracy: 0.7969 - val_auc: 0.8591 - 139s/epoch - 9s/step\n",
            "Epoch 142/150\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5432 - accuracy: 0.7741 - auc: 0.8155 - val_loss: 0.4997 - val_accuracy: 0.7812 - val_auc: 0.8276 - 139s/epoch - 9s/step\n",
            "Epoch 143/150\n",
            "\n",
            "Epoch 143: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5774 - accuracy: 0.7591 - auc: 0.7866 - val_loss: 0.5920 - val_accuracy: 0.7500 - val_auc: 0.7842 - 139s/epoch - 9s/step\n",
            "Epoch 144/150\n",
            "\n",
            "Epoch 144: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5751 - accuracy: 0.7537 - auc: 0.7925 - val_loss: 0.4940 - val_accuracy: 0.7812 - val_auc: 0.8491 - 139s/epoch - 9s/step\n",
            "Epoch 145/150\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5791 - accuracy: 0.7570 - auc: 0.7842 - val_loss: 0.5806 - val_accuracy: 0.7031 - val_auc: 0.8035 - 139s/epoch - 9s/step\n",
            "Epoch 146/150\n",
            "\n",
            "Epoch 146: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5976 - accuracy: 0.7452 - auc: 0.7755 - val_loss: 0.4583 - val_accuracy: 0.8125 - val_auc: 0.8635 - 139s/epoch - 9s/step\n",
            "Epoch 147/150\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.42221\n",
            "15/15 - 139s - loss: 0.5682 - accuracy: 0.7441 - auc: 0.7980 - val_loss: 0.4525 - val_accuracy: 0.8281 - val_auc: 0.8484 - 139s/epoch - 9s/step\n",
            "Epoch 148/150\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.42221\n",
            "15/15 - 138s - loss: 0.5772 - accuracy: 0.7516 - auc: 0.7916 - val_loss: 0.5572 - val_accuracy: 0.7188 - val_auc: 0.7976 - 138s/epoch - 9s/step\n",
            "Epoch 149/150\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.42221\n",
            "15/15 - 138s - loss: 0.5779 - accuracy: 0.7559 - auc: 0.7905 - val_loss: 0.4587 - val_accuracy: 0.7969 - val_auc: 0.8584 - 138s/epoch - 9s/step\n",
            "Epoch 150/150\n",
            "\n",
            "Epoch 150: val_loss did not improve from 0.42221\n",
            "15/15 - 138s - loss: 0.5790 - accuracy: 0.7570 - auc: 0.7916 - val_loss: 0.5089 - val_accuracy: 0.7969 - val_auc: 0.8308 - 138s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [01:30<00:00,  2.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6887\n",
            "Recall: 0.8889\n",
            "Threshold: 0.2769\n",
            "F1 Score: 0.7761\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#prediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\n#print(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_Name='Pretrained plus 3rd layer Model Saved'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 4th layer Model Saved'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history4 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history4.history, timestamp,Model_Name)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6x9SC6HKU5J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU6K6XfE2JpC"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1.history['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2.history['accuracy'], label='Layer 2 accuracy')\n",
        "plt.plot(history3.history['accuracy'], label='Layer 3 accuracy')\n",
        "plt.plot(history4.history['accuracy'], label='Layer 4 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 4 Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rMdudZb2JpC"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3.history['val_accuracy'], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4.history['val_accuracy'], label='Layer 4 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 4 Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa36_lqN2JpC"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.plot(history1.history['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2.history['loss'], label='Layer 2 Loss')\n",
        "plt.plot(history3.history['loss'], label='Layer 3 Loss')\n",
        "plt.plot(history4.history['loss'], label='Layer 4 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 4 Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wak3QKRR2JpC"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1.history['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3.history['val_loss'], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4.history['val_loss'], label='Layer 4 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 4 Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhMVhSHv2JpD"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.plot(history1.history['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2.history['auc'], label='Layer 2 Auc')\n",
        "plt.plot(history3.history['auc'], label='Layer 3 Auc')\n",
        "plt.plot(history4.history['auc'], label='Layer 4 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 4 Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPCcXVa82JpD"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1.history['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2.history['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3.history['val_auc'], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4.history['val_auc'], label='Layer 4 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 4 Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJyaTQknOzZ1",
        "outputId": "75638db9-7b09-4578-c14f-1063ac1a6b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 2)                 74974984  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,976,138\n",
            "Trainable params: 51,386,378\n",
            "Non-trainable params: 23,589,760\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.67802, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 149s - loss: 0.6459 - accuracy: 0.7388 - auc: 0.7887 - val_loss: 0.6780 - val_accuracy: 0.6094 - val_auc: 0.6252 - 149s/epoch - 10s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.67802\n",
            "15/15 - 141s - loss: 0.6573 - accuracy: 0.7398 - auc: 0.7794 - val_loss: 0.6924 - val_accuracy: 0.6875 - val_auc: 0.7393 - 141s/epoch - 9s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss improved from 0.67802 to 0.53216, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 142s - loss: 0.6508 - accuracy: 0.7302 - auc: 0.7820 - val_loss: 0.5322 - val_accuracy: 0.8125 - val_auc: 0.8628 - 142s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.53216\n",
            "15/15 - 139s - loss: 0.6383 - accuracy: 0.7398 - auc: 0.7865 - val_loss: 0.8851 - val_accuracy: 0.6250 - val_auc: 0.6733 - 139s/epoch - 9s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss improved from 0.53216 to 0.52152, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 141s - loss: 0.6519 - accuracy: 0.7259 - auc: 0.7712 - val_loss: 0.5215 - val_accuracy: 0.8125 - val_auc: 0.8357 - 141s/epoch - 9s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.52152\n",
            "15/15 - 139s - loss: 0.6404 - accuracy: 0.7291 - auc: 0.7809 - val_loss: 0.7289 - val_accuracy: 0.6719 - val_auc: 0.7080 - 139s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.52152\n",
            "15/15 - 138s - loss: 0.6432 - accuracy: 0.7420 - auc: 0.7782 - val_loss: 0.6189 - val_accuracy: 0.7656 - val_auc: 0.7749 - 138s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss improved from 0.52152 to 0.51278, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 143s - loss: 0.6113 - accuracy: 0.7463 - auc: 0.7939 - val_loss: 0.5128 - val_accuracy: 0.7969 - val_auc: 0.8672 - 143s/epoch - 10s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss improved from 0.51278 to 0.50679, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 141s - loss: 0.6480 - accuracy: 0.7238 - auc: 0.7674 - val_loss: 0.5068 - val_accuracy: 0.7969 - val_auc: 0.8464 - 141s/epoch - 9s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.50679\n",
            "15/15 - 139s - loss: 0.6469 - accuracy: 0.7388 - auc: 0.7654 - val_loss: 0.5402 - val_accuracy: 0.7656 - val_auc: 0.8743 - 139s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.50679\n",
            "15/15 - 139s - loss: 0.6419 - accuracy: 0.7334 - auc: 0.7724 - val_loss: 0.7178 - val_accuracy: 0.6406 - val_auc: 0.7600 - 139s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss improved from 0.50679 to 0.49659, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 142s - loss: 0.6207 - accuracy: 0.7398 - auc: 0.7838 - val_loss: 0.4966 - val_accuracy: 0.7812 - val_auc: 0.8799 - 142s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.49659\n",
            "15/15 - 139s - loss: 0.5944 - accuracy: 0.7591 - auc: 0.8020 - val_loss: 0.5224 - val_accuracy: 0.7656 - val_auc: 0.8596 - 139s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.49659\n",
            "15/15 - 138s - loss: 0.6116 - accuracy: 0.7420 - auc: 0.7873 - val_loss: 0.5083 - val_accuracy: 0.7969 - val_auc: 0.8625 - 138s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.49659\n",
            "15/15 - 138s - loss: 0.6255 - accuracy: 0.7259 - auc: 0.7760 - val_loss: 0.6202 - val_accuracy: 0.7188 - val_auc: 0.7820 - 138s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.49659\n",
            "15/15 - 138s - loss: 0.6252 - accuracy: 0.7377 - auc: 0.7768 - val_loss: 0.7057 - val_accuracy: 0.7031 - val_auc: 0.7224 - 138s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.49659\n",
            "15/15 - 138s - loss: 0.6423 - accuracy: 0.7238 - auc: 0.7565 - val_loss: 0.7857 - val_accuracy: 0.5938 - val_auc: 0.6675 - 138s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.49659\n",
            "15/15 - 138s - loss: 0.6120 - accuracy: 0.7527 - auc: 0.7830 - val_loss: 0.5870 - val_accuracy: 0.7188 - val_auc: 0.8315 - 138s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss improved from 0.49659 to 0.46697, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 141s - loss: 0.6115 - accuracy: 0.7377 - auc: 0.7842 - val_loss: 0.4670 - val_accuracy: 0.8281 - val_auc: 0.8359 - 141s/epoch - 9s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.46697\n",
            "15/15 - 139s - loss: 0.6259 - accuracy: 0.7281 - auc: 0.7709 - val_loss: 0.5512 - val_accuracy: 0.7656 - val_auc: 0.8032 - 139s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.46697\n",
            "15/15 - 141s - loss: 0.6178 - accuracy: 0.7388 - auc: 0.7779 - val_loss: 0.6864 - val_accuracy: 0.6562 - val_auc: 0.7529 - 141s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.46697\n",
            "15/15 - 137s - loss: 0.6098 - accuracy: 0.7473 - auc: 0.7824 - val_loss: 0.5198 - val_accuracy: 0.7969 - val_auc: 0.8430 - 137s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.46697\n",
            "15/15 - 136s - loss: 0.6114 - accuracy: 0.7409 - auc: 0.7809 - val_loss: 0.4880 - val_accuracy: 0.8125 - val_auc: 0.8394 - 136s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.46697\n",
            "15/15 - 137s - loss: 0.6064 - accuracy: 0.7516 - auc: 0.7834 - val_loss: 0.6654 - val_accuracy: 0.7031 - val_auc: 0.7026 - 137s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.46697\n",
            "15/15 - 138s - loss: 0.6140 - accuracy: 0.7516 - auc: 0.7734 - val_loss: 0.5768 - val_accuracy: 0.7500 - val_auc: 0.7886 - 138s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.46697\n",
            "15/15 - 138s - loss: 0.6105 - accuracy: 0.7495 - auc: 0.7772 - val_loss: 0.7520 - val_accuracy: 0.6719 - val_auc: 0.6794 - 138s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss improved from 0.46697 to 0.46608, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 141s - loss: 0.6092 - accuracy: 0.7527 - auc: 0.7779 - val_loss: 0.4661 - val_accuracy: 0.8438 - val_auc: 0.8337 - 141s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.46608\n",
            "15/15 - 139s - loss: 0.6133 - accuracy: 0.7398 - auc: 0.7727 - val_loss: 0.5965 - val_accuracy: 0.7188 - val_auc: 0.7537 - 139s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5853 - accuracy: 0.7612 - auc: 0.7985 - val_loss: 0.6691 - val_accuracy: 0.6875 - val_auc: 0.7280 - 138s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.46608\n",
            "15/15 - 137s - loss: 0.6191 - accuracy: 0.7270 - auc: 0.7731 - val_loss: 0.5555 - val_accuracy: 0.7500 - val_auc: 0.8198 - 137s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6038 - accuracy: 0.7398 - auc: 0.7815 - val_loss: 0.5237 - val_accuracy: 0.7812 - val_auc: 0.8083 - 138s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6157 - accuracy: 0.7355 - auc: 0.7747 - val_loss: 0.5129 - val_accuracy: 0.7812 - val_auc: 0.8528 - 138s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6051 - accuracy: 0.7559 - auc: 0.7816 - val_loss: 0.4894 - val_accuracy: 0.8125 - val_auc: 0.8303 - 138s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6150 - accuracy: 0.7291 - auc: 0.7714 - val_loss: 0.4929 - val_accuracy: 0.7812 - val_auc: 0.8478 - 138s/epoch - 9s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6024 - accuracy: 0.7548 - auc: 0.7793 - val_loss: 0.5041 - val_accuracy: 0.7812 - val_auc: 0.8430 - 138s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.46608\n",
            "15/15 - 139s - loss: 0.6219 - accuracy: 0.7377 - auc: 0.7716 - val_loss: 0.5274 - val_accuracy: 0.7656 - val_auc: 0.8508 - 139s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.46608\n",
            "15/15 - 137s - loss: 0.6103 - accuracy: 0.7302 - auc: 0.7762 - val_loss: 0.5283 - val_accuracy: 0.7812 - val_auc: 0.8313 - 137s/epoch - 9s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6222 - accuracy: 0.7216 - auc: 0.7665 - val_loss: 0.5388 - val_accuracy: 0.7656 - val_auc: 0.8242 - 138s/epoch - 9s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6132 - accuracy: 0.7452 - auc: 0.7715 - val_loss: 0.4972 - val_accuracy: 0.7812 - val_auc: 0.8320 - 138s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5987 - accuracy: 0.7580 - auc: 0.7833 - val_loss: 0.5028 - val_accuracy: 0.7969 - val_auc: 0.8369 - 138s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6170 - accuracy: 0.7430 - auc: 0.7708 - val_loss: 0.5288 - val_accuracy: 0.7656 - val_auc: 0.8367 - 138s/epoch - 9s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5784 - accuracy: 0.7559 - auc: 0.7969 - val_loss: 0.4698 - val_accuracy: 0.8281 - val_auc: 0.8306 - 138s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6079 - accuracy: 0.7473 - auc: 0.7754 - val_loss: 0.4954 - val_accuracy: 0.7969 - val_auc: 0.8435 - 138s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.46608\n",
            "15/15 - 139s - loss: 0.6332 - accuracy: 0.7238 - auc: 0.7575 - val_loss: 0.6008 - val_accuracy: 0.6875 - val_auc: 0.8074 - 139s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.46608\n",
            "15/15 - 139s - loss: 0.6113 - accuracy: 0.7377 - auc: 0.7752 - val_loss: 0.4860 - val_accuracy: 0.7812 - val_auc: 0.8425 - 139s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5774 - accuracy: 0.7655 - auc: 0.7964 - val_loss: 0.4784 - val_accuracy: 0.7969 - val_auc: 0.8328 - 138s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5750 - accuracy: 0.7730 - auc: 0.7986 - val_loss: 0.5908 - val_accuracy: 0.7031 - val_auc: 0.7969 - 138s/epoch - 9s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6204 - accuracy: 0.7441 - auc: 0.7660 - val_loss: 0.6287 - val_accuracy: 0.6719 - val_auc: 0.7952 - 138s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.46608\n",
            "15/15 - 140s - loss: 0.5891 - accuracy: 0.7591 - auc: 0.7894 - val_loss: 0.6215 - val_accuracy: 0.6875 - val_auc: 0.8201 - 140s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.46608\n",
            "15/15 - 137s - loss: 0.5836 - accuracy: 0.7623 - auc: 0.7958 - val_loss: 0.8326 - val_accuracy: 0.6250 - val_auc: 0.6265 - 137s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5937 - accuracy: 0.7602 - auc: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7812 - val_auc: 0.8237 - 138s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6125 - accuracy: 0.7441 - auc: 0.7717 - val_loss: 0.4863 - val_accuracy: 0.8125 - val_auc: 0.8262 - 138s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6093 - accuracy: 0.7430 - auc: 0.7687 - val_loss: 0.6520 - val_accuracy: 0.6875 - val_auc: 0.7356 - 138s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6156 - accuracy: 0.7345 - auc: 0.7683 - val_loss: 0.5024 - val_accuracy: 0.7656 - val_auc: 0.8701 - 138s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6033 - accuracy: 0.7602 - auc: 0.7761 - val_loss: 0.5581 - val_accuracy: 0.7188 - val_auc: 0.8328 - 138s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5999 - accuracy: 0.7420 - auc: 0.7812 - val_loss: 0.5704 - val_accuracy: 0.7188 - val_auc: 0.8303 - 138s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6197 - accuracy: 0.7302 - auc: 0.7651 - val_loss: 0.5835 - val_accuracy: 0.7344 - val_auc: 0.7614 - 138s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5972 - accuracy: 0.7452 - auc: 0.7802 - val_loss: 0.4968 - val_accuracy: 0.7812 - val_auc: 0.8457 - 138s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6173 - accuracy: 0.7441 - auc: 0.7605 - val_loss: 0.4838 - val_accuracy: 0.7812 - val_auc: 0.8530 - 138s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.6123 - accuracy: 0.7248 - auc: 0.7705 - val_loss: 0.4707 - val_accuracy: 0.8281 - val_auc: 0.8313 - 138s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.46608\n",
            "15/15 - 138s - loss: 0.5909 - accuracy: 0.7420 - auc: 0.7864 - val_loss: 0.6935 - val_accuracy: 0.6250 - val_auc: 0.7231 - 138s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.46608\n",
            "15/15 - 139s - loss: 0.5814 - accuracy: 0.7537 - auc: 0.7900 - val_loss: 0.4810 - val_accuracy: 0.7812 - val_auc: 0.8765 - 139s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.46608\n",
            "15/15 - 136s - loss: 0.6013 - accuracy: 0.7452 - auc: 0.7791 - val_loss: 0.6599 - val_accuracy: 0.6875 - val_auc: 0.7166 - 136s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.46608\n",
            "15/15 - 136s - loss: 0.6058 - accuracy: 0.7495 - auc: 0.7756 - val_loss: 0.5144 - val_accuracy: 0.7812 - val_auc: 0.8091 - 136s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss improved from 0.46608 to 0.46235, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 138s - loss: 0.5975 - accuracy: 0.7516 - auc: 0.7778 - val_loss: 0.4623 - val_accuracy: 0.7969 - val_auc: 0.8667 - 138s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.46235\n",
            "15/15 - 136s - loss: 0.6021 - accuracy: 0.7345 - auc: 0.7790 - val_loss: 0.5405 - val_accuracy: 0.7500 - val_auc: 0.8445 - 136s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.46235\n",
            "15/15 - 136s - loss: 0.6118 - accuracy: 0.7366 - auc: 0.7717 - val_loss: 0.5655 - val_accuracy: 0.7188 - val_auc: 0.8235 - 136s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.46235\n",
            "15/15 - 137s - loss: 0.5767 - accuracy: 0.7473 - auc: 0.7967 - val_loss: 0.4966 - val_accuracy: 0.7656 - val_auc: 0.8569 - 137s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.5925 - accuracy: 0.7495 - auc: 0.7823 - val_loss: 0.5230 - val_accuracy: 0.7656 - val_auc: 0.8447 - 138s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.5919 - accuracy: 0.7505 - auc: 0.7855 - val_loss: 0.4942 - val_accuracy: 0.7656 - val_auc: 0.8621 - 138s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.6024 - accuracy: 0.7527 - auc: 0.7746 - val_loss: 0.4745 - val_accuracy: 0.7812 - val_auc: 0.8503 - 138s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.6244 - accuracy: 0.7366 - auc: 0.7602 - val_loss: 0.6910 - val_accuracy: 0.7031 - val_auc: 0.6877 - 138s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.6073 - accuracy: 0.7409 - auc: 0.7714 - val_loss: 0.5059 - val_accuracy: 0.7969 - val_auc: 0.8162 - 138s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.5823 - accuracy: 0.7430 - auc: 0.7916 - val_loss: 0.6109 - val_accuracy: 0.7188 - val_auc: 0.7495 - 138s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.6069 - accuracy: 0.7366 - auc: 0.7728 - val_loss: 0.5247 - val_accuracy: 0.7500 - val_auc: 0.8577 - 138s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.5947 - accuracy: 0.7591 - auc: 0.7816 - val_loss: 0.5210 - val_accuracy: 0.7344 - val_auc: 0.8677 - 138s/epoch - 9s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.5799 - accuracy: 0.7580 - auc: 0.7898 - val_loss: 0.5269 - val_accuracy: 0.7344 - val_auc: 0.8599 - 138s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.46235\n",
            "15/15 - 138s - loss: 0.5952 - accuracy: 0.7527 - auc: 0.7823 - val_loss: 0.4720 - val_accuracy: 0.7812 - val_auc: 0.8540 - 138s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss improved from 0.46235 to 0.45761, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 140s - loss: 0.5931 - accuracy: 0.7473 - auc: 0.7841 - val_loss: 0.4576 - val_accuracy: 0.8281 - val_auc: 0.8481 - 140s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.45761\n",
            "15/15 - 140s - loss: 0.5727 - accuracy: 0.7537 - auc: 0.7992 - val_loss: 0.4834 - val_accuracy: 0.7812 - val_auc: 0.8545 - 140s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.6108 - accuracy: 0.7398 - auc: 0.7700 - val_loss: 0.5256 - val_accuracy: 0.7344 - val_auc: 0.8503 - 138s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.6011 - accuracy: 0.7452 - auc: 0.7748 - val_loss: 0.4667 - val_accuracy: 0.7969 - val_auc: 0.8550 - 138s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.5845 - accuracy: 0.7537 - auc: 0.7884 - val_loss: 0.4691 - val_accuracy: 0.8125 - val_auc: 0.8538 - 138s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.5761 - accuracy: 0.7602 - auc: 0.7950 - val_loss: 0.5032 - val_accuracy: 0.7812 - val_auc: 0.8301 - 138s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.45761\n",
            "15/15 - 139s - loss: 0.6073 - accuracy: 0.7270 - auc: 0.7732 - val_loss: 0.4867 - val_accuracy: 0.8125 - val_auc: 0.8335 - 139s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.6114 - accuracy: 0.7388 - auc: 0.7708 - val_loss: 0.5025 - val_accuracy: 0.8125 - val_auc: 0.8120 - 138s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.6215 - accuracy: 0.7430 - auc: 0.7628 - val_loss: 0.4884 - val_accuracy: 0.7656 - val_auc: 0.8613 - 138s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.5782 - accuracy: 0.7495 - auc: 0.7942 - val_loss: 0.5701 - val_accuracy: 0.7188 - val_auc: 0.8081 - 138s/epoch - 9s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.5846 - accuracy: 0.7570 - auc: 0.7894 - val_loss: 0.4723 - val_accuracy: 0.8125 - val_auc: 0.8545 - 138s/epoch - 9s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.5946 - accuracy: 0.7495 - auc: 0.7806 - val_loss: 0.6153 - val_accuracy: 0.6875 - val_auc: 0.7732 - 138s/epoch - 9s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.5897 - accuracy: 0.7441 - auc: 0.7876 - val_loss: 0.5481 - val_accuracy: 0.7344 - val_auc: 0.8376 - 138s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.45761\n",
            "15/15 - 138s - loss: 0.5986 - accuracy: 0.7463 - auc: 0.7809 - val_loss: 0.4888 - val_accuracy: 0.7969 - val_auc: 0.8450 - 138s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss improved from 0.45761 to 0.43861, saving model to Cascade all Model Layers Graph/2022-08-25_16:32:56-model.hdf5\n",
            "15/15 - 142s - loss: 0.6008 - accuracy: 0.7463 - auc: 0.7762 - val_loss: 0.4386 - val_accuracy: 0.8438 - val_auc: 0.8555 - 142s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5887 - accuracy: 0.7527 - auc: 0.7826 - val_loss: 0.4459 - val_accuracy: 0.8281 - val_auc: 0.8457 - 138s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6003 - accuracy: 0.7366 - auc: 0.7766 - val_loss: 0.4729 - val_accuracy: 0.8125 - val_auc: 0.8435 - 138s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5708 - accuracy: 0.7634 - auc: 0.7998 - val_loss: 0.4903 - val_accuracy: 0.7812 - val_auc: 0.8364 - 138s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6006 - accuracy: 0.7420 - auc: 0.7780 - val_loss: 0.4513 - val_accuracy: 0.8438 - val_auc: 0.8457 - 138s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5801 - accuracy: 0.7580 - auc: 0.7924 - val_loss: 0.4677 - val_accuracy: 0.8125 - val_auc: 0.8391 - 138s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5967 - accuracy: 0.7398 - auc: 0.7805 - val_loss: 0.5807 - val_accuracy: 0.6875 - val_auc: 0.8228 - 138s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5745 - accuracy: 0.7570 - auc: 0.7939 - val_loss: 0.5163 - val_accuracy: 0.7500 - val_auc: 0.8403 - 139s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5783 - accuracy: 0.7559 - auc: 0.7897 - val_loss: 0.4847 - val_accuracy: 0.7969 - val_auc: 0.8376 - 138s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5622 - accuracy: 0.7645 - auc: 0.8027 - val_loss: 0.4742 - val_accuracy: 0.7969 - val_auc: 0.8652 - 138s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6096 - accuracy: 0.7398 - auc: 0.7675 - val_loss: 0.5585 - val_accuracy: 0.7500 - val_auc: 0.7974 - 138s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5843 - accuracy: 0.7398 - auc: 0.7888 - val_loss: 0.5096 - val_accuracy: 0.7656 - val_auc: 0.8396 - 138s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5835 - accuracy: 0.7516 - auc: 0.7848 - val_loss: 0.7066 - val_accuracy: 0.6094 - val_auc: 0.7107 - 139s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5935 - accuracy: 0.7570 - auc: 0.7851 - val_loss: 0.5004 - val_accuracy: 0.7656 - val_auc: 0.8474 - 138s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.43861\n",
            "15/15 - 136s - loss: 0.5895 - accuracy: 0.7527 - auc: 0.7838 - val_loss: 0.4847 - val_accuracy: 0.8125 - val_auc: 0.8337 - 136s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.43861\n",
            "15/15 - 136s - loss: 0.5965 - accuracy: 0.7527 - auc: 0.7812 - val_loss: 0.8789 - val_accuracy: 0.6250 - val_auc: 0.6140 - 136s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.6125 - accuracy: 0.7420 - auc: 0.7698 - val_loss: 0.4912 - val_accuracy: 0.7969 - val_auc: 0.8364 - 139s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.43861\n",
            "15/15 - 140s - loss: 0.6021 - accuracy: 0.7409 - auc: 0.7770 - val_loss: 0.5081 - val_accuracy: 0.7656 - val_auc: 0.8381 - 140s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5801 - accuracy: 0.7463 - auc: 0.7890 - val_loss: 0.5064 - val_accuracy: 0.7500 - val_auc: 0.8599 - 139s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.43861\n",
            "15/15 - 140s - loss: 0.5584 - accuracy: 0.7666 - auc: 0.8055 - val_loss: 0.4544 - val_accuracy: 0.8438 - val_auc: 0.8425 - 140s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5936 - accuracy: 0.7441 - auc: 0.7792 - val_loss: 0.4886 - val_accuracy: 0.7969 - val_auc: 0.8459 - 139s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5594 - accuracy: 0.7687 - auc: 0.8045 - val_loss: 0.4878 - val_accuracy: 0.7969 - val_auc: 0.8618 - 139s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5645 - accuracy: 0.7730 - auc: 0.8031 - val_loss: 0.4977 - val_accuracy: 0.7812 - val_auc: 0.8303 - 139s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5920 - accuracy: 0.7537 - auc: 0.7833 - val_loss: 0.4927 - val_accuracy: 0.7812 - val_auc: 0.8423 - 139s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5633 - accuracy: 0.7602 - auc: 0.8039 - val_loss: 0.5139 - val_accuracy: 0.7812 - val_auc: 0.8132 - 139s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5900 - accuracy: 0.7473 - auc: 0.7883 - val_loss: 0.5188 - val_accuracy: 0.7656 - val_auc: 0.8359 - 138s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5729 - accuracy: 0.7591 - auc: 0.7977 - val_loss: 0.5069 - val_accuracy: 0.7812 - val_auc: 0.8276 - 138s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5860 - accuracy: 0.7495 - auc: 0.7876 - val_loss: 0.5151 - val_accuracy: 0.7812 - val_auc: 0.8125 - 139s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5782 - accuracy: 0.7484 - auc: 0.7934 - val_loss: 0.5749 - val_accuracy: 0.7344 - val_auc: 0.7971 - 139s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6120 - accuracy: 0.7345 - auc: 0.7691 - val_loss: 0.5084 - val_accuracy: 0.7656 - val_auc: 0.8423 - 138s/epoch - 9s/step\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5886 - accuracy: 0.7548 - auc: 0.7849 - val_loss: 0.5060 - val_accuracy: 0.8125 - val_auc: 0.8293 - 138s/epoch - 9s/step\n",
            "Epoch 124/150\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5728 - accuracy: 0.7602 - auc: 0.7947 - val_loss: 0.5141 - val_accuracy: 0.7969 - val_auc: 0.8042 - 138s/epoch - 9s/step\n",
            "Epoch 125/150\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5846 - accuracy: 0.7495 - auc: 0.7867 - val_loss: 0.5999 - val_accuracy: 0.6562 - val_auc: 0.7974 - 139s/epoch - 9s/step\n",
            "Epoch 126/150\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5601 - accuracy: 0.7634 - auc: 0.8073 - val_loss: 0.5586 - val_accuracy: 0.7031 - val_auc: 0.8286 - 139s/epoch - 9s/step\n",
            "Epoch 127/150\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5836 - accuracy: 0.7409 - auc: 0.7914 - val_loss: 0.5542 - val_accuracy: 0.7031 - val_auc: 0.8489 - 138s/epoch - 9s/step\n",
            "Epoch 128/150\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.5808 - accuracy: 0.7548 - auc: 0.7908 - val_loss: 0.4761 - val_accuracy: 0.8125 - val_auc: 0.8533 - 139s/epoch - 9s/step\n",
            "Epoch 129/150\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5957 - accuracy: 0.7441 - auc: 0.7796 - val_loss: 0.4667 - val_accuracy: 0.7969 - val_auc: 0.8706 - 138s/epoch - 9s/step\n",
            "Epoch 130/150\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6181 - accuracy: 0.7366 - auc: 0.7648 - val_loss: 0.5232 - val_accuracy: 0.7656 - val_auc: 0.8093 - 138s/epoch - 9s/step\n",
            "Epoch 131/150\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5903 - accuracy: 0.7516 - auc: 0.7833 - val_loss: 0.5674 - val_accuracy: 0.7812 - val_auc: 0.7830 - 138s/epoch - 9s/step\n",
            "Epoch 132/150\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6140 - accuracy: 0.7463 - auc: 0.7629 - val_loss: 0.5496 - val_accuracy: 0.7812 - val_auc: 0.7996 - 138s/epoch - 9s/step\n",
            "Epoch 133/150\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5590 - accuracy: 0.7591 - auc: 0.8090 - val_loss: 0.6617 - val_accuracy: 0.6406 - val_auc: 0.7466 - 138s/epoch - 9s/step\n",
            "Epoch 134/150\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5928 - accuracy: 0.7388 - auc: 0.7860 - val_loss: 0.4922 - val_accuracy: 0.8125 - val_auc: 0.8196 - 138s/epoch - 9s/step\n",
            "Epoch 135/150\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5788 - accuracy: 0.7409 - auc: 0.7909 - val_loss: 0.4773 - val_accuracy: 0.8281 - val_auc: 0.8259 - 138s/epoch - 9s/step\n",
            "Epoch 136/150\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6071 - accuracy: 0.7441 - auc: 0.7745 - val_loss: 0.7390 - val_accuracy: 0.6875 - val_auc: 0.6821 - 138s/epoch - 9s/step\n",
            "Epoch 137/150\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5927 - accuracy: 0.7388 - auc: 0.7801 - val_loss: 0.5076 - val_accuracy: 0.7969 - val_auc: 0.8186 - 138s/epoch - 9s/step\n",
            "Epoch 138/150\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5725 - accuracy: 0.7602 - auc: 0.8007 - val_loss: 0.6327 - val_accuracy: 0.7500 - val_auc: 0.7378 - 138s/epoch - 9s/step\n",
            "Epoch 139/150\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5794 - accuracy: 0.7430 - auc: 0.7888 - val_loss: 0.5048 - val_accuracy: 0.7812 - val_auc: 0.8342 - 138s/epoch - 9s/step\n",
            "Epoch 140/150\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.6018 - accuracy: 0.7409 - auc: 0.7717 - val_loss: 0.4953 - val_accuracy: 0.7812 - val_auc: 0.8459 - 138s/epoch - 9s/step\n",
            "Epoch 141/150\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5664 - accuracy: 0.7634 - auc: 0.7989 - val_loss: 0.5116 - val_accuracy: 0.7656 - val_auc: 0.8481 - 138s/epoch - 9s/step\n",
            "Epoch 142/150\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.43861\n",
            "15/15 - 139s - loss: 0.6027 - accuracy: 0.7398 - auc: 0.7694 - val_loss: 0.4963 - val_accuracy: 0.7969 - val_auc: 0.8423 - 139s/epoch - 9s/step\n",
            "Epoch 143/150\n",
            "\n",
            "Epoch 143: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5826 - accuracy: 0.7516 - auc: 0.7877 - val_loss: 0.4804 - val_accuracy: 0.7812 - val_auc: 0.8511 - 138s/epoch - 9s/step\n",
            "Epoch 144/150\n",
            "\n",
            "Epoch 144: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5819 - accuracy: 0.7473 - auc: 0.7894 - val_loss: 0.6295 - val_accuracy: 0.7188 - val_auc: 0.7466 - 138s/epoch - 9s/step\n",
            "Epoch 145/150\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5807 - accuracy: 0.7537 - auc: 0.7878 - val_loss: 0.6271 - val_accuracy: 0.6562 - val_auc: 0.7747 - 138s/epoch - 9s/step\n",
            "Epoch 146/150\n",
            "\n",
            "Epoch 146: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5910 - accuracy: 0.7473 - auc: 0.7822 - val_loss: 0.5012 - val_accuracy: 0.7656 - val_auc: 0.8323 - 138s/epoch - 9s/step\n",
            "Epoch 147/150\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5877 - accuracy: 0.7591 - auc: 0.7856 - val_loss: 0.4827 - val_accuracy: 0.7812 - val_auc: 0.8472 - 138s/epoch - 9s/step\n",
            "Epoch 148/150\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5940 - accuracy: 0.7463 - auc: 0.7829 - val_loss: 0.5151 - val_accuracy: 0.7500 - val_auc: 0.8545 - 138s/epoch - 9s/step\n",
            "Epoch 149/150\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5740 - accuracy: 0.7580 - auc: 0.7943 - val_loss: 0.4820 - val_accuracy: 0.7969 - val_auc: 0.8442 - 138s/epoch - 9s/step\n",
            "Epoch 150/150\n",
            "\n",
            "Epoch 150: val_loss did not improve from 0.43861\n",
            "15/15 - 138s - loss: 0.5817 - accuracy: 0.7548 - auc: 0.7921 - val_loss: 0.4960 - val_accuracy: 0.7812 - val_auc: 0.8569 - 138s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [00:51<00:00,  4.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7185\n",
            "Recall: 0.8291\n",
            "Threshold: 0.2767\n",
            "F1 Score: 0.7698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10982/10982 [1:12:46<00:00,  2.51it/s]\n"
          ]
        }
      ],
      "source": [
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 5th layer Model Saved'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history5 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history5.history, timestamp,Model_Name)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n",
        "\n",
        "\n",
        "#prediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\n",
        "#print(\"Chance of being malignant: {:.2f} %\".format(prediction))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frvaxlas1-Kj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GKgWHl21-k7"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1.history['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2.history['accuracy'], label='Layer 2 accuracy')\n",
        "plt.plot(history3.history['accuracy'], label='Layer 3 accuracy')\n",
        "plt.plot(history4.history['accuracy'], label='Layer 4 accuracy')\n",
        "plt.plot(history5.history['accuracy'], label='Layer 5 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 5 Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzZ5aYxP1-k7"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3.history['val_accuracy'], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4.history['val_accuracy'], label='Layer 4 Val_Accuracy')\n",
        "plt.plot(history5.history['val_accuracy'], label='Layer 5 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 5 Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf12W_0Y1-k7"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.plot(history1.history['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2.history['loss'], label='Layer 2 Loss')\n",
        "plt.plot(history3.history['loss'], label='Layer 3 Loss')\n",
        "plt.plot(history4.history['loss'], label='Layer 4 Loss')\n",
        "plt.plot(history5.history['loss'], label='Layer 5 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 5 Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0EyakGW1-k7"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1.history['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3.history['val_loss'], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4.history['val_loss'], label='Layer 4 Val_Loss')\n",
        "plt.plot(history5.history['val_loss'], label='Layer 5 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 5 Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FwH3gVa1-k8"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.plot(history1.history['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2.history['auc'], label='Layer 2 Auc')\n",
        "plt.plot(history3.history['auc'], label='Layer 3 Auc')\n",
        "plt.plot(history4.history['auc'], label='Layer 4 Auc')\n",
        "plt.plot(history5.history['auc'], label='Layer 5 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 5 Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGCi50Un1-k8"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1.history['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2.history['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3.history['val_auc'], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4.history['val_auc'], label='Layer 4 Val_Auc')\n",
        "plt.plot(history5.history['val_auc'], label='Layer 5 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 5 Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u1gwBKXjOzZ2",
        "outputId": "8fa04b19-bbf5-46a0-e0ec-9ce0ea80e6b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_2 (Sequential)   (None, 2)                 74976138  \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,977,292\n",
            "Trainable params: 51,387,276\n",
            "Non-trainable params: 23,590,016\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.69889, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 147s - loss: 0.7516 - accuracy: 0.5546 - auc: 0.5749 - val_loss: 0.6989 - val_accuracy: 0.4688 - val_auc: 0.3540 - 147s/epoch - 10s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss improved from 0.69889 to 0.65383, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 141s - loss: 0.7401 - accuracy: 0.5739 - auc: 0.5982 - val_loss: 0.6538 - val_accuracy: 0.7812 - val_auc: 0.8499 - 141s/epoch - 9s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss improved from 0.65383 to 0.62183, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 141s - loss: 0.7327 - accuracy: 0.5664 - auc: 0.5978 - val_loss: 0.6218 - val_accuracy: 0.8125 - val_auc: 0.8074 - 141s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.62183\n",
            "15/15 - 138s - loss: 0.7369 - accuracy: 0.5610 - auc: 0.5989 - val_loss: 0.6600 - val_accuracy: 0.6406 - val_auc: 0.7312 - 138s/epoch - 9s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss improved from 0.62183 to 0.60604, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.7068 - accuracy: 0.6167 - auc: 0.6523 - val_loss: 0.6060 - val_accuracy: 0.7812 - val_auc: 0.8696 - 140s/epoch - 9s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss improved from 0.60604 to 0.58454, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.7006 - accuracy: 0.5953 - auc: 0.6531 - val_loss: 0.5845 - val_accuracy: 0.7969 - val_auc: 0.8533 - 140s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.58454\n",
            "15/15 - 137s - loss: 0.7037 - accuracy: 0.6113 - auc: 0.6489 - val_loss: 0.6102 - val_accuracy: 0.7188 - val_auc: 0.7947 - 137s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss improved from 0.58454 to 0.58179, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.6693 - accuracy: 0.6488 - auc: 0.7015 - val_loss: 0.5818 - val_accuracy: 0.7656 - val_auc: 0.8323 - 140s/epoch - 9s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.58179\n",
            "15/15 - 137s - loss: 0.6743 - accuracy: 0.6349 - auc: 0.6917 - val_loss: 0.6005 - val_accuracy: 0.7344 - val_auc: 0.7563 - 137s/epoch - 9s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss improved from 0.58179 to 0.57498, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.6842 - accuracy: 0.6328 - auc: 0.6828 - val_loss: 0.5750 - val_accuracy: 0.7812 - val_auc: 0.7930 - 140s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss improved from 0.57498 to 0.55314, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.6692 - accuracy: 0.6403 - auc: 0.6966 - val_loss: 0.5531 - val_accuracy: 0.7969 - val_auc: 0.8215 - 140s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss improved from 0.55314 to 0.54753, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.6616 - accuracy: 0.6617 - auc: 0.7122 - val_loss: 0.5475 - val_accuracy: 0.7969 - val_auc: 0.8206 - 140s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.54753\n",
            "15/15 - 137s - loss: 0.6547 - accuracy: 0.6756 - auc: 0.7298 - val_loss: 0.5614 - val_accuracy: 0.7500 - val_auc: 0.8628 - 137s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss improved from 0.54753 to 0.54228, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 139s - loss: 0.6683 - accuracy: 0.6595 - auc: 0.7095 - val_loss: 0.5423 - val_accuracy: 0.7812 - val_auc: 0.8318 - 139s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.54228\n",
            "15/15 - 137s - loss: 0.6469 - accuracy: 0.6884 - auc: 0.7332 - val_loss: 0.5445 - val_accuracy: 0.7969 - val_auc: 0.8496 - 137s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.54228\n",
            "15/15 - 137s - loss: 0.6496 - accuracy: 0.6734 - auc: 0.7268 - val_loss: 0.5922 - val_accuracy: 0.7031 - val_auc: 0.7959 - 137s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss improved from 0.54228 to 0.51757, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.6643 - accuracy: 0.6467 - auc: 0.7099 - val_loss: 0.5176 - val_accuracy: 0.8125 - val_auc: 0.8367 - 140s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.51757\n",
            "15/15 - 138s - loss: 0.6653 - accuracy: 0.6670 - auc: 0.7124 - val_loss: 0.6302 - val_accuracy: 0.6875 - val_auc: 0.6743 - 138s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.51757\n",
            "15/15 - 137s - loss: 0.6561 - accuracy: 0.6638 - auc: 0.7236 - val_loss: 0.5329 - val_accuracy: 0.7969 - val_auc: 0.7864 - 137s/epoch - 9s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.51757\n",
            "15/15 - 137s - loss: 0.6495 - accuracy: 0.6799 - auc: 0.7325 - val_loss: 0.5998 - val_accuracy: 0.6875 - val_auc: 0.7922 - 137s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.51757\n",
            "15/15 - 137s - loss: 0.6403 - accuracy: 0.7024 - auc: 0.7405 - val_loss: 0.6065 - val_accuracy: 0.6875 - val_auc: 0.7998 - 137s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss improved from 0.51757 to 0.51098, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 139s - loss: 0.6300 - accuracy: 0.6981 - auc: 0.7542 - val_loss: 0.5110 - val_accuracy: 0.7969 - val_auc: 0.8250 - 139s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.51098\n",
            "15/15 - 137s - loss: 0.6495 - accuracy: 0.6777 - auc: 0.7272 - val_loss: 0.5328 - val_accuracy: 0.7656 - val_auc: 0.8215 - 137s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.51098\n",
            "15/15 - 137s - loss: 0.6050 - accuracy: 0.7195 - auc: 0.7760 - val_loss: 0.5189 - val_accuracy: 0.7812 - val_auc: 0.8298 - 137s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.51098\n",
            "15/15 - 136s - loss: 0.6320 - accuracy: 0.6970 - auc: 0.7485 - val_loss: 0.5123 - val_accuracy: 0.7812 - val_auc: 0.8462 - 136s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.51098\n",
            "15/15 - 137s - loss: 0.6016 - accuracy: 0.7313 - auc: 0.7789 - val_loss: 0.5416 - val_accuracy: 0.7344 - val_auc: 0.8474 - 137s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss improved from 0.51098 to 0.50109, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.6076 - accuracy: 0.7216 - auc: 0.7757 - val_loss: 0.5011 - val_accuracy: 0.8125 - val_auc: 0.8110 - 140s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.50109\n",
            "15/15 - 138s - loss: 0.6174 - accuracy: 0.7034 - auc: 0.7592 - val_loss: 0.6140 - val_accuracy: 0.7188 - val_auc: 0.6975 - 138s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.50109\n",
            "15/15 - 137s - loss: 0.6171 - accuracy: 0.7323 - auc: 0.7680 - val_loss: 0.5504 - val_accuracy: 0.7500 - val_auc: 0.7815 - 137s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss improved from 0.50109 to 0.49298, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.6290 - accuracy: 0.7270 - auc: 0.7562 - val_loss: 0.4930 - val_accuracy: 0.8281 - val_auc: 0.8225 - 140s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.49298\n",
            "15/15 - 137s - loss: 0.6365 - accuracy: 0.7109 - auc: 0.7473 - val_loss: 0.5501 - val_accuracy: 0.7500 - val_auc: 0.7671 - 137s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.49298\n",
            "15/15 - 137s - loss: 0.6240 - accuracy: 0.7206 - auc: 0.7534 - val_loss: 0.5289 - val_accuracy: 0.7812 - val_auc: 0.7905 - 137s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.49298\n",
            "15/15 - 137s - loss: 0.5999 - accuracy: 0.7302 - auc: 0.7781 - val_loss: 0.4971 - val_accuracy: 0.8125 - val_auc: 0.8176 - 137s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.49298\n",
            "15/15 - 137s - loss: 0.6159 - accuracy: 0.7334 - auc: 0.7637 - val_loss: 0.5007 - val_accuracy: 0.7969 - val_auc: 0.8284 - 137s/epoch - 9s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss improved from 0.49298 to 0.48808, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 139s - loss: 0.6141 - accuracy: 0.7195 - auc: 0.7668 - val_loss: 0.4881 - val_accuracy: 0.8281 - val_auc: 0.8313 - 139s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.48808\n",
            "15/15 - 139s - loss: 0.6258 - accuracy: 0.7355 - auc: 0.7573 - val_loss: 0.5001 - val_accuracy: 0.7969 - val_auc: 0.8130 - 139s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.48808\n",
            "15/15 - 138s - loss: 0.6003 - accuracy: 0.7302 - auc: 0.7760 - val_loss: 0.6761 - val_accuracy: 0.6719 - val_auc: 0.6570 - 138s/epoch - 9s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.48808\n",
            "15/15 - 139s - loss: 0.6024 - accuracy: 0.7366 - auc: 0.7744 - val_loss: 0.6151 - val_accuracy: 0.7031 - val_auc: 0.7192 - 139s/epoch - 9s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss improved from 0.48808 to 0.43436, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 142s - loss: 0.5987 - accuracy: 0.7195 - auc: 0.7759 - val_loss: 0.4344 - val_accuracy: 0.8594 - val_auc: 0.8542 - 142s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.43436\n",
            "15/15 - 141s - loss: 0.6299 - accuracy: 0.7302 - auc: 0.7507 - val_loss: 0.5264 - val_accuracy: 0.7812 - val_auc: 0.7869 - 141s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss improved from 0.43436 to 0.43284, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 143s - loss: 0.6156 - accuracy: 0.7302 - auc: 0.7615 - val_loss: 0.4328 - val_accuracy: 0.8594 - val_auc: 0.8584 - 143s/epoch - 10s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.43284\n",
            "15/15 - 139s - loss: 0.5835 - accuracy: 0.7463 - auc: 0.7875 - val_loss: 0.4871 - val_accuracy: 0.8125 - val_auc: 0.8374 - 139s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.43284\n",
            "15/15 - 138s - loss: 0.6162 - accuracy: 0.7323 - auc: 0.7642 - val_loss: 0.5815 - val_accuracy: 0.7031 - val_auc: 0.8025 - 138s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.43284\n",
            "15/15 - 137s - loss: 0.5912 - accuracy: 0.7559 - auc: 0.7863 - val_loss: 0.5015 - val_accuracy: 0.7812 - val_auc: 0.8452 - 137s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.43284\n",
            "15/15 - 137s - loss: 0.6069 - accuracy: 0.7441 - auc: 0.7708 - val_loss: 0.5346 - val_accuracy: 0.7656 - val_auc: 0.8362 - 137s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.43284\n",
            "15/15 - 138s - loss: 0.6154 - accuracy: 0.7313 - auc: 0.7626 - val_loss: 0.4982 - val_accuracy: 0.7812 - val_auc: 0.8481 - 138s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.43284\n",
            "15/15 - 137s - loss: 0.6016 - accuracy: 0.7570 - auc: 0.7782 - val_loss: 0.4889 - val_accuracy: 0.7969 - val_auc: 0.8643 - 137s/epoch - 9s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.43284\n",
            "15/15 - 137s - loss: 0.6020 - accuracy: 0.7409 - auc: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7812 - val_auc: 0.8508 - 137s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss improved from 0.43284 to 0.42898, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 140s - loss: 0.5834 - accuracy: 0.7623 - auc: 0.7920 - val_loss: 0.4290 - val_accuracy: 0.8594 - val_auc: 0.8616 - 140s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6035 - accuracy: 0.7484 - auc: 0.7713 - val_loss: 0.5207 - val_accuracy: 0.7656 - val_auc: 0.8445 - 138s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6083 - accuracy: 0.7345 - auc: 0.7692 - val_loss: 0.5169 - val_accuracy: 0.7656 - val_auc: 0.8459 - 138s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6169 - accuracy: 0.7377 - auc: 0.7606 - val_loss: 0.5298 - val_accuracy: 0.7500 - val_auc: 0.8428 - 138s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.42898\n",
            "15/15 - 139s - loss: 0.5991 - accuracy: 0.7473 - auc: 0.7799 - val_loss: 0.6002 - val_accuracy: 0.6875 - val_auc: 0.7957 - 139s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.5650 - accuracy: 0.7527 - auc: 0.8042 - val_loss: 0.4310 - val_accuracy: 0.8438 - val_auc: 0.8569 - 138s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6001 - accuracy: 0.7430 - auc: 0.7782 - val_loss: 0.6069 - val_accuracy: 0.7344 - val_auc: 0.7354 - 138s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6170 - accuracy: 0.7430 - auc: 0.7641 - val_loss: 0.4988 - val_accuracy: 0.7812 - val_auc: 0.8354 - 138s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.42898\n",
            "15/15 - 139s - loss: 0.6030 - accuracy: 0.7420 - auc: 0.7799 - val_loss: 0.5278 - val_accuracy: 0.7656 - val_auc: 0.8323 - 139s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.42898\n",
            "15/15 - 140s - loss: 0.5944 - accuracy: 0.7516 - auc: 0.7851 - val_loss: 0.5286 - val_accuracy: 0.7656 - val_auc: 0.8381 - 140s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.42898\n",
            "15/15 - 139s - loss: 0.5925 - accuracy: 0.7409 - auc: 0.7795 - val_loss: 0.4682 - val_accuracy: 0.8125 - val_auc: 0.8333 - 139s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.42898\n",
            "15/15 - 140s - loss: 0.6182 - accuracy: 0.7345 - auc: 0.7614 - val_loss: 0.4529 - val_accuracy: 0.8281 - val_auc: 0.8545 - 140s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.42898\n",
            "15/15 - 141s - loss: 0.5985 - accuracy: 0.7452 - auc: 0.7766 - val_loss: 0.5859 - val_accuracy: 0.7031 - val_auc: 0.8079 - 141s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.42898\n",
            "15/15 - 139s - loss: 0.6335 - accuracy: 0.7302 - auc: 0.7463 - val_loss: 0.5596 - val_accuracy: 0.7344 - val_auc: 0.8113 - 139s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.42898\n",
            "15/15 - 139s - loss: 0.6104 - accuracy: 0.7398 - auc: 0.7664 - val_loss: 0.5528 - val_accuracy: 0.7656 - val_auc: 0.7793 - 139s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.42898\n",
            "15/15 - 139s - loss: 0.6071 - accuracy: 0.7505 - auc: 0.7752 - val_loss: 0.5322 - val_accuracy: 0.7656 - val_auc: 0.8003 - 139s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.42898\n",
            "15/15 - 139s - loss: 0.5909 - accuracy: 0.7495 - auc: 0.7841 - val_loss: 0.4389 - val_accuracy: 0.8438 - val_auc: 0.8545 - 139s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.5699 - accuracy: 0.7602 - auc: 0.8011 - val_loss: 0.4482 - val_accuracy: 0.8281 - val_auc: 0.8628 - 138s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.5928 - accuracy: 0.7505 - auc: 0.7813 - val_loss: 0.7563 - val_accuracy: 0.6406 - val_auc: 0.6455 - 138s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6007 - accuracy: 0.7388 - auc: 0.7756 - val_loss: 0.4676 - val_accuracy: 0.8281 - val_auc: 0.8469 - 138s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6276 - accuracy: 0.7227 - auc: 0.7526 - val_loss: 0.5010 - val_accuracy: 0.7812 - val_auc: 0.8379 - 138s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6159 - accuracy: 0.7441 - auc: 0.7640 - val_loss: 0.4767 - val_accuracy: 0.8125 - val_auc: 0.8524 - 138s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6230 - accuracy: 0.7195 - auc: 0.7580 - val_loss: 0.4651 - val_accuracy: 0.8125 - val_auc: 0.8589 - 138s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.42898\n",
            "15/15 - 138s - loss: 0.6099 - accuracy: 0.7495 - auc: 0.7658 - val_loss: 0.4687 - val_accuracy: 0.8125 - val_auc: 0.8572 - 138s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss improved from 0.42898 to 0.42815, saving model to Cascade all Model Layers Graph/2022-08-25_23:34:27-model.hdf5\n",
            "15/15 - 142s - loss: 0.6053 - accuracy: 0.7516 - auc: 0.7720 - val_loss: 0.4282 - val_accuracy: 0.8594 - val_auc: 0.8645 - 142s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.42815\n",
            "15/15 - 138s - loss: 0.5751 - accuracy: 0.7527 - auc: 0.7974 - val_loss: 0.4863 - val_accuracy: 0.7969 - val_auc: 0.8477 - 138s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5989 - accuracy: 0.7420 - auc: 0.7766 - val_loss: 0.5218 - val_accuracy: 0.7656 - val_auc: 0.8357 - 139s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.6133 - accuracy: 0.7323 - auc: 0.7652 - val_loss: 0.5898 - val_accuracy: 0.7656 - val_auc: 0.7324 - 139s/epoch - 9s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.6259 - accuracy: 0.7270 - auc: 0.7507 - val_loss: 0.4416 - val_accuracy: 0.8281 - val_auc: 0.8542 - 139s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5745 - accuracy: 0.7527 - auc: 0.7948 - val_loss: 0.4529 - val_accuracy: 0.8281 - val_auc: 0.8521 - 139s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5989 - accuracy: 0.7323 - auc: 0.7796 - val_loss: 0.5205 - val_accuracy: 0.7656 - val_auc: 0.8408 - 139s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5850 - accuracy: 0.7452 - auc: 0.7858 - val_loss: 0.4327 - val_accuracy: 0.8438 - val_auc: 0.8599 - 139s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.6148 - accuracy: 0.7334 - auc: 0.7616 - val_loss: 0.4974 - val_accuracy: 0.7812 - val_auc: 0.8420 - 139s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5813 - accuracy: 0.7505 - auc: 0.7925 - val_loss: 0.4914 - val_accuracy: 0.7969 - val_auc: 0.8386 - 139s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5965 - accuracy: 0.7473 - auc: 0.7814 - val_loss: 0.4378 - val_accuracy: 0.8438 - val_auc: 0.8574 - 139s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.6141 - accuracy: 0.7355 - auc: 0.7620 - val_loss: 0.4494 - val_accuracy: 0.8438 - val_auc: 0.8489 - 139s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5991 - accuracy: 0.7516 - auc: 0.7739 - val_loss: 0.4903 - val_accuracy: 0.7812 - val_auc: 0.8423 - 139s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.6140 - accuracy: 0.7334 - auc: 0.7653 - val_loss: 0.5713 - val_accuracy: 0.7344 - val_auc: 0.7900 - 139s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.6090 - accuracy: 0.7291 - auc: 0.7635 - val_loss: 0.5318 - val_accuracy: 0.7500 - val_auc: 0.8315 - 139s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.42815\n",
            "15/15 - 139s - loss: 0.5940 - accuracy: 0.7377 - auc: 0.7793 - val_loss: 0.4804 - val_accuracy: 0.7969 - val_auc: 0.8618 - 139s/epoch - 9s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5939 - accuracy: 0.7398 - auc: 0.7777 - val_loss: 0.5676 - val_accuracy: 0.7188 - val_auc: 0.7974 - 140s/epoch - 9s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6058 - accuracy: 0.7291 - auc: 0.7727 - val_loss: 0.4857 - val_accuracy: 0.7812 - val_auc: 0.8716 - 140s/epoch - 9s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6065 - accuracy: 0.7430 - auc: 0.7719 - val_loss: 0.4888 - val_accuracy: 0.7656 - val_auc: 0.8647 - 140s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6030 - accuracy: 0.7527 - auc: 0.7751 - val_loss: 0.4329 - val_accuracy: 0.8438 - val_auc: 0.8667 - 140s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6118 - accuracy: 0.7430 - auc: 0.7669 - val_loss: 0.6898 - val_accuracy: 0.7031 - val_auc: 0.6755 - 140s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6062 - accuracy: 0.7495 - auc: 0.7721 - val_loss: 0.4562 - val_accuracy: 0.8125 - val_auc: 0.8767 - 140s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5791 - accuracy: 0.7645 - auc: 0.7939 - val_loss: 0.4301 - val_accuracy: 0.8438 - val_auc: 0.8835 - 140s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5718 - accuracy: 0.7570 - auc: 0.7969 - val_loss: 0.4368 - val_accuracy: 0.8281 - val_auc: 0.8816 - 140s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5821 - accuracy: 0.7473 - auc: 0.7903 - val_loss: 0.4489 - val_accuracy: 0.8125 - val_auc: 0.8853 - 140s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.5863 - accuracy: 0.7495 - auc: 0.7873 - val_loss: 0.4478 - val_accuracy: 0.8125 - val_auc: 0.8723 - 141s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.42815\n",
            "15/15 - 142s - loss: 0.5815 - accuracy: 0.7430 - auc: 0.7923 - val_loss: 0.4310 - val_accuracy: 0.8438 - val_auc: 0.8818 - 142s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.42815\n",
            "15/15 - 142s - loss: 0.5816 - accuracy: 0.7580 - auc: 0.7869 - val_loss: 0.6692 - val_accuracy: 0.6250 - val_auc: 0.7163 - 142s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.6134 - accuracy: 0.7377 - auc: 0.7657 - val_loss: 0.4942 - val_accuracy: 0.7812 - val_auc: 0.8518 - 141s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.6162 - accuracy: 0.7302 - auc: 0.7631 - val_loss: 0.7164 - val_accuracy: 0.6875 - val_auc: 0.6694 - 141s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5976 - accuracy: 0.7537 - auc: 0.7756 - val_loss: 0.4385 - val_accuracy: 0.8438 - val_auc: 0.8535 - 140s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6219 - accuracy: 0.7398 - auc: 0.7603 - val_loss: 0.5196 - val_accuracy: 0.7656 - val_auc: 0.8337 - 140s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.6051 - accuracy: 0.7484 - auc: 0.7708 - val_loss: 0.5374 - val_accuracy: 0.7969 - val_auc: 0.7915 - 141s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.6058 - accuracy: 0.7334 - auc: 0.7732 - val_loss: 0.4423 - val_accuracy: 0.8281 - val_auc: 0.8621 - 141s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.5923 - accuracy: 0.7430 - auc: 0.7810 - val_loss: 0.4970 - val_accuracy: 0.7656 - val_auc: 0.8672 - 141s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.6077 - accuracy: 0.7409 - auc: 0.7705 - val_loss: 0.6320 - val_accuracy: 0.7344 - val_auc: 0.7244 - 141s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.5988 - accuracy: 0.7388 - auc: 0.7757 - val_loss: 0.4601 - val_accuracy: 0.8281 - val_auc: 0.8364 - 141s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.42815\n",
            "15/15 - 142s - loss: 0.5861 - accuracy: 0.7505 - auc: 0.7858 - val_loss: 0.4474 - val_accuracy: 0.8438 - val_auc: 0.8633 - 142s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.6015 - accuracy: 0.7409 - auc: 0.7750 - val_loss: 0.5939 - val_accuracy: 0.6875 - val_auc: 0.8032 - 141s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.6186 - accuracy: 0.7323 - auc: 0.7610 - val_loss: 0.7157 - val_accuracy: 0.6875 - val_auc: 0.6577 - 141s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.5966 - accuracy: 0.7345 - auc: 0.7782 - val_loss: 0.4437 - val_accuracy: 0.8281 - val_auc: 0.8655 - 141s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.42815\n",
            "15/15 - 141s - loss: 0.5731 - accuracy: 0.7537 - auc: 0.7944 - val_loss: 0.4991 - val_accuracy: 0.7812 - val_auc: 0.8616 - 141s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5883 - accuracy: 0.7420 - auc: 0.7802 - val_loss: 0.5538 - val_accuracy: 0.7344 - val_auc: 0.8135 - 140s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6004 - accuracy: 0.7463 - auc: 0.7735 - val_loss: 0.4296 - val_accuracy: 0.8281 - val_auc: 0.8762 - 140s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5762 - accuracy: 0.7612 - auc: 0.7914 - val_loss: 0.6537 - val_accuracy: 0.6406 - val_auc: 0.7549 - 140s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6011 - accuracy: 0.7430 - auc: 0.7768 - val_loss: 0.5073 - val_accuracy: 0.7656 - val_auc: 0.8599 - 140s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5824 - accuracy: 0.7570 - auc: 0.7845 - val_loss: 0.5177 - val_accuracy: 0.7656 - val_auc: 0.8271 - 140s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5857 - accuracy: 0.7580 - auc: 0.7860 - val_loss: 0.4832 - val_accuracy: 0.7812 - val_auc: 0.8611 - 140s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5473 - accuracy: 0.7730 - auc: 0.8144 - val_loss: 0.7684 - val_accuracy: 0.6406 - val_auc: 0.6479 - 140s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.6049 - accuracy: 0.7388 - auc: 0.7690 - val_loss: 0.5174 - val_accuracy: 0.7969 - val_auc: 0.7966 - 140s/epoch - 9s/step\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.42815\n",
            "15/15 - 140s - loss: 0.5981 - accuracy: 0.7291 - auc: 0.7790 - val_loss: 0.5716 - val_accuracy: 0.7188 - val_auc: 0.7871 - 140s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [00:51<00:00,  4.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7344\n",
            "Recall: 0.8034\n",
            "Threshold: 0.6941\n",
            "F1 Score: 0.7673\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 6th layer Model Saved'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history6 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history6.history, timestamp,Model_Name)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "'''\n",
        "prediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\n",
        "print(\"Chance of being malignant: {:.2f} %\".format(prediction))\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzSsyyHhN0kN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFTFfzPi1w4V"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1.history['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2.history['accuracy'], label='Layer 2 accuracy')\n",
        "plt.plot(history3.history['accuracy'], label='Layer 3 accuracy')\n",
        "plt.plot(history4.history['accuracy'], label='Layer 4 accuracy')\n",
        "plt.plot(history5.history['accuracy'], label='Layer 5 accuracy')\n",
        "plt.plot(history6.history['accuracy'], label='Layer 6 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 6 Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYpzT03H1w4V"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3.history['val_accuracy'], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4.history['val_accuracy'], label='Layer 4 Val_Accuracy')\n",
        "plt.plot(history5.history['val_accuracy'], label='Layer 5 Val_Accuracy')\n",
        "plt.plot(history6.history['val_accuracy'], label='Layer 6 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 6 Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnMZg5Uk1w4W"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.plot(history1.history['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2.history['loss'], label='Layer 2 Loss')\n",
        "plt.plot(history3.history['loss'], label='Layer 3 Loss')\n",
        "plt.plot(history4.history['loss'], label='Layer 4 Loss')\n",
        "plt.plot(history5.history['loss'], label='Layer 5 Loss')\n",
        "plt.plot(history6.history['loss'], label='Layer 6 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 6 Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeZRTiys1w4W"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1.history['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3.history['val_loss'], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4.history['val_loss'], label='Layer 4 Val_Loss')\n",
        "plt.plot(history5.history['val_loss'], label='Layer 5 Val_Loss')\n",
        "plt.plot(history6.history['val_loss'], label='Layer 6 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 6 Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb9B00VI1w4W"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.plot(history1.history['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2.history['auc'], label='Layer 2 Auc')\n",
        "plt.plot(history3.history['auc'], label='Layer 3 Auc')\n",
        "plt.plot(history4.history['auc'], label='Layer 4 Auc')\n",
        "plt.plot(history5.history['auc'], label='Layer 5 Auc')\n",
        "plt.plot(history6.history['auc'], label='Layer 6 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 6 Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raF1SCK81w4X"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1.history['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2.history['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3.history['val_auc'], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4.history['val_auc'], label='Layer 4 Val_Auc')\n",
        "plt.plot(history5.history['val_auc'], label='Layer 5 Val_Auc')\n",
        "plt.plot(history6.history['val_auc'], label='Layer 6 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 6 Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MZfTvTLOR2s7",
        "outputId": "0d657bad-d0ec-4655-f447-641fca9deae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_3 (Sequential)   (None, 2)                 74977292  \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,978,446\n",
            "Trainable params: 51,388,174\n",
            "Non-trainable params: 23,590,272\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.76443, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 149s - loss: 0.9537 - accuracy: 0.3415 - auc: 0.2893 - val_loss: 0.7644 - val_accuracy: 0.1719 - val_auc: 0.1687 - 149s/epoch - 10s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.76443\n",
            "15/15 - 140s - loss: 0.9161 - accuracy: 0.3448 - auc: 0.2985 - val_loss: 0.8976 - val_accuracy: 0.1406 - val_auc: 0.1321 - 140s/epoch - 9s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.76443\n",
            "15/15 - 140s - loss: 0.8873 - accuracy: 0.3897 - auc: 0.3468 - val_loss: 0.9009 - val_accuracy: 0.1562 - val_auc: 0.1416 - 140s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.76443\n",
            "15/15 - 140s - loss: 0.8768 - accuracy: 0.4004 - auc: 0.3570 - val_loss: 0.8723 - val_accuracy: 0.1719 - val_auc: 0.1761 - 140s/epoch - 9s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.76443\n",
            "15/15 - 139s - loss: 0.8776 - accuracy: 0.3801 - auc: 0.3318 - val_loss: 0.8607 - val_accuracy: 0.1719 - val_auc: 0.1475 - 139s/epoch - 9s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.76443\n",
            "15/15 - 139s - loss: 0.8843 - accuracy: 0.3865 - auc: 0.3390 - val_loss: 0.8451 - val_accuracy: 0.1719 - val_auc: 0.1553 - 139s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.76443\n",
            "15/15 - 139s - loss: 0.8501 - accuracy: 0.4293 - auc: 0.3927 - val_loss: 0.8261 - val_accuracy: 0.1719 - val_auc: 0.1499 - 139s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.76443\n",
            "15/15 - 139s - loss: 0.8255 - accuracy: 0.4240 - auc: 0.3924 - val_loss: 0.8046 - val_accuracy: 0.2031 - val_auc: 0.2151 - 139s/epoch - 9s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.76443\n",
            "15/15 - 139s - loss: 0.8215 - accuracy: 0.4443 - auc: 0.4236 - val_loss: 0.7835 - val_accuracy: 0.2188 - val_auc: 0.1475 - 139s/epoch - 9s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss improved from 0.76443 to 0.76391, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 141s - loss: 0.8122 - accuracy: 0.4443 - auc: 0.4241 - val_loss: 0.7639 - val_accuracy: 0.2344 - val_auc: 0.1846 - 141s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss improved from 0.76391 to 0.74800, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 141s - loss: 0.8073 - accuracy: 0.4529 - auc: 0.4341 - val_loss: 0.7480 - val_accuracy: 0.2500 - val_auc: 0.1885 - 141s/epoch - 9s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss improved from 0.74800 to 0.74205, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 141s - loss: 0.7902 - accuracy: 0.4550 - auc: 0.4479 - val_loss: 0.7421 - val_accuracy: 0.2344 - val_auc: 0.1614 - 141s/epoch - 9s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss improved from 0.74205 to 0.73183, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 141s - loss: 0.7747 - accuracy: 0.4700 - auc: 0.4704 - val_loss: 0.7318 - val_accuracy: 0.2500 - val_auc: 0.2028 - 141s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss improved from 0.73183 to 0.71936, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7893 - accuracy: 0.4722 - auc: 0.4678 - val_loss: 0.7194 - val_accuracy: 0.4531 - val_auc: 0.3264 - 142s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss improved from 0.71936 to 0.70868, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.7834 - accuracy: 0.4722 - auc: 0.4808 - val_loss: 0.7087 - val_accuracy: 0.4531 - val_auc: 0.3228 - 143s/epoch - 10s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss improved from 0.70868 to 0.69842, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.7653 - accuracy: 0.5214 - auc: 0.5190 - val_loss: 0.6984 - val_accuracy: 0.4531 - val_auc: 0.5702 - 143s/epoch - 10s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss improved from 0.69842 to 0.69182, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.7528 - accuracy: 0.5203 - auc: 0.5332 - val_loss: 0.6918 - val_accuracy: 0.7656 - val_auc: 0.7247 - 143s/epoch - 10s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss improved from 0.69182 to 0.68661, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7542 - accuracy: 0.5246 - auc: 0.5361 - val_loss: 0.6866 - val_accuracy: 0.7656 - val_auc: 0.7063 - 142s/epoch - 9s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss improved from 0.68661 to 0.67702, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.7516 - accuracy: 0.5214 - auc: 0.5190 - val_loss: 0.6770 - val_accuracy: 0.7656 - val_auc: 0.7300 - 143s/epoch - 10s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.67702\n",
            "15/15 - 139s - loss: 0.7526 - accuracy: 0.5278 - auc: 0.5310 - val_loss: 0.6968 - val_accuracy: 0.5625 - val_auc: 0.5410 - 139s/epoch - 9s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.67702\n",
            "15/15 - 139s - loss: 0.7441 - accuracy: 0.5289 - auc: 0.5526 - val_loss: 0.6805 - val_accuracy: 0.6406 - val_auc: 0.6384 - 139s/epoch - 9s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss improved from 0.67702 to 0.65548, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7365 - accuracy: 0.5493 - auc: 0.5640 - val_loss: 0.6555 - val_accuracy: 0.7656 - val_auc: 0.7424 - 142s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.65548\n",
            "15/15 - 139s - loss: 0.7411 - accuracy: 0.5439 - auc: 0.5605 - val_loss: 0.6892 - val_accuracy: 0.5781 - val_auc: 0.5581 - 139s/epoch - 9s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.65548\n",
            "15/15 - 139s - loss: 0.7288 - accuracy: 0.5600 - auc: 0.5827 - val_loss: 0.6767 - val_accuracy: 0.6250 - val_auc: 0.6147 - 139s/epoch - 9s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss improved from 0.65548 to 0.65492, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7203 - accuracy: 0.5739 - auc: 0.6111 - val_loss: 0.6549 - val_accuracy: 0.7031 - val_auc: 0.7424 - 142s/epoch - 9s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss improved from 0.65492 to 0.63624, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7119 - accuracy: 0.5878 - auc: 0.6140 - val_loss: 0.6362 - val_accuracy: 0.7500 - val_auc: 0.8313 - 142s/epoch - 9s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss improved from 0.63624 to 0.62676, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7163 - accuracy: 0.5835 - auc: 0.6065 - val_loss: 0.6268 - val_accuracy: 0.7812 - val_auc: 0.7764 - 142s/epoch - 9s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.62676\n",
            "15/15 - 139s - loss: 0.7067 - accuracy: 0.5921 - auc: 0.6233 - val_loss: 0.6310 - val_accuracy: 0.7344 - val_auc: 0.8118 - 139s/epoch - 9s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.62676\n",
            "15/15 - 138s - loss: 0.7013 - accuracy: 0.5771 - auc: 0.6226 - val_loss: 0.6314 - val_accuracy: 0.7188 - val_auc: 0.8254 - 138s/epoch - 9s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss improved from 0.62676 to 0.60595, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 141s - loss: 0.7110 - accuracy: 0.5889 - auc: 0.6253 - val_loss: 0.6060 - val_accuracy: 0.7812 - val_auc: 0.8545 - 141s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss improved from 0.60595 to 0.58687, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7080 - accuracy: 0.5942 - auc: 0.6283 - val_loss: 0.5869 - val_accuracy: 0.8281 - val_auc: 0.8479 - 142s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.58687\n",
            "15/15 - 140s - loss: 0.7042 - accuracy: 0.5910 - auc: 0.6355 - val_loss: 0.6592 - val_accuracy: 0.6562 - val_auc: 0.6282 - 140s/epoch - 9s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss improved from 0.58687 to 0.58473, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.7053 - accuracy: 0.5964 - auc: 0.6353 - val_loss: 0.5847 - val_accuracy: 0.7969 - val_auc: 0.8782 - 142s/epoch - 9s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss improved from 0.58473 to 0.57628, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.6979 - accuracy: 0.6135 - auc: 0.6490 - val_loss: 0.5763 - val_accuracy: 0.8281 - val_auc: 0.8323 - 143s/epoch - 10s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.57628\n",
            "15/15 - 140s - loss: 0.6936 - accuracy: 0.6167 - auc: 0.6541 - val_loss: 0.6115 - val_accuracy: 0.7188 - val_auc: 0.8223 - 140s/epoch - 9s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss improved from 0.57628 to 0.56430, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.6834 - accuracy: 0.6349 - auc: 0.6706 - val_loss: 0.5643 - val_accuracy: 0.8125 - val_auc: 0.8796 - 142s/epoch - 9s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss improved from 0.56430 to 0.55589, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.6689 - accuracy: 0.6445 - auc: 0.6944 - val_loss: 0.5559 - val_accuracy: 0.8281 - val_auc: 0.8425 - 143s/epoch - 10s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss improved from 0.55589 to 0.53525, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.6902 - accuracy: 0.6231 - auc: 0.6577 - val_loss: 0.5353 - val_accuracy: 0.8594 - val_auc: 0.8806 - 143s/epoch - 10s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.53525\n",
            "15/15 - 140s - loss: 0.6746 - accuracy: 0.6585 - auc: 0.6895 - val_loss: 0.5894 - val_accuracy: 0.7344 - val_auc: 0.8308 - 140s/epoch - 9s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.53525\n",
            "15/15 - 140s - loss: 0.6714 - accuracy: 0.6456 - auc: 0.6913 - val_loss: 0.5413 - val_accuracy: 0.8281 - val_auc: 0.8389 - 140s/epoch - 9s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss improved from 0.53525 to 0.52823, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.6771 - accuracy: 0.6231 - auc: 0.6815 - val_loss: 0.5282 - val_accuracy: 0.8438 - val_auc: 0.8596 - 143s/epoch - 10s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.52823\n",
            "15/15 - 139s - loss: 0.6753 - accuracy: 0.6435 - auc: 0.6915 - val_loss: 0.5905 - val_accuracy: 0.7500 - val_auc: 0.7334 - 139s/epoch - 9s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.52823\n",
            "15/15 - 139s - loss: 0.6795 - accuracy: 0.6370 - auc: 0.6773 - val_loss: 0.5585 - val_accuracy: 0.7656 - val_auc: 0.8279 - 139s/epoch - 9s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss improved from 0.52823 to 0.50501, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.6484 - accuracy: 0.6852 - auc: 0.7277 - val_loss: 0.5050 - val_accuracy: 0.8594 - val_auc: 0.8970 - 142s/epoch - 9s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.50501\n",
            "15/15 - 140s - loss: 0.6805 - accuracy: 0.6520 - auc: 0.6837 - val_loss: 0.5148 - val_accuracy: 0.8281 - val_auc: 0.8918 - 140s/epoch - 9s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.50501\n",
            "15/15 - 140s - loss: 0.6583 - accuracy: 0.6799 - auc: 0.7156 - val_loss: 0.5851 - val_accuracy: 0.7188 - val_auc: 0.8145 - 140s/epoch - 9s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss improved from 0.50501 to 0.50053, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.6522 - accuracy: 0.6777 - auc: 0.7234 - val_loss: 0.5005 - val_accuracy: 0.8438 - val_auc: 0.8850 - 143s/epoch - 10s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.50053\n",
            "15/15 - 140s - loss: 0.6533 - accuracy: 0.6713 - auc: 0.7217 - val_loss: 0.5137 - val_accuracy: 0.8281 - val_auc: 0.8318 - 140s/epoch - 9s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.50053\n",
            "15/15 - 140s - loss: 0.6628 - accuracy: 0.6842 - auc: 0.7140 - val_loss: 0.5677 - val_accuracy: 0.7344 - val_auc: 0.8123 - 140s/epoch - 9s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.50053\n",
            "15/15 - 140s - loss: 0.6427 - accuracy: 0.6906 - auc: 0.7312 - val_loss: 0.5342 - val_accuracy: 0.7812 - val_auc: 0.8745 - 140s/epoch - 9s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.50053\n",
            "15/15 - 140s - loss: 0.6725 - accuracy: 0.6617 - auc: 0.6967 - val_loss: 0.5334 - val_accuracy: 0.7812 - val_auc: 0.8730 - 140s/epoch - 9s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.50053\n",
            "15/15 - 140s - loss: 0.6490 - accuracy: 0.6799 - auc: 0.7253 - val_loss: 0.5049 - val_accuracy: 0.8281 - val_auc: 0.8518 - 140s/epoch - 9s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss improved from 0.50053 to 0.49929, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.6380 - accuracy: 0.6756 - auc: 0.7352 - val_loss: 0.4993 - val_accuracy: 0.8281 - val_auc: 0.8596 - 142s/epoch - 9s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss improved from 0.49929 to 0.49365, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.6263 - accuracy: 0.6991 - auc: 0.7576 - val_loss: 0.4937 - val_accuracy: 0.8281 - val_auc: 0.8804 - 142s/epoch - 9s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss improved from 0.49365 to 0.47780, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.6239 - accuracy: 0.7056 - auc: 0.7526 - val_loss: 0.4778 - val_accuracy: 0.8438 - val_auc: 0.8733 - 142s/epoch - 9s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.47780\n",
            "15/15 - 140s - loss: 0.6193 - accuracy: 0.7227 - auc: 0.7621 - val_loss: 0.5167 - val_accuracy: 0.7969 - val_auc: 0.8162 - 140s/epoch - 9s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss improved from 0.47780 to 0.46387, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.6427 - accuracy: 0.6863 - auc: 0.7295 - val_loss: 0.4639 - val_accuracy: 0.8594 - val_auc: 0.8862 - 142s/epoch - 9s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.46387\n",
            "15/15 - 140s - loss: 0.6371 - accuracy: 0.6906 - auc: 0.7411 - val_loss: 0.5458 - val_accuracy: 0.7500 - val_auc: 0.8281 - 140s/epoch - 9s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.46387\n",
            "15/15 - 140s - loss: 0.6368 - accuracy: 0.6991 - auc: 0.7411 - val_loss: 0.5581 - val_accuracy: 0.7344 - val_auc: 0.8167 - 140s/epoch - 9s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.46387\n",
            "15/15 - 139s - loss: 0.6120 - accuracy: 0.7398 - auc: 0.7697 - val_loss: 0.4807 - val_accuracy: 0.8281 - val_auc: 0.8896 - 139s/epoch - 9s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.46387\n",
            "15/15 - 140s - loss: 0.5918 - accuracy: 0.7430 - auc: 0.7952 - val_loss: 0.4975 - val_accuracy: 0.8125 - val_auc: 0.8203 - 140s/epoch - 9s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.46387\n",
            "15/15 - 139s - loss: 0.6328 - accuracy: 0.7077 - auc: 0.7416 - val_loss: 0.5083 - val_accuracy: 0.7969 - val_auc: 0.8044 - 139s/epoch - 9s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.46387\n",
            "15/15 - 140s - loss: 0.6306 - accuracy: 0.7013 - auc: 0.7467 - val_loss: 0.4793 - val_accuracy: 0.8281 - val_auc: 0.8362 - 140s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.46387\n",
            "15/15 - 140s - loss: 0.6300 - accuracy: 0.7152 - auc: 0.7479 - val_loss: 0.4686 - val_accuracy: 0.8438 - val_auc: 0.8398 - 140s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.46387\n",
            "15/15 - 140s - loss: 0.6155 - accuracy: 0.7141 - auc: 0.7627 - val_loss: 0.4783 - val_accuracy: 0.8281 - val_auc: 0.8362 - 140s/epoch - 9s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss improved from 0.46387 to 0.46376, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 143s - loss: 0.6252 - accuracy: 0.7120 - auc: 0.7505 - val_loss: 0.4638 - val_accuracy: 0.8438 - val_auc: 0.8547 - 143s/epoch - 10s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.46376\n",
            "15/15 - 140s - loss: 0.6302 - accuracy: 0.7291 - auc: 0.7493 - val_loss: 0.5531 - val_accuracy: 0.7344 - val_auc: 0.8240 - 140s/epoch - 9s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss improved from 0.46376 to 0.46108, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 142s - loss: 0.6185 - accuracy: 0.7109 - auc: 0.7585 - val_loss: 0.4611 - val_accuracy: 0.8281 - val_auc: 0.8669 - 142s/epoch - 9s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.46108\n",
            "15/15 - 139s - loss: 0.6321 - accuracy: 0.7184 - auc: 0.7443 - val_loss: 0.4981 - val_accuracy: 0.8125 - val_auc: 0.8086 - 139s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.46108\n",
            "15/15 - 138s - loss: 0.6184 - accuracy: 0.7141 - auc: 0.7631 - val_loss: 0.5309 - val_accuracy: 0.7500 - val_auc: 0.8281 - 138s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.46108\n",
            "15/15 - 138s - loss: 0.6119 - accuracy: 0.7291 - auc: 0.7630 - val_loss: 0.5224 - val_accuracy: 0.7656 - val_auc: 0.8542 - 138s/epoch - 9s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss improved from 0.46108 to 0.44596, saving model to Cascade all Model Layers Graph/2022-08-26_04:22:51-model.hdf5\n",
            "15/15 - 141s - loss: 0.6180 - accuracy: 0.7238 - auc: 0.7576 - val_loss: 0.4460 - val_accuracy: 0.8438 - val_auc: 0.8657 - 141s/epoch - 9s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.44596\n",
            "15/15 - 139s - loss: 0.6272 - accuracy: 0.7120 - auc: 0.7471 - val_loss: 0.6588 - val_accuracy: 0.6250 - val_auc: 0.7104 - 139s/epoch - 9s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6113 - accuracy: 0.7238 - auc: 0.7585 - val_loss: 0.5568 - val_accuracy: 0.7344 - val_auc: 0.8079 - 138s/epoch - 9s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6109 - accuracy: 0.7238 - auc: 0.7602 - val_loss: 0.5192 - val_accuracy: 0.7656 - val_auc: 0.8286 - 138s/epoch - 9s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6037 - accuracy: 0.7420 - auc: 0.7707 - val_loss: 0.5092 - val_accuracy: 0.7812 - val_auc: 0.8328 - 138s/epoch - 9s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6461 - accuracy: 0.7173 - auc: 0.7332 - val_loss: 0.6757 - val_accuracy: 0.6719 - val_auc: 0.6572 - 138s/epoch - 9s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.5990 - accuracy: 0.7302 - auc: 0.7748 - val_loss: 0.6485 - val_accuracy: 0.6875 - val_auc: 0.6870 - 138s/epoch - 9s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6011 - accuracy: 0.7259 - auc: 0.7713 - val_loss: 0.5507 - val_accuracy: 0.7656 - val_auc: 0.7590 - 138s/epoch - 9s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6051 - accuracy: 0.7323 - auc: 0.7699 - val_loss: 0.4915 - val_accuracy: 0.7812 - val_auc: 0.8491 - 138s/epoch - 9s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.5955 - accuracy: 0.7398 - auc: 0.7750 - val_loss: 0.4733 - val_accuracy: 0.8125 - val_auc: 0.8481 - 138s/epoch - 9s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6225 - accuracy: 0.7238 - auc: 0.7529 - val_loss: 0.7150 - val_accuracy: 0.5781 - val_auc: 0.6753 - 138s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.5969 - accuracy: 0.7473 - auc: 0.7771 - val_loss: 0.6016 - val_accuracy: 0.6875 - val_auc: 0.7661 - 138s/epoch - 9s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6353 - accuracy: 0.7163 - auc: 0.7388 - val_loss: 0.4709 - val_accuracy: 0.8125 - val_auc: 0.8730 - 138s/epoch - 9s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6030 - accuracy: 0.7409 - auc: 0.7732 - val_loss: 0.5089 - val_accuracy: 0.7812 - val_auc: 0.8350 - 138s/epoch - 9s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6075 - accuracy: 0.7238 - auc: 0.7630 - val_loss: 0.4987 - val_accuracy: 0.7969 - val_auc: 0.8357 - 138s/epoch - 9s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6093 - accuracy: 0.7291 - auc: 0.7657 - val_loss: 0.5128 - val_accuracy: 0.7969 - val_auc: 0.7944 - 138s/epoch - 9s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6029 - accuracy: 0.7377 - auc: 0.7678 - val_loss: 0.5131 - val_accuracy: 0.7812 - val_auc: 0.8149 - 138s/epoch - 9s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6311 - accuracy: 0.7141 - auc: 0.7437 - val_loss: 0.5090 - val_accuracy: 0.7812 - val_auc: 0.8367 - 138s/epoch - 9s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6213 - accuracy: 0.7163 - auc: 0.7546 - val_loss: 0.5232 - val_accuracy: 0.7500 - val_auc: 0.8269 - 138s/epoch - 9s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.5961 - accuracy: 0.7420 - auc: 0.7738 - val_loss: 0.5044 - val_accuracy: 0.7812 - val_auc: 0.8452 - 138s/epoch - 9s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6113 - accuracy: 0.7388 - auc: 0.7600 - val_loss: 0.4958 - val_accuracy: 0.7969 - val_auc: 0.8167 - 138s/epoch - 9s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6296 - accuracy: 0.7323 - auc: 0.7449 - val_loss: 0.4822 - val_accuracy: 0.8125 - val_auc: 0.8259 - 137s/epoch - 9s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5959 - accuracy: 0.7345 - auc: 0.7756 - val_loss: 0.5007 - val_accuracy: 0.7969 - val_auc: 0.8076 - 137s/epoch - 9s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6162 - accuracy: 0.7398 - auc: 0.7566 - val_loss: 0.5232 - val_accuracy: 0.7656 - val_auc: 0.8154 - 138s/epoch - 9s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6047 - accuracy: 0.7377 - auc: 0.7679 - val_loss: 0.5048 - val_accuracy: 0.7969 - val_auc: 0.8113 - 138s/epoch - 9s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6267 - accuracy: 0.7281 - auc: 0.7459 - val_loss: 0.5354 - val_accuracy: 0.7812 - val_auc: 0.7773 - 138s/epoch - 9s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6263 - accuracy: 0.7345 - auc: 0.7484 - val_loss: 0.5478 - val_accuracy: 0.7344 - val_auc: 0.8157 - 138s/epoch - 9s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6240 - accuracy: 0.7313 - auc: 0.7497 - val_loss: 0.5163 - val_accuracy: 0.7812 - val_auc: 0.8091 - 138s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6043 - accuracy: 0.7377 - auc: 0.7661 - val_loss: 0.5893 - val_accuracy: 0.7031 - val_auc: 0.7805 - 138s/epoch - 9s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6072 - accuracy: 0.7430 - auc: 0.7644 - val_loss: 0.5390 - val_accuracy: 0.7500 - val_auc: 0.8162 - 137s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6263 - accuracy: 0.7281 - auc: 0.7520 - val_loss: 0.5512 - val_accuracy: 0.7344 - val_auc: 0.8052 - 138s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6184 - accuracy: 0.7345 - auc: 0.7543 - val_loss: 0.5144 - val_accuracy: 0.7812 - val_auc: 0.8215 - 138s/epoch - 9s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6056 - accuracy: 0.7441 - auc: 0.7669 - val_loss: 0.5525 - val_accuracy: 0.7344 - val_auc: 0.8125 - 138s/epoch - 9s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.6018 - accuracy: 0.7495 - auc: 0.7698 - val_loss: 0.5205 - val_accuracy: 0.7656 - val_auc: 0.8486 - 138s/epoch - 9s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6070 - accuracy: 0.7377 - auc: 0.7613 - val_loss: 0.5010 - val_accuracy: 0.7812 - val_auc: 0.8401 - 137s/epoch - 9s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6018 - accuracy: 0.7420 - auc: 0.7716 - val_loss: 0.6123 - val_accuracy: 0.6719 - val_auc: 0.7625 - 137s/epoch - 9s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6213 - accuracy: 0.7388 - auc: 0.7500 - val_loss: 0.5664 - val_accuracy: 0.7188 - val_auc: 0.7976 - 137s/epoch - 9s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5977 - accuracy: 0.7505 - auc: 0.7711 - val_loss: 0.5035 - val_accuracy: 0.7969 - val_auc: 0.8076 - 137s/epoch - 9s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5912 - accuracy: 0.7580 - auc: 0.7765 - val_loss: 0.4837 - val_accuracy: 0.8125 - val_auc: 0.8279 - 137s/epoch - 9s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6154 - accuracy: 0.7334 - auc: 0.7593 - val_loss: 0.4918 - val_accuracy: 0.7812 - val_auc: 0.8516 - 137s/epoch - 9s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6419 - accuracy: 0.7131 - auc: 0.7377 - val_loss: 0.4863 - val_accuracy: 0.8125 - val_auc: 0.8237 - 137s/epoch - 9s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5975 - accuracy: 0.7463 - auc: 0.7754 - val_loss: 0.5965 - val_accuracy: 0.7031 - val_auc: 0.7979 - 137s/epoch - 9s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6151 - accuracy: 0.7355 - auc: 0.7568 - val_loss: 0.4981 - val_accuracy: 0.7812 - val_auc: 0.8293 - 137s/epoch - 9s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.5909 - accuracy: 0.7527 - auc: 0.7785 - val_loss: 0.5131 - val_accuracy: 0.7812 - val_auc: 0.8293 - 138s/epoch - 9s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5948 - accuracy: 0.7537 - auc: 0.7706 - val_loss: 0.4944 - val_accuracy: 0.8125 - val_auc: 0.8164 - 137s/epoch - 9s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.5905 - accuracy: 0.7570 - auc: 0.7757 - val_loss: 0.5096 - val_accuracy: 0.7812 - val_auc: 0.8303 - 138s/epoch - 9s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5919 - accuracy: 0.7484 - auc: 0.7805 - val_loss: 0.4657 - val_accuracy: 0.8281 - val_auc: 0.8528 - 137s/epoch - 9s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5984 - accuracy: 0.7495 - auc: 0.7723 - val_loss: 0.5328 - val_accuracy: 0.7500 - val_auc: 0.8333 - 137s/epoch - 9s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.44596\n",
            "15/15 - 138s - loss: 0.5873 - accuracy: 0.7548 - auc: 0.7759 - val_loss: 0.5175 - val_accuracy: 0.7812 - val_auc: 0.8154 - 138s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.6124 - accuracy: 0.7409 - auc: 0.7603 - val_loss: 0.4997 - val_accuracy: 0.7812 - val_auc: 0.8472 - 137s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.44596\n",
            "15/15 - 137s - loss: 0.5971 - accuracy: 0.7473 - auc: 0.7698 - val_loss: 0.4772 - val_accuracy: 0.8125 - val_auc: 0.8521 - 137s/epoch - 9s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [00:51<00:00,  4.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.75\n",
            "Recall: 0.7692\n",
            "Threshold: 0.6001\n",
            "F1 Score: 0.7595\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 7th layer Model Saved'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history7 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history7.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "'''\n",
        "prediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\n",
        "print(\"Chance of being malignant: {:.2f} %\".format(prediction))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yGCZOEC1hmS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNUAqyV21h-D"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1.history['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2.history['accuracy'], label='Layer 2 accuracy')\n",
        "plt.plot(history3.history['accuracy'], label='Layer 3 accuracy')\n",
        "plt.plot(history4.history['accuracy'], label='Layer 4 accuracy')\n",
        "plt.plot(history5.history['accuracy'], label='Layer 5 accuracy')\n",
        "plt.plot(history6.history['accuracy'], label='Layer 6 accuracy')\n",
        "plt.plot(history7.history['accuracy'], label='Layer 7 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 7 Layers Model Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYtX5mkx1h-E"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3.history['val_accuracy'], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4.history['val_accuracy'], label='Layer 4 Val_Accuracy')\n",
        "plt.plot(history5.history['val_accuracy'], label='Layer 5 Val_Accuracy')\n",
        "plt.plot(history6.history['val_accuracy'], label='Layer 6 Val_Accuracy')\n",
        "plt.plot(history7.history['val_accuracy'], label='Layer 7 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 7 Layers Model Val_Accuracy(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igeo7GAk1h-F"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['loss'], label='E2E Loss')\n",
        "plt.plot(history1.history['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2.history['loss'], label='Layer 2 Loss')\n",
        "plt.plot(history3.history['loss'], label='Layer 3 Loss')\n",
        "plt.plot(history4.history['loss'], label='Layer 4 Loss')\n",
        "plt.plot(history5.history['loss'], label='Layer 5 Loss')\n",
        "plt.plot(history6.history['loss'], label='Layer 6 Loss')\n",
        "plt.plot(history7.history['loss'], label='Layer 7 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 7 Layers Model Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxs5K3Tn1h-F"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1.history['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2.history['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3.history['val_loss'], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4.history['val_loss'], label='Layer 4 Val_Loss')\n",
        "plt.plot(history5.history['val_loss'], label='Layer 5 Val_Loss')\n",
        "plt.plot(history6.history['val_loss'], label='Layer 6 Val_Loss')\n",
        "plt.plot(history7.history['val_loss'], label='Layer 7 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 7 Layers Model Val_Loss(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSe6kr241h-F"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['auc'], label='E2E Auc')\n",
        "plt.plot(history1.history['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2.history['auc'], label='Layer 2 Auc')\n",
        "plt.plot(history3.history['auc'], label='Layer 3 Auc')\n",
        "plt.plot(history4.history['auc'], label='Layer 4 Auc')\n",
        "plt.plot(history5.history['auc'], label='Layer 5 Auc')\n",
        "plt.plot(history6.history['auc'], label='Layer 6 Auc')\n",
        "plt.plot(history7.history['auc'], label='Layer 7 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 7 Layers Model Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_VS5Pwt1h-F"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0.history['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1.history['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2.history['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3.history['val_auc'], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4.history['val_auc'], label='Layer 4 Val_Auc')\n",
        "plt.plot(history5.history['val_auc'], label='Layer 5 Val_Auc')\n",
        "plt.plot(history6.history['val_auc'], label='Layer 6 Val_Auc')\n",
        "plt.plot(history7.history['val_auc'], label='Layer 7 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig(CascadeLearning+'/'+' 1 to 7 Layers Model Val_Auc(save_history)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X9Pt_5NUR2s9",
        "outputId": "4b1131c1-8f0d-40f6-ce37-0d1aec6cdee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_4 (Sequential)   (None, 2)                 74978446  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,979,600\n",
            "Trainable params: 51,389,072\n",
            "Non-trainable params: 23,590,528\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: auc improved from inf to 0.51740, saving model to Cascade all Model Layers Graph/2022-08-26_17:01:05-model.hdf5\n",
            "15/15 - 491s - loss: 0.8785 - accuracy: 0.5021 - auc: 0.5174 - val_loss: 0.7132 - val_accuracy: 0.7188 - val_auc: 0.7058 - 491s/epoch - 33s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.8426 - accuracy: 0.5493 - auc: 0.5685 - val_loss: 0.7902 - val_accuracy: 0.7812 - val_auc: 0.8003 - 118s/epoch - 8s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.8556 - accuracy: 0.5482 - auc: 0.5575 - val_loss: 0.7802 - val_accuracy: 0.8125 - val_auc: 0.8323 - 116s/epoch - 8s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.8500 - accuracy: 0.5353 - auc: 0.5526 - val_loss: 0.7744 - val_accuracy: 0.7031 - val_auc: 0.7566 - 116s/epoch - 8s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.8162 - accuracy: 0.5514 - auc: 0.5914 - val_loss: 0.7602 - val_accuracy: 0.7031 - val_auc: 0.7729 - 116s/epoch - 8s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.8100 - accuracy: 0.5685 - auc: 0.5963 - val_loss: 0.7475 - val_accuracy: 0.7656 - val_auc: 0.8298 - 116s/epoch - 8s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.8161 - accuracy: 0.5696 - auc: 0.5813 - val_loss: 0.7443 - val_accuracy: 0.6719 - val_auc: 0.7615 - 116s/epoch - 8s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.8177 - accuracy: 0.5589 - auc: 0.5915 - val_loss: 0.7408 - val_accuracy: 0.6719 - val_auc: 0.7510 - 117s/epoch - 8s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.7948 - accuracy: 0.5792 - auc: 0.6148 - val_loss: 0.7129 - val_accuracy: 0.7656 - val_auc: 0.8276 - 116s/epoch - 8s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.7865 - accuracy: 0.5814 - auc: 0.6072 - val_loss: 0.7045 - val_accuracy: 0.7656 - val_auc: 0.8169 - 116s/epoch - 8s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7931 - accuracy: 0.5814 - auc: 0.6067 - val_loss: 0.8001 - val_accuracy: 0.6094 - val_auc: 0.5942 - 115s/epoch - 8s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7743 - accuracy: 0.5910 - auc: 0.6350 - val_loss: 0.7378 - val_accuracy: 0.7031 - val_auc: 0.6995 - 115s/epoch - 8s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7732 - accuracy: 0.5899 - auc: 0.6313 - val_loss: 0.6856 - val_accuracy: 0.7188 - val_auc: 0.7759 - 115s/epoch - 8s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7641 - accuracy: 0.6092 - auc: 0.6508 - val_loss: 0.6715 - val_accuracy: 0.7500 - val_auc: 0.8191 - 115s/epoch - 8s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7440 - accuracy: 0.6263 - auc: 0.6679 - val_loss: 0.6484 - val_accuracy: 0.8125 - val_auc: 0.8311 - 115s/epoch - 8s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7421 - accuracy: 0.6156 - auc: 0.6642 - val_loss: 0.6441 - val_accuracy: 0.7812 - val_auc: 0.8330 - 115s/epoch - 8s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7412 - accuracy: 0.6135 - auc: 0.6671 - val_loss: 0.6445 - val_accuracy: 0.7656 - val_auc: 0.8210 - 115s/epoch - 8s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7477 - accuracy: 0.6017 - auc: 0.6509 - val_loss: 0.6361 - val_accuracy: 0.7656 - val_auc: 0.8210 - 115s/epoch - 8s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7237 - accuracy: 0.6349 - auc: 0.6862 - val_loss: 0.6404 - val_accuracy: 0.7344 - val_auc: 0.8193 - 115s/epoch - 8s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7263 - accuracy: 0.6360 - auc: 0.6821 - val_loss: 0.6298 - val_accuracy: 0.7656 - val_auc: 0.8066 - 115s/epoch - 8s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7427 - accuracy: 0.6103 - auc: 0.6532 - val_loss: 0.6336 - val_accuracy: 0.7500 - val_auc: 0.7832 - 115s/epoch - 8s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7144 - accuracy: 0.6445 - auc: 0.6905 - val_loss: 0.5893 - val_accuracy: 0.8125 - val_auc: 0.8455 - 115s/epoch - 8s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7300 - accuracy: 0.6317 - auc: 0.6672 - val_loss: 0.6602 - val_accuracy: 0.7188 - val_auc: 0.7090 - 115s/epoch - 8s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7159 - accuracy: 0.6296 - auc: 0.6814 - val_loss: 0.5865 - val_accuracy: 0.7969 - val_auc: 0.8269 - 115s/epoch - 8s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6928 - accuracy: 0.6595 - auc: 0.7063 - val_loss: 0.5793 - val_accuracy: 0.7969 - val_auc: 0.8291 - 115s/epoch - 8s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6980 - accuracy: 0.6435 - auc: 0.6996 - val_loss: 0.6254 - val_accuracy: 0.7500 - val_auc: 0.7385 - 115s/epoch - 8s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7031 - accuracy: 0.6478 - auc: 0.6975 - val_loss: 0.5778 - val_accuracy: 0.7969 - val_auc: 0.8147 - 115s/epoch - 8s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7109 - accuracy: 0.6510 - auc: 0.6924 - val_loss: 0.5683 - val_accuracy: 0.7969 - val_auc: 0.8250 - 115s/epoch - 8s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7054 - accuracy: 0.6510 - auc: 0.6939 - val_loss: 0.5738 - val_accuracy: 0.7812 - val_auc: 0.8149 - 115s/epoch - 8s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6900 - accuracy: 0.6499 - auc: 0.7079 - val_loss: 0.5788 - val_accuracy: 0.7656 - val_auc: 0.8110 - 115s/epoch - 8s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.7061 - accuracy: 0.6424 - auc: 0.6918 - val_loss: 0.6664 - val_accuracy: 0.6875 - val_auc: 0.6675 - 115s/epoch - 8s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6754 - accuracy: 0.6595 - auc: 0.7182 - val_loss: 0.5663 - val_accuracy: 0.7812 - val_auc: 0.8037 - 115s/epoch - 8s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6803 - accuracy: 0.6777 - auc: 0.7126 - val_loss: 0.5618 - val_accuracy: 0.7812 - val_auc: 0.8171 - 115s/epoch - 8s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6649 - accuracy: 0.6767 - auc: 0.7286 - val_loss: 0.5473 - val_accuracy: 0.7969 - val_auc: 0.8140 - 115s/epoch - 8s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6818 - accuracy: 0.6660 - auc: 0.7091 - val_loss: 0.6617 - val_accuracy: 0.6250 - val_auc: 0.7236 - 115s/epoch - 8s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6526 - accuracy: 0.6949 - auc: 0.7490 - val_loss: 0.6267 - val_accuracy: 0.6719 - val_auc: 0.7432 - 115s/epoch - 8s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6847 - accuracy: 0.6702 - auc: 0.7118 - val_loss: 0.5960 - val_accuracy: 0.7188 - val_auc: 0.7693 - 115s/epoch - 8s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6905 - accuracy: 0.6595 - auc: 0.6987 - val_loss: 0.5448 - val_accuracy: 0.7812 - val_auc: 0.8105 - 115s/epoch - 8s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6468 - accuracy: 0.7109 - auc: 0.7480 - val_loss: 0.5191 - val_accuracy: 0.8125 - val_auc: 0.8306 - 115s/epoch - 8s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6561 - accuracy: 0.6938 - auc: 0.7379 - val_loss: 0.6688 - val_accuracy: 0.6094 - val_auc: 0.6907 - 115s/epoch - 8s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6744 - accuracy: 0.6820 - auc: 0.7159 - val_loss: 0.7075 - val_accuracy: 0.5625 - val_auc: 0.6240 - 116s/epoch - 8s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6842 - accuracy: 0.6660 - auc: 0.7067 - val_loss: 0.6562 - val_accuracy: 0.6250 - val_auc: 0.7256 - 115s/epoch - 8s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6696 - accuracy: 0.6820 - auc: 0.7231 - val_loss: 0.5261 - val_accuracy: 0.7969 - val_auc: 0.8125 - 115s/epoch - 8s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6650 - accuracy: 0.6831 - auc: 0.7235 - val_loss: 0.6687 - val_accuracy: 0.6719 - val_auc: 0.6548 - 115s/epoch - 8s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6565 - accuracy: 0.6938 - auc: 0.7305 - val_loss: 0.5835 - val_accuracy: 0.7344 - val_auc: 0.7454 - 115s/epoch - 8s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6530 - accuracy: 0.7056 - auc: 0.7391 - val_loss: 0.5903 - val_accuracy: 0.7031 - val_auc: 0.7822 - 115s/epoch - 8s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6602 - accuracy: 0.7034 - auc: 0.7306 - val_loss: 0.5880 - val_accuracy: 0.7031 - val_auc: 0.7742 - 116s/epoch - 8s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6539 - accuracy: 0.6906 - auc: 0.7329 - val_loss: 0.5405 - val_accuracy: 0.7812 - val_auc: 0.8098 - 116s/epoch - 8s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6665 - accuracy: 0.6927 - auc: 0.7194 - val_loss: 0.5635 - val_accuracy: 0.7344 - val_auc: 0.7949 - 116s/epoch - 8s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6768 - accuracy: 0.6863 - auc: 0.7109 - val_loss: 0.6265 - val_accuracy: 0.7031 - val_auc: 0.6965 - 115s/epoch - 8s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6541 - accuracy: 0.6842 - auc: 0.7378 - val_loss: 0.5765 - val_accuracy: 0.7500 - val_auc: 0.7485 - 115s/epoch - 8s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6469 - accuracy: 0.7099 - auc: 0.7411 - val_loss: 0.5862 - val_accuracy: 0.7188 - val_auc: 0.7612 - 115s/epoch - 8s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6599 - accuracy: 0.7099 - auc: 0.7258 - val_loss: 0.5894 - val_accuracy: 0.7344 - val_auc: 0.7283 - 115s/epoch - 8s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6524 - accuracy: 0.7024 - auc: 0.7332 - val_loss: 0.6833 - val_accuracy: 0.6562 - val_auc: 0.6636 - 115s/epoch - 8s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6565 - accuracy: 0.7088 - auc: 0.7383 - val_loss: 0.5350 - val_accuracy: 0.7656 - val_auc: 0.8040 - 115s/epoch - 8s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6540 - accuracy: 0.7045 - auc: 0.7331 - val_loss: 0.5418 - val_accuracy: 0.7500 - val_auc: 0.8176 - 115s/epoch - 8s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6646 - accuracy: 0.6906 - auc: 0.7232 - val_loss: 0.5609 - val_accuracy: 0.7344 - val_auc: 0.7927 - 115s/epoch - 8s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6417 - accuracy: 0.7120 - auc: 0.7444 - val_loss: 0.5318 - val_accuracy: 0.7656 - val_auc: 0.8093 - 115s/epoch - 8s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6693 - accuracy: 0.6895 - auc: 0.7153 - val_loss: 0.5406 - val_accuracy: 0.7812 - val_auc: 0.7642 - 115s/epoch - 8s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6465 - accuracy: 0.6970 - auc: 0.7409 - val_loss: 0.5437 - val_accuracy: 0.7812 - val_auc: 0.7646 - 118s/epoch - 8s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6566 - accuracy: 0.6916 - auc: 0.7269 - val_loss: 0.5334 - val_accuracy: 0.7656 - val_auc: 0.8083 - 118s/epoch - 8s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: auc did not improve from 0.51740\n",
            "15/15 - 119s - loss: 0.6693 - accuracy: 0.6799 - auc: 0.7160 - val_loss: 0.5583 - val_accuracy: 0.7500 - val_auc: 0.7891 - 119s/epoch - 8s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6552 - accuracy: 0.7024 - auc: 0.7290 - val_loss: 0.5483 - val_accuracy: 0.7500 - val_auc: 0.8257 - 118s/epoch - 8s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6556 - accuracy: 0.6970 - auc: 0.7291 - val_loss: 0.5340 - val_accuracy: 0.7656 - val_auc: 0.8066 - 118s/epoch - 8s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6522 - accuracy: 0.7141 - auc: 0.7289 - val_loss: 0.6625 - val_accuracy: 0.6875 - val_auc: 0.6611 - 117s/epoch - 8s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6546 - accuracy: 0.6938 - auc: 0.7335 - val_loss: 0.5272 - val_accuracy: 0.7812 - val_auc: 0.7964 - 117s/epoch - 8s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6635 - accuracy: 0.6916 - auc: 0.7220 - val_loss: 0.5334 - val_accuracy: 0.7812 - val_auc: 0.7920 - 117s/epoch - 8s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6729 - accuracy: 0.6820 - auc: 0.7140 - val_loss: 0.5394 - val_accuracy: 0.7812 - val_auc: 0.7781 - 118s/epoch - 8s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6442 - accuracy: 0.7045 - auc: 0.7412 - val_loss: 0.6169 - val_accuracy: 0.6719 - val_auc: 0.7358 - 117s/epoch - 8s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6580 - accuracy: 0.7013 - auc: 0.7274 - val_loss: 0.6181 - val_accuracy: 0.6719 - val_auc: 0.7441 - 117s/epoch - 8s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6579 - accuracy: 0.6981 - auc: 0.7251 - val_loss: 0.5980 - val_accuracy: 0.6875 - val_auc: 0.7749 - 118s/epoch - 8s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6624 - accuracy: 0.6884 - auc: 0.7168 - val_loss: 0.5643 - val_accuracy: 0.7344 - val_auc: 0.7991 - 117s/epoch - 8s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6550 - accuracy: 0.6981 - auc: 0.7330 - val_loss: 0.6116 - val_accuracy: 0.6719 - val_auc: 0.7668 - 116s/epoch - 8s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6340 - accuracy: 0.7088 - auc: 0.7465 - val_loss: 0.5640 - val_accuracy: 0.7344 - val_auc: 0.7766 - 116s/epoch - 8s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6282 - accuracy: 0.7099 - auc: 0.7543 - val_loss: 0.5161 - val_accuracy: 0.7812 - val_auc: 0.8242 - 117s/epoch - 8s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6332 - accuracy: 0.7195 - auc: 0.7482 - val_loss: 0.5095 - val_accuracy: 0.7969 - val_auc: 0.8010 - 118s/epoch - 8s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6551 - accuracy: 0.7034 - auc: 0.7285 - val_loss: 0.5716 - val_accuracy: 0.7500 - val_auc: 0.7734 - 117s/epoch - 8s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: auc did not improve from 0.51740\n",
            "15/15 - 119s - loss: 0.6277 - accuracy: 0.7152 - auc: 0.7551 - val_loss: 0.5092 - val_accuracy: 0.7812 - val_auc: 0.8181 - 119s/epoch - 8s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: auc did not improve from 0.51740\n",
            "15/15 - 119s - loss: 0.6324 - accuracy: 0.7206 - auc: 0.7476 - val_loss: 0.5157 - val_accuracy: 0.7812 - val_auc: 0.8169 - 119s/epoch - 8s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: auc did not improve from 0.51740\n",
            "15/15 - 119s - loss: 0.6523 - accuracy: 0.7045 - auc: 0.7357 - val_loss: 0.5609 - val_accuracy: 0.7188 - val_auc: 0.8074 - 119s/epoch - 8s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6604 - accuracy: 0.6863 - auc: 0.7220 - val_loss: 0.5603 - val_accuracy: 0.7344 - val_auc: 0.8083 - 118s/epoch - 8s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: auc did not improve from 0.51740\n",
            "15/15 - 119s - loss: 0.6668 - accuracy: 0.6970 - auc: 0.7187 - val_loss: 0.5847 - val_accuracy: 0.7500 - val_auc: 0.7549 - 119s/epoch - 8s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6499 - accuracy: 0.7024 - auc: 0.7376 - val_loss: 0.5204 - val_accuracy: 0.7812 - val_auc: 0.8105 - 117s/epoch - 8s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6523 - accuracy: 0.6927 - auc: 0.7299 - val_loss: 0.5338 - val_accuracy: 0.7656 - val_auc: 0.8047 - 116s/epoch - 8s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6412 - accuracy: 0.7077 - auc: 0.7413 - val_loss: 0.5232 - val_accuracy: 0.7812 - val_auc: 0.8054 - 115s/epoch - 8s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6695 - accuracy: 0.6734 - auc: 0.7127 - val_loss: 0.6200 - val_accuracy: 0.6719 - val_auc: 0.7390 - 115s/epoch - 8s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6676 - accuracy: 0.6895 - auc: 0.7139 - val_loss: 0.5631 - val_accuracy: 0.7344 - val_auc: 0.7886 - 115s/epoch - 8s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6377 - accuracy: 0.7013 - auc: 0.7462 - val_loss: 0.5582 - val_accuracy: 0.7656 - val_auc: 0.7668 - 115s/epoch - 8s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6589 - accuracy: 0.7045 - auc: 0.7247 - val_loss: 0.5607 - val_accuracy: 0.7344 - val_auc: 0.7917 - 115s/epoch - 8s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6821 - accuracy: 0.6831 - auc: 0.7021 - val_loss: 0.5549 - val_accuracy: 0.7500 - val_auc: 0.7786 - 116s/epoch - 8s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6655 - accuracy: 0.6970 - auc: 0.7147 - val_loss: 0.5518 - val_accuracy: 0.7344 - val_auc: 0.8049 - 117s/epoch - 8s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6547 - accuracy: 0.6916 - auc: 0.7319 - val_loss: 0.5283 - val_accuracy: 0.7812 - val_auc: 0.7910 - 117s/epoch - 8s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6484 - accuracy: 0.6916 - auc: 0.7263 - val_loss: 0.5579 - val_accuracy: 0.7500 - val_auc: 0.7837 - 116s/epoch - 8s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6270 - accuracy: 0.7206 - auc: 0.7552 - val_loss: 0.5262 - val_accuracy: 0.7500 - val_auc: 0.8440 - 116s/epoch - 8s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6487 - accuracy: 0.6938 - auc: 0.7315 - val_loss: 0.5538 - val_accuracy: 0.7188 - val_auc: 0.8132 - 115s/epoch - 8s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6505 - accuracy: 0.6906 - auc: 0.7277 - val_loss: 0.6394 - val_accuracy: 0.6406 - val_auc: 0.7175 - 115s/epoch - 8s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6502 - accuracy: 0.7173 - auc: 0.7330 - val_loss: 0.5742 - val_accuracy: 0.7031 - val_auc: 0.7942 - 115s/epoch - 8s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6432 - accuracy: 0.7045 - auc: 0.7355 - val_loss: 0.5210 - val_accuracy: 0.7969 - val_auc: 0.7976 - 115s/epoch - 8s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6571 - accuracy: 0.6938 - auc: 0.7233 - val_loss: 0.4985 - val_accuracy: 0.8125 - val_auc: 0.8008 - 117s/epoch - 8s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6180 - accuracy: 0.7259 - auc: 0.7555 - val_loss: 0.4988 - val_accuracy: 0.7969 - val_auc: 0.8396 - 118s/epoch - 8s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6470 - accuracy: 0.7066 - auc: 0.7337 - val_loss: 0.7501 - val_accuracy: 0.5312 - val_auc: 0.5986 - 117s/epoch - 8s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6465 - accuracy: 0.7056 - auc: 0.7380 - val_loss: 0.5810 - val_accuracy: 0.7031 - val_auc: 0.7820 - 117s/epoch - 8s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6331 - accuracy: 0.7109 - auc: 0.7497 - val_loss: 0.5405 - val_accuracy: 0.7500 - val_auc: 0.8018 - 117s/epoch - 8s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6206 - accuracy: 0.7238 - auc: 0.7618 - val_loss: 0.6377 - val_accuracy: 0.6406 - val_auc: 0.7170 - 117s/epoch - 8s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6353 - accuracy: 0.7099 - auc: 0.7445 - val_loss: 0.6280 - val_accuracy: 0.6562 - val_auc: 0.7217 - 117s/epoch - 8s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6360 - accuracy: 0.7152 - auc: 0.7462 - val_loss: 0.4973 - val_accuracy: 0.7969 - val_auc: 0.8215 - 117s/epoch - 8s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6296 - accuracy: 0.7227 - auc: 0.7466 - val_loss: 0.7408 - val_accuracy: 0.6562 - val_auc: 0.6240 - 116s/epoch - 8s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6502 - accuracy: 0.6991 - auc: 0.7277 - val_loss: 0.6673 - val_accuracy: 0.7031 - val_auc: 0.6677 - 117s/epoch - 8s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6421 - accuracy: 0.7152 - auc: 0.7379 - val_loss: 0.5361 - val_accuracy: 0.7812 - val_auc: 0.7788 - 117s/epoch - 8s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6417 - accuracy: 0.7131 - auc: 0.7415 - val_loss: 0.5419 - val_accuracy: 0.7656 - val_auc: 0.7844 - 116s/epoch - 8s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6249 - accuracy: 0.7302 - auc: 0.7557 - val_loss: 0.7620 - val_accuracy: 0.6406 - val_auc: 0.6125 - 116s/epoch - 8s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6310 - accuracy: 0.7152 - auc: 0.7474 - val_loss: 0.5153 - val_accuracy: 0.8125 - val_auc: 0.7871 - 115s/epoch - 8s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6516 - accuracy: 0.7066 - auc: 0.7348 - val_loss: 0.5223 - val_accuracy: 0.7656 - val_auc: 0.8127 - 116s/epoch - 8s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6256 - accuracy: 0.7206 - auc: 0.7512 - val_loss: 0.5234 - val_accuracy: 0.7656 - val_auc: 0.8125 - 117s/epoch - 8s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6278 - accuracy: 0.7313 - auc: 0.7570 - val_loss: 0.5727 - val_accuracy: 0.7344 - val_auc: 0.7671 - 117s/epoch - 8s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6432 - accuracy: 0.7024 - auc: 0.7410 - val_loss: 0.5309 - val_accuracy: 0.7656 - val_auc: 0.8145 - 117s/epoch - 8s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6143 - accuracy: 0.7302 - auc: 0.7618 - val_loss: 0.5006 - val_accuracy: 0.8125 - val_auc: 0.8047 - 117s/epoch - 8s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6325 - accuracy: 0.7173 - auc: 0.7506 - val_loss: 0.5596 - val_accuracy: 0.7344 - val_auc: 0.7898 - 117s/epoch - 8s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6260 - accuracy: 0.7120 - auc: 0.7533 - val_loss: 0.6381 - val_accuracy: 0.6562 - val_auc: 0.7109 - 117s/epoch - 8s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6368 - accuracy: 0.6981 - auc: 0.7454 - val_loss: 0.6283 - val_accuracy: 0.6562 - val_auc: 0.7471 - 117s/epoch - 8s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6557 - accuracy: 0.7013 - auc: 0.7285 - val_loss: 0.5649 - val_accuracy: 0.7188 - val_auc: 0.7842 - 118s/epoch - 8s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6332 - accuracy: 0.7195 - auc: 0.7525 - val_loss: 0.5393 - val_accuracy: 0.7656 - val_auc: 0.7896 - 116s/epoch - 8s/step\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6042 - accuracy: 0.7323 - auc: 0.7721 - val_loss: 0.5094 - val_accuracy: 0.7969 - val_auc: 0.8140 - 116s/epoch - 8s/step\n",
            "Epoch 124/150\n",
            "\n",
            "Epoch 124: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6435 - accuracy: 0.7045 - auc: 0.7365 - val_loss: 0.5687 - val_accuracy: 0.7188 - val_auc: 0.7925 - 116s/epoch - 8s/step\n",
            "Epoch 125/150\n",
            "\n",
            "Epoch 125: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6481 - accuracy: 0.7088 - auc: 0.7381 - val_loss: 0.5625 - val_accuracy: 0.7188 - val_auc: 0.7944 - 116s/epoch - 8s/step\n",
            "Epoch 126/150\n",
            "\n",
            "Epoch 126: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6521 - accuracy: 0.7034 - auc: 0.7281 - val_loss: 0.5109 - val_accuracy: 0.7969 - val_auc: 0.8159 - 115s/epoch - 8s/step\n",
            "Epoch 127/150\n",
            "\n",
            "Epoch 127: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6187 - accuracy: 0.7206 - auc: 0.7568 - val_loss: 0.5431 - val_accuracy: 0.7656 - val_auc: 0.7927 - 115s/epoch - 8s/step\n",
            "Epoch 128/150\n",
            "\n",
            "Epoch 128: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6241 - accuracy: 0.7184 - auc: 0.7552 - val_loss: 0.5071 - val_accuracy: 0.7812 - val_auc: 0.8213 - 115s/epoch - 8s/step\n",
            "Epoch 129/150\n",
            "\n",
            "Epoch 129: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6401 - accuracy: 0.7184 - auc: 0.7417 - val_loss: 0.5237 - val_accuracy: 0.7656 - val_auc: 0.8210 - 115s/epoch - 8s/step\n",
            "Epoch 130/150\n",
            "\n",
            "Epoch 130: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6686 - accuracy: 0.6991 - auc: 0.7146 - val_loss: 0.4749 - val_accuracy: 0.8125 - val_auc: 0.8418 - 115s/epoch - 8s/step\n",
            "Epoch 131/150\n",
            "\n",
            "Epoch 131: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6457 - accuracy: 0.7099 - auc: 0.7317 - val_loss: 0.4914 - val_accuracy: 0.7969 - val_auc: 0.8284 - 115s/epoch - 8s/step\n",
            "Epoch 132/150\n",
            "\n",
            "Epoch 132: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6508 - accuracy: 0.7045 - auc: 0.7245 - val_loss: 0.5330 - val_accuracy: 0.7969 - val_auc: 0.7737 - 115s/epoch - 8s/step\n",
            "Epoch 133/150\n",
            "\n",
            "Epoch 133: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6357 - accuracy: 0.7141 - auc: 0.7402 - val_loss: 0.5404 - val_accuracy: 0.7500 - val_auc: 0.8086 - 115s/epoch - 8s/step\n",
            "Epoch 134/150\n",
            "\n",
            "Epoch 134: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6272 - accuracy: 0.7248 - auc: 0.7474 - val_loss: 0.6860 - val_accuracy: 0.5938 - val_auc: 0.6577 - 115s/epoch - 8s/step\n",
            "Epoch 135/150\n",
            "\n",
            "Epoch 135: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6353 - accuracy: 0.7141 - auc: 0.7414 - val_loss: 0.5517 - val_accuracy: 0.7344 - val_auc: 0.7974 - 115s/epoch - 8s/step\n",
            "Epoch 136/150\n",
            "\n",
            "Epoch 136: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6388 - accuracy: 0.7248 - auc: 0.7409 - val_loss: 0.5424 - val_accuracy: 0.7500 - val_auc: 0.7969 - 115s/epoch - 8s/step\n",
            "Epoch 137/150\n",
            "\n",
            "Epoch 137: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6472 - accuracy: 0.7099 - auc: 0.7334 - val_loss: 0.5241 - val_accuracy: 0.7812 - val_auc: 0.8064 - 116s/epoch - 8s/step\n",
            "Epoch 138/150\n",
            "\n",
            "Epoch 138: auc did not improve from 0.51740\n",
            "15/15 - 118s - loss: 0.6424 - accuracy: 0.7066 - auc: 0.7354 - val_loss: 0.5270 - val_accuracy: 0.7812 - val_auc: 0.7949 - 118s/epoch - 8s/step\n",
            "Epoch 139/150\n",
            "\n",
            "Epoch 139: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6210 - accuracy: 0.7206 - auc: 0.7595 - val_loss: 0.5394 - val_accuracy: 0.7500 - val_auc: 0.8174 - 116s/epoch - 8s/step\n",
            "Epoch 140/150\n",
            "\n",
            "Epoch 140: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6287 - accuracy: 0.7238 - auc: 0.7455 - val_loss: 0.6927 - val_accuracy: 0.5938 - val_auc: 0.6577 - 117s/epoch - 8s/step\n",
            "Epoch 141/150\n",
            "\n",
            "Epoch 141: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6358 - accuracy: 0.7099 - auc: 0.7465 - val_loss: 0.5565 - val_accuracy: 0.7344 - val_auc: 0.7898 - 117s/epoch - 8s/step\n",
            "Epoch 142/150\n",
            "\n",
            "Epoch 142: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6366 - accuracy: 0.7120 - auc: 0.7368 - val_loss: 0.5580 - val_accuracy: 0.7344 - val_auc: 0.7898 - 117s/epoch - 8s/step\n",
            "Epoch 143/150\n",
            "\n",
            "Epoch 143: auc did not improve from 0.51740\n",
            "15/15 - 117s - loss: 0.6361 - accuracy: 0.7152 - auc: 0.7446 - val_loss: 0.7608 - val_accuracy: 0.6562 - val_auc: 0.6240 - 117s/epoch - 8s/step\n",
            "Epoch 144/150\n",
            "\n",
            "Epoch 144: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6464 - accuracy: 0.7120 - auc: 0.7358 - val_loss: 0.5562 - val_accuracy: 0.7656 - val_auc: 0.7759 - 115s/epoch - 8s/step\n",
            "Epoch 145/150\n",
            "\n",
            "Epoch 145: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6311 - accuracy: 0.7281 - auc: 0.7496 - val_loss: 0.5348 - val_accuracy: 0.7500 - val_auc: 0.8047 - 115s/epoch - 8s/step\n",
            "Epoch 146/150\n",
            "\n",
            "Epoch 146: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6513 - accuracy: 0.7077 - auc: 0.7287 - val_loss: 0.5514 - val_accuracy: 0.7344 - val_auc: 0.7974 - 115s/epoch - 8s/step\n",
            "Epoch 147/150\n",
            "\n",
            "Epoch 147: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6248 - accuracy: 0.7141 - auc: 0.7525 - val_loss: 0.5237 - val_accuracy: 0.7656 - val_auc: 0.8093 - 115s/epoch - 8s/step\n",
            "Epoch 148/150\n",
            "\n",
            "Epoch 148: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.6344 - accuracy: 0.7238 - auc: 0.7420 - val_loss: 0.5272 - val_accuracy: 0.7812 - val_auc: 0.7917 - 115s/epoch - 8s/step\n",
            "Epoch 149/150\n",
            "\n",
            "Epoch 149: auc did not improve from 0.51740\n",
            "15/15 - 115s - loss: 0.5998 - accuracy: 0.7345 - auc: 0.7770 - val_loss: 0.5580 - val_accuracy: 0.7344 - val_auc: 0.7881 - 115s/epoch - 8s/step\n",
            "Epoch 150/150\n",
            "\n",
            "Epoch 150: auc did not improve from 0.51740\n",
            "15/15 - 116s - loss: 0.6137 - accuracy: 0.7281 - auc: 0.7591 - val_loss: 0.7410 - val_accuracy: 0.6719 - val_auc: 0.6414 - 116s/epoch - 8s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [01:54<00:00,  2.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "Threshold: 0.2814\n",
            "F1 Score: 0.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10982/10982 [2:03:01<00:00,  1.49it/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n\\n\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_Name='Pretrained plus 7th layer Model Saved'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 8th layer Model Saved'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history8 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history8.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./Pretrained Model_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMhTNMWxKy6m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKEVvqfK2np9"
      },
      "source": [
        "#Training the model with ResNet(150 Epohs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH4kT_brC7fR"
      },
      "outputs": [],
      "source": [
        "Model_Name='ResNet Model Saved'\n",
        "ResNet50 = ResNet50(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "for layer in ResNet50.layers[:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "for idx, layer in enumerate(ResNet50.layers[:]):\n",
        "    print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "\n",
        "model = create_model_ResNet()\n",
        "print('create model')\n",
        "\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history0 = model.fit(\n",
        "        train_gen, epochs=150, verbose=VERBOSE_LEVEL, validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history0.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./ResNet_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eUZdy98N0Eq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvoVuczoN0Bo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOox3sf3pawh"
      },
      "source": [
        "#Training the model with VGG(150 Epohs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1u37jYS4Jr0"
      },
      "outputs": [],
      "source": [
        "Model_Name='VGG Model Saved'\n",
        "model = create_model_VGG()\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history0 = model.fit(train_gen, epochs=150, verbose=VERBOSE_LEVEL, validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history0.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./VGG_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOr8pUdfpYnp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxnAhTM89Cjb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HjhUC8dAMPV"
      },
      "source": [
        "#Testing moels on Balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7xZ4rjLEUQW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ThPcjP0EUnj",
        "outputId": "0ee9439f-03fe-4987-c059-a3778ac56738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "layer 1 : input_1 is trainable: True\n",
            "layer 2 : block1_conv1 is trainable: True\n",
            "layer 3 : block1_conv2 is trainable: True\n",
            "layer 4 : block1_pool is trainable: True\n",
            "layer 5 : block2_conv1 is trainable: True\n",
            "layer 6 : block2_conv2 is trainable: True\n",
            "layer 7 : block2_pool is trainable: True\n",
            "layer 8 : block3_conv1 is trainable: True\n",
            "layer 9 : block3_conv2 is trainable: True\n",
            "layer 10 : block3_conv3 is trainable: True\n",
            "layer 11 : block3_pool is trainable: True\n",
            "layer 12 : block4_conv1 is trainable: True\n",
            "layer 13 : block4_conv2 is trainable: True\n",
            "layer 14 : block4_conv3 is trainable: True\n",
            "layer 15 : block4_pool is trainable: True\n",
            "layer 16 : block5_conv1 is trainable: True\n",
            "layer 17 : block5_conv2 is trainable: True\n",
            "layer 18 : block5_conv3 is trainable: True\n",
            "layer 19 : block5_pool is trainable: True\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 14,764,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "rows in train_df 966\n",
            "rows in val_df 242\n",
            "Found 966 non-validated image filenames.\n",
            "Found 242 non-validated image filenames.\n",
            "16/16 - 134s - loss: 0.8113 - accuracy: 0.5124 - val_loss: 0.6903 - val_accuracy: 0.5469 - 134s/epoch - 8s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 242/242 [00:43<00:00,  5.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5083\n",
            "Recall: 1.0\n",
            "Threshold: 1\n",
            "F1 Score: 0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1168/1168 [03:37<00:00,  5.37it/s]\n"
          ]
        }
      ],
      "source": [
        "Model_Name='Melignant Model Saved'\n",
        "model = create_model_malignant()\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "historyMalignant = model.fit(train_gen, epochs=1, verbose=VERBOSE_LEVEL, validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "#save_history(historyMalignant.history, timestamp,Model_Name)\n",
        "#plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,len(y_p)):\n",
        "  y_p[i]=1\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./Malignant_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dG0WMk7evBaX",
        "outputId": "a37abe15-4167-4747-9ca1-cdf4090ed4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "layer 1 : input_5 is trainable: True\n",
            "layer 2 : conv1_pad is trainable: True\n",
            "layer 3 : conv1_conv is trainable: True\n",
            "layer 4 : conv1_bn is trainable: True\n",
            "layer 5 : conv1_relu is trainable: True\n",
            "layer 6 : pool1_pad is trainable: True\n",
            "layer 7 : pool1_pool is trainable: True\n",
            "layer 8 : conv2_block1_1_conv is trainable: True\n",
            "layer 9 : conv2_block1_1_bn is trainable: True\n",
            "layer 10 : conv2_block1_1_relu is trainable: True\n",
            "rows in train_df 966\n",
            "rows in val_df 242\n",
            "Found 966 non-validated image filenames.\n",
            "Found 242 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.73700, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 151s - loss: 0.8419 - accuracy: 0.5197 - auc: 0.5304 - val_loss: 0.7370 - val_accuracy: 0.5469 - val_auc: 0.5574 - 151s/epoch - 9s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.73700\n",
            "16/16 - 139s - loss: 0.8562 - accuracy: 0.4948 - auc: 0.4969 - val_loss: 0.7372 - val_accuracy: 0.4844 - val_auc: 0.4805 - 139s/epoch - 9s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss improved from 0.73700 to 0.73401, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 143s - loss: 0.8291 - accuracy: 0.5280 - auc: 0.5383 - val_loss: 0.7340 - val_accuracy: 0.4531 - val_auc: 0.4425 - 143s/epoch - 9s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss improved from 0.73401 to 0.72642, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 140s - loss: 0.8323 - accuracy: 0.5331 - auc: 0.5416 - val_loss: 0.7264 - val_accuracy: 0.5469 - val_auc: 0.5588 - 140s/epoch - 9s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.72642\n",
            "16/16 - 139s - loss: 0.8179 - accuracy: 0.5166 - auc: 0.5370 - val_loss: 0.7314 - val_accuracy: 0.5469 - val_auc: 0.4877 - 139s/epoch - 9s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.72642\n",
            "16/16 - 138s - loss: 0.8174 - accuracy: 0.5072 - auc: 0.5280 - val_loss: 0.7309 - val_accuracy: 0.5469 - val_auc: 0.5354 - 138s/epoch - 9s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.72642\n",
            "16/16 - 138s - loss: 0.8420 - accuracy: 0.5052 - auc: 0.4950 - val_loss: 0.7380 - val_accuracy: 0.4844 - val_auc: 0.4794 - 138s/epoch - 9s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.72642\n",
            "16/16 - 136s - loss: 0.8348 - accuracy: 0.4834 - auc: 0.5041 - val_loss: 0.7327 - val_accuracy: 0.4688 - val_auc: 0.5577 - 136s/epoch - 9s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.72642\n",
            "16/16 - 135s - loss: 0.8289 - accuracy: 0.5083 - auc: 0.5202 - val_loss: 0.7278 - val_accuracy: 0.5000 - val_auc: 0.4547 - 135s/epoch - 8s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.72642\n",
            "16/16 - 136s - loss: 0.8096 - accuracy: 0.5124 - auc: 0.5322 - val_loss: 0.7294 - val_accuracy: 0.5469 - val_auc: 0.5105 - 136s/epoch - 9s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.72642\n",
            "16/16 - 136s - loss: 0.7993 - accuracy: 0.5331 - auc: 0.5533 - val_loss: 0.7477 - val_accuracy: 0.5469 - val_auc: 0.4958 - 136s/epoch - 8s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.72642\n",
            "16/16 - 136s - loss: 0.8125 - accuracy: 0.5238 - auc: 0.5403 - val_loss: 0.7461 - val_accuracy: 0.4531 - val_auc: 0.4216 - 136s/epoch - 8s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.72642\n",
            "16/16 - 137s - loss: 0.7997 - accuracy: 0.5083 - auc: 0.5384 - val_loss: 0.7431 - val_accuracy: 0.4531 - val_auc: 0.4003 - 137s/epoch - 9s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss improved from 0.72642 to 0.71468, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 143s - loss: 0.8054 - accuracy: 0.5010 - auc: 0.5361 - val_loss: 0.7147 - val_accuracy: 0.4688 - val_auc: 0.3898 - 143s/epoch - 9s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss improved from 0.71468 to 0.70630, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 142s - loss: 0.7896 - accuracy: 0.5207 - auc: 0.5478 - val_loss: 0.7063 - val_accuracy: 0.5469 - val_auc: 0.4983 - 142s/epoch - 9s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.70630\n",
            "16/16 - 138s - loss: 0.8056 - accuracy: 0.5321 - auc: 0.5457 - val_loss: 0.7081 - val_accuracy: 0.3750 - val_auc: 0.3536 - 138s/epoch - 9s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.70630\n",
            "16/16 - 138s - loss: 0.7950 - accuracy: 0.5207 - auc: 0.5540 - val_loss: 0.7078 - val_accuracy: 0.5156 - val_auc: 0.4135 - 138s/epoch - 9s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.70630\n",
            "16/16 - 136s - loss: 0.7998 - accuracy: 0.5300 - auc: 0.5460 - val_loss: 0.7240 - val_accuracy: 0.4531 - val_auc: 0.4172 - 136s/epoch - 8s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.70630\n",
            "16/16 - 135s - loss: 0.7666 - accuracy: 0.5476 - auc: 0.5822 - val_loss: 0.7137 - val_accuracy: 0.4531 - val_auc: 0.4039 - 135s/epoch - 8s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.70630\n",
            "16/16 - 134s - loss: 0.7865 - accuracy: 0.5176 - auc: 0.5424 - val_loss: 0.7263 - val_accuracy: 0.4375 - val_auc: 0.4020 - 134s/epoch - 8s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.70630\n",
            "16/16 - 134s - loss: 0.7934 - accuracy: 0.5031 - auc: 0.5387 - val_loss: 0.7084 - val_accuracy: 0.4844 - val_auc: 0.4048 - 134s/epoch - 8s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss improved from 0.70630 to 0.70292, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 138s - loss: 0.7890 - accuracy: 0.5228 - auc: 0.5478 - val_loss: 0.7029 - val_accuracy: 0.5156 - val_auc: 0.4592 - 138s/epoch - 9s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.70292\n",
            "16/16 - 135s - loss: 0.7835 - accuracy: 0.5186 - auc: 0.5516 - val_loss: 0.7120 - val_accuracy: 0.4844 - val_auc: 0.4343 - 135s/epoch - 8s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7712 - accuracy: 0.5186 - auc: 0.5589 - val_loss: 0.7199 - val_accuracy: 0.4688 - val_auc: 0.4022 - 134s/epoch - 8s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7765 - accuracy: 0.5269 - auc: 0.5695 - val_loss: 0.7253 - val_accuracy: 0.4531 - val_auc: 0.4131 - 134s/epoch - 8s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7645 - accuracy: 0.5414 - auc: 0.5736 - val_loss: 0.7458 - val_accuracy: 0.4531 - val_auc: 0.4219 - 134s/epoch - 8s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7818 - accuracy: 0.5176 - auc: 0.5495 - val_loss: 0.7644 - val_accuracy: 0.4375 - val_auc: 0.4163 - 133s/epoch - 8s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.70292\n",
            "16/16 - 135s - loss: 0.7479 - accuracy: 0.5352 - auc: 0.5795 - val_loss: 0.7716 - val_accuracy: 0.4375 - val_auc: 0.4407 - 135s/epoch - 8s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.70292\n",
            "16/16 - 135s - loss: 0.7739 - accuracy: 0.5228 - auc: 0.5619 - val_loss: 0.7495 - val_accuracy: 0.4688 - val_auc: 0.4623 - 135s/epoch - 8s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.70292\n",
            "16/16 - 136s - loss: 0.7678 - accuracy: 0.5124 - auc: 0.5506 - val_loss: 0.7744 - val_accuracy: 0.4688 - val_auc: 0.4836 - 136s/epoch - 9s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.70292\n",
            "16/16 - 137s - loss: 0.7526 - accuracy: 0.5321 - auc: 0.5687 - val_loss: 0.7426 - val_accuracy: 0.4844 - val_auc: 0.5022 - 137s/epoch - 9s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.70292\n",
            "16/16 - 136s - loss: 0.7726 - accuracy: 0.5393 - auc: 0.5581 - val_loss: 0.7559 - val_accuracy: 0.4531 - val_auc: 0.4709 - 136s/epoch - 8s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.70292\n",
            "16/16 - 135s - loss: 0.7307 - accuracy: 0.5559 - auc: 0.6086 - val_loss: 0.7759 - val_accuracy: 0.4688 - val_auc: 0.4287 - 135s/epoch - 8s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7436 - accuracy: 0.5631 - auc: 0.5946 - val_loss: 0.7665 - val_accuracy: 0.4688 - val_auc: 0.4290 - 133s/epoch - 8s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7459 - accuracy: 0.5455 - auc: 0.5808 - val_loss: 0.7821 - val_accuracy: 0.4688 - val_auc: 0.4343 - 134s/epoch - 8s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7485 - accuracy: 0.5507 - auc: 0.5743 - val_loss: 0.8809 - val_accuracy: 0.4844 - val_auc: 0.4287 - 134s/epoch - 8s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7448 - accuracy: 0.5487 - auc: 0.5917 - val_loss: 0.9233 - val_accuracy: 0.4844 - val_auc: 0.4163 - 134s/epoch - 8s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7509 - accuracy: 0.5528 - auc: 0.5835 - val_loss: 0.8935 - val_accuracy: 0.5000 - val_auc: 0.4365 - 134s/epoch - 8s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7584 - accuracy: 0.5487 - auc: 0.5775 - val_loss: 0.7761 - val_accuracy: 0.4844 - val_auc: 0.4263 - 133s/epoch - 8s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7195 - accuracy: 0.5818 - auc: 0.6349 - val_loss: 0.7461 - val_accuracy: 0.5000 - val_auc: 0.4509 - 133s/epoch - 8s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7359 - accuracy: 0.5538 - auc: 0.6000 - val_loss: 0.7638 - val_accuracy: 0.5000 - val_auc: 0.4436 - 133s/epoch - 8s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7425 - accuracy: 0.5518 - auc: 0.5954 - val_loss: 0.7839 - val_accuracy: 0.5000 - val_auc: 0.4419 - 133s/epoch - 8s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7257 - accuracy: 0.5518 - auc: 0.5999 - val_loss: 0.7784 - val_accuracy: 0.4688 - val_auc: 0.4401 - 134s/epoch - 8s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7384 - accuracy: 0.5756 - auc: 0.5959 - val_loss: 0.7279 - val_accuracy: 0.4688 - val_auc: 0.4619 - 133s/epoch - 8s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7446 - accuracy: 0.5559 - auc: 0.5970 - val_loss: 0.7188 - val_accuracy: 0.4688 - val_auc: 0.4729 - 133s/epoch - 8s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7263 - accuracy: 0.5538 - auc: 0.6013 - val_loss: 0.7120 - val_accuracy: 0.5156 - val_auc: 0.5126 - 133s/epoch - 8s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7281 - accuracy: 0.5569 - auc: 0.5982 - val_loss: 0.7048 - val_accuracy: 0.5000 - val_auc: 0.5305 - 133s/epoch - 8s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7296 - accuracy: 0.5652 - auc: 0.6109 - val_loss: 0.7296 - val_accuracy: 0.5312 - val_auc: 0.4990 - 133s/epoch - 8s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7228 - accuracy: 0.5725 - auc: 0.6084 - val_loss: 0.7126 - val_accuracy: 0.5312 - val_auc: 0.5134 - 133s/epoch - 8s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.70292\n",
            "16/16 - 133s - loss: 0.7268 - accuracy: 0.5518 - auc: 0.5943 - val_loss: 0.7068 - val_accuracy: 0.5156 - val_auc: 0.5319 - 133s/epoch - 8s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.70292\n",
            "16/16 - 132s - loss: 0.7155 - accuracy: 0.5642 - auc: 0.6156 - val_loss: 0.7035 - val_accuracy: 0.5312 - val_auc: 0.5459 - 132s/epoch - 8s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.70292\n",
            "16/16 - 132s - loss: 0.7177 - accuracy: 0.5590 - auc: 0.6027 - val_loss: 0.7108 - val_accuracy: 0.5156 - val_auc: 0.5342 - 132s/epoch - 8s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.70292\n",
            "16/16 - 134s - loss: 0.7266 - accuracy: 0.5673 - auc: 0.6084 - val_loss: 0.7072 - val_accuracy: 0.5625 - val_auc: 0.5378 - 134s/epoch - 8s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.70292\n",
            "16/16 - 135s - loss: 0.7238 - accuracy: 0.5901 - auc: 0.6263 - val_loss: 0.7046 - val_accuracy: 0.5781 - val_auc: 0.5376 - 135s/epoch - 8s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss improved from 0.70292 to 0.69513, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.7073 - accuracy: 0.5714 - auc: 0.6299 - val_loss: 0.6951 - val_accuracy: 0.5625 - val_auc: 0.5715 - 136s/epoch - 8s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss improved from 0.69513 to 0.68714, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.7235 - accuracy: 0.5745 - auc: 0.6174 - val_loss: 0.6871 - val_accuracy: 0.5781 - val_auc: 0.6185 - 136s/epoch - 8s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss improved from 0.68714 to 0.68397, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.7198 - accuracy: 0.5901 - auc: 0.6207 - val_loss: 0.6840 - val_accuracy: 0.5938 - val_auc: 0.6401 - 136s/epoch - 8s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.68397\n",
            "16/16 - 134s - loss: 0.7145 - accuracy: 0.5590 - auc: 0.6197 - val_loss: 0.6883 - val_accuracy: 0.5625 - val_auc: 0.6267 - 134s/epoch - 8s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.68397\n",
            "16/16 - 133s - loss: 0.7213 - accuracy: 0.5559 - auc: 0.6086 - val_loss: 0.6871 - val_accuracy: 0.5156 - val_auc: 0.6499 - 133s/epoch - 8s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.68397\n",
            "16/16 - 132s - loss: 0.6953 - accuracy: 0.5994 - auc: 0.6561 - val_loss: 0.6894 - val_accuracy: 0.5625 - val_auc: 0.6338 - 132s/epoch - 8s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.68397\n",
            "16/16 - 134s - loss: 0.7083 - accuracy: 0.5807 - auc: 0.6252 - val_loss: 0.6878 - val_accuracy: 0.5469 - val_auc: 0.6482 - 134s/epoch - 8s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.68397\n",
            "16/16 - 136s - loss: 0.6973 - accuracy: 0.5911 - auc: 0.6430 - val_loss: 0.6893 - val_accuracy: 0.5469 - val_auc: 0.6487 - 136s/epoch - 8s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.68397\n",
            "16/16 - 136s - loss: 0.6978 - accuracy: 0.5911 - auc: 0.6414 - val_loss: 0.6850 - val_accuracy: 0.5469 - val_auc: 0.6609 - 136s/epoch - 9s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.68397\n",
            "16/16 - 137s - loss: 0.6929 - accuracy: 0.5849 - auc: 0.6403 - val_loss: 0.6864 - val_accuracy: 0.5469 - val_auc: 0.6624 - 137s/epoch - 9s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.68397\n",
            "16/16 - 136s - loss: 0.6930 - accuracy: 0.6066 - auc: 0.6611 - val_loss: 0.6883 - val_accuracy: 0.5469 - val_auc: 0.6621 - 136s/epoch - 8s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss improved from 0.68397 to 0.68375, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 137s - loss: 0.6914 - accuracy: 0.6014 - auc: 0.6481 - val_loss: 0.6838 - val_accuracy: 0.5469 - val_auc: 0.6787 - 137s/epoch - 9s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.68375\n",
            "16/16 - 134s - loss: 0.7082 - accuracy: 0.5745 - auc: 0.6165 - val_loss: 0.6870 - val_accuracy: 0.5469 - val_auc: 0.6648 - 134s/epoch - 8s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss improved from 0.68375 to 0.68145, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 135s - loss: 0.6939 - accuracy: 0.6087 - auc: 0.6571 - val_loss: 0.6815 - val_accuracy: 0.5469 - val_auc: 0.6680 - 135s/epoch - 8s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss improved from 0.68145 to 0.68061, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 137s - loss: 0.6888 - accuracy: 0.6201 - auc: 0.6674 - val_loss: 0.6806 - val_accuracy: 0.5469 - val_auc: 0.6895 - 137s/epoch - 9s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss improved from 0.68061 to 0.67555, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.6836 - accuracy: 0.6014 - auc: 0.6498 - val_loss: 0.6755 - val_accuracy: 0.5469 - val_auc: 0.6987 - 136s/epoch - 9s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss improved from 0.67555 to 0.67526, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.6846 - accuracy: 0.6087 - auc: 0.6634 - val_loss: 0.6753 - val_accuracy: 0.5469 - val_auc: 0.6924 - 136s/epoch - 8s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.67526\n",
            "16/16 - 133s - loss: 0.6895 - accuracy: 0.5932 - auc: 0.6493 - val_loss: 0.6765 - val_accuracy: 0.5469 - val_auc: 0.7070 - 133s/epoch - 8s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss improved from 0.67526 to 0.67311, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 135s - loss: 0.6827 - accuracy: 0.6128 - auc: 0.6612 - val_loss: 0.6731 - val_accuracy: 0.5625 - val_auc: 0.7004 - 135s/epoch - 8s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss improved from 0.67311 to 0.66570, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 135s - loss: 0.6839 - accuracy: 0.6004 - auc: 0.6595 - val_loss: 0.6657 - val_accuracy: 0.5938 - val_auc: 0.6934 - 135s/epoch - 8s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.66570\n",
            "16/16 - 133s - loss: 0.6928 - accuracy: 0.5890 - auc: 0.6464 - val_loss: 0.6690 - val_accuracy: 0.5781 - val_auc: 0.6869 - 133s/epoch - 8s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.66570\n",
            "16/16 - 131s - loss: 0.6788 - accuracy: 0.6201 - auc: 0.6698 - val_loss: 0.6667 - val_accuracy: 0.5938 - val_auc: 0.7068 - 131s/epoch - 8s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss improved from 0.66570 to 0.65279, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 134s - loss: 0.6784 - accuracy: 0.6263 - auc: 0.6752 - val_loss: 0.6528 - val_accuracy: 0.6562 - val_auc: 0.7355 - 134s/epoch - 8s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss improved from 0.65279 to 0.64906, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 135s - loss: 0.6989 - accuracy: 0.6108 - auc: 0.6508 - val_loss: 0.6491 - val_accuracy: 0.6562 - val_auc: 0.7529 - 135s/epoch - 8s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.64906\n",
            "16/16 - 133s - loss: 0.6777 - accuracy: 0.6253 - auc: 0.6743 - val_loss: 0.6560 - val_accuracy: 0.6406 - val_auc: 0.7231 - 133s/epoch - 8s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.64906\n",
            "16/16 - 133s - loss: 0.6808 - accuracy: 0.6056 - auc: 0.6673 - val_loss: 0.6543 - val_accuracy: 0.6562 - val_auc: 0.7430 - 133s/epoch - 8s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.64906\n",
            "16/16 - 133s - loss: 0.6761 - accuracy: 0.6242 - auc: 0.6824 - val_loss: 0.6512 - val_accuracy: 0.6562 - val_auc: 0.7622 - 133s/epoch - 8s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss improved from 0.64906 to 0.64641, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 137s - loss: 0.6745 - accuracy: 0.6325 - auc: 0.6706 - val_loss: 0.6464 - val_accuracy: 0.6562 - val_auc: 0.7456 - 137s/epoch - 9s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6889 - accuracy: 0.5994 - auc: 0.6595 - val_loss: 0.6524 - val_accuracy: 0.6406 - val_auc: 0.7379 - 134s/epoch - 8s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.64641\n",
            "16/16 - 133s - loss: 0.6707 - accuracy: 0.6222 - auc: 0.6823 - val_loss: 0.6510 - val_accuracy: 0.6406 - val_auc: 0.7424 - 133s/epoch - 8s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.64641\n",
            "16/16 - 133s - loss: 0.6713 - accuracy: 0.6398 - auc: 0.7006 - val_loss: 0.6514 - val_accuracy: 0.6250 - val_auc: 0.7350 - 133s/epoch - 8s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.64641\n",
            "16/16 - 135s - loss: 0.6591 - accuracy: 0.6335 - auc: 0.6952 - val_loss: 0.6485 - val_accuracy: 0.6250 - val_auc: 0.7390 - 135s/epoch - 8s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.64641\n",
            "16/16 - 135s - loss: 0.6748 - accuracy: 0.6294 - auc: 0.6862 - val_loss: 0.6504 - val_accuracy: 0.6094 - val_auc: 0.7190 - 135s/epoch - 8s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6614 - accuracy: 0.6439 - auc: 0.7011 - val_loss: 0.6562 - val_accuracy: 0.6094 - val_auc: 0.7104 - 134s/epoch - 8s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6640 - accuracy: 0.6366 - auc: 0.6991 - val_loss: 0.6561 - val_accuracy: 0.6250 - val_auc: 0.7034 - 134s/epoch - 8s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6566 - accuracy: 0.6253 - auc: 0.6989 - val_loss: 0.6656 - val_accuracy: 0.5938 - val_auc: 0.6904 - 134s/epoch - 8s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6491 - accuracy: 0.6687 - auc: 0.7291 - val_loss: 0.6602 - val_accuracy: 0.6094 - val_auc: 0.7019 - 134s/epoch - 8s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6587 - accuracy: 0.6449 - auc: 0.7003 - val_loss: 0.6594 - val_accuracy: 0.5938 - val_auc: 0.7146 - 134s/epoch - 8s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6474 - accuracy: 0.6242 - auc: 0.6965 - val_loss: 0.6640 - val_accuracy: 0.5938 - val_auc: 0.7126 - 134s/epoch - 8s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.64641\n",
            "16/16 - 133s - loss: 0.6672 - accuracy: 0.6346 - auc: 0.6819 - val_loss: 0.6658 - val_accuracy: 0.5781 - val_auc: 0.7007 - 133s/epoch - 8s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.64641\n",
            "16/16 - 132s - loss: 0.6563 - accuracy: 0.6408 - auc: 0.7027 - val_loss: 0.6562 - val_accuracy: 0.6250 - val_auc: 0.7107 - 132s/epoch - 8s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.64641\n",
            "16/16 - 132s - loss: 0.6561 - accuracy: 0.6346 - auc: 0.6979 - val_loss: 0.6557 - val_accuracy: 0.6094 - val_auc: 0.7090 - 132s/epoch - 8s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.64641\n",
            "16/16 - 132s - loss: 0.6495 - accuracy: 0.6532 - auc: 0.7245 - val_loss: 0.6538 - val_accuracy: 0.6094 - val_auc: 0.7239 - 132s/epoch - 8s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.64641\n",
            "16/16 - 134s - loss: 0.6569 - accuracy: 0.6480 - auc: 0.7093 - val_loss: 0.6582 - val_accuracy: 0.5938 - val_auc: 0.6890 - 134s/epoch - 8s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss improved from 0.64641 to 0.64597, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 137s - loss: 0.6542 - accuracy: 0.6522 - auc: 0.7119 - val_loss: 0.6460 - val_accuracy: 0.6250 - val_auc: 0.7249 - 137s/epoch - 9s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.64597\n",
            "16/16 - 134s - loss: 0.6362 - accuracy: 0.6522 - auc: 0.7250 - val_loss: 0.6502 - val_accuracy: 0.6094 - val_auc: 0.7024 - 134s/epoch - 8s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss improved from 0.64597 to 0.64342, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.6668 - accuracy: 0.6429 - auc: 0.7019 - val_loss: 0.6434 - val_accuracy: 0.6250 - val_auc: 0.7529 - 136s/epoch - 9s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss improved from 0.64342 to 0.64202, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 137s - loss: 0.6388 - accuracy: 0.6863 - auc: 0.7435 - val_loss: 0.6420 - val_accuracy: 0.6406 - val_auc: 0.7356 - 137s/epoch - 9s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss improved from 0.64202 to 0.64166, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.6460 - accuracy: 0.6770 - auc: 0.7320 - val_loss: 0.6417 - val_accuracy: 0.6094 - val_auc: 0.7524 - 136s/epoch - 8s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.64166\n",
            "16/16 - 134s - loss: 0.6405 - accuracy: 0.6584 - auc: 0.7304 - val_loss: 0.6474 - val_accuracy: 0.6094 - val_auc: 0.7495 - 134s/epoch - 8s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6412 - accuracy: 0.6656 - auc: 0.7253 - val_loss: 0.6641 - val_accuracy: 0.5938 - val_auc: 0.7300 - 133s/epoch - 8s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.64166\n",
            "16/16 - 131s - loss: 0.6332 - accuracy: 0.6698 - auc: 0.7391 - val_loss: 0.6722 - val_accuracy: 0.5781 - val_auc: 0.6912 - 131s/epoch - 8s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.64166\n",
            "16/16 - 132s - loss: 0.6405 - accuracy: 0.6656 - auc: 0.7335 - val_loss: 0.6659 - val_accuracy: 0.5781 - val_auc: 0.7136 - 132s/epoch - 8s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.64166\n",
            "16/16 - 132s - loss: 0.6412 - accuracy: 0.6605 - auc: 0.7293 - val_loss: 0.6592 - val_accuracy: 0.5938 - val_auc: 0.7336 - 132s/epoch - 8s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.64166\n",
            "16/16 - 132s - loss: 0.6392 - accuracy: 0.6718 - auc: 0.7327 - val_loss: 0.6561 - val_accuracy: 0.5938 - val_auc: 0.7280 - 132s/epoch - 8s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.64166\n",
            "16/16 - 131s - loss: 0.6257 - accuracy: 0.6977 - auc: 0.7597 - val_loss: 0.6450 - val_accuracy: 0.6719 - val_auc: 0.7234 - 131s/epoch - 8s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.64166\n",
            "16/16 - 131s - loss: 0.6317 - accuracy: 0.6687 - auc: 0.7332 - val_loss: 0.6515 - val_accuracy: 0.6406 - val_auc: 0.7195 - 131s/epoch - 8s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6171 - accuracy: 0.6708 - auc: 0.7518 - val_loss: 0.6422 - val_accuracy: 0.6406 - val_auc: 0.7390 - 133s/epoch - 8s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6278 - accuracy: 0.6822 - auc: 0.7534 - val_loss: 0.6512 - val_accuracy: 0.5781 - val_auc: 0.7295 - 133s/epoch - 8s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6299 - accuracy: 0.6760 - auc: 0.7413 - val_loss: 0.6482 - val_accuracy: 0.5938 - val_auc: 0.7314 - 133s/epoch - 8s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6186 - accuracy: 0.6977 - auc: 0.7723 - val_loss: 0.6443 - val_accuracy: 0.6094 - val_auc: 0.7242 - 133s/epoch - 8s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6283 - accuracy: 0.6853 - auc: 0.7585 - val_loss: 0.6457 - val_accuracy: 0.6094 - val_auc: 0.7280 - 133s/epoch - 8s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6262 - accuracy: 0.6749 - auc: 0.7549 - val_loss: 0.6481 - val_accuracy: 0.5938 - val_auc: 0.7292 - 133s/epoch - 8s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.64166\n",
            "16/16 - 133s - loss: 0.6119 - accuracy: 0.7215 - auc: 0.7792 - val_loss: 0.6489 - val_accuracy: 0.5938 - val_auc: 0.7148 - 133s/epoch - 8s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.64166\n",
            "16/16 - 135s - loss: 0.6186 - accuracy: 0.7019 - auc: 0.7742 - val_loss: 0.6479 - val_accuracy: 0.6094 - val_auc: 0.7275 - 135s/epoch - 8s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss improved from 0.64166 to 0.63577, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.6166 - accuracy: 0.6957 - auc: 0.7691 - val_loss: 0.6358 - val_accuracy: 0.6719 - val_auc: 0.7473 - 136s/epoch - 9s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss improved from 0.63577 to 0.63439, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 137s - loss: 0.6074 - accuracy: 0.6957 - auc: 0.7722 - val_loss: 0.6344 - val_accuracy: 0.6562 - val_auc: 0.7477 - 137s/epoch - 9s/step\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.63439\n",
            "16/16 - 134s - loss: 0.6096 - accuracy: 0.7050 - auc: 0.7777 - val_loss: 0.6543 - val_accuracy: 0.6094 - val_auc: 0.7280 - 134s/epoch - 8s/step\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.63439\n",
            "16/16 - 133s - loss: 0.6003 - accuracy: 0.7050 - auc: 0.7759 - val_loss: 0.6631 - val_accuracy: 0.5781 - val_auc: 0.7195 - 133s/epoch - 8s/step\n",
            "Epoch 124/150\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.63439\n",
            "16/16 - 133s - loss: 0.6002 - accuracy: 0.7070 - auc: 0.7767 - val_loss: 0.6565 - val_accuracy: 0.5781 - val_auc: 0.7295 - 133s/epoch - 8s/step\n",
            "Epoch 125/150\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.63439\n",
            "16/16 - 133s - loss: 0.6164 - accuracy: 0.6832 - auc: 0.7593 - val_loss: 0.6489 - val_accuracy: 0.6250 - val_auc: 0.7332 - 133s/epoch - 8s/step\n",
            "Epoch 126/150\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.63439\n",
            "16/16 - 133s - loss: 0.6190 - accuracy: 0.6884 - auc: 0.7516 - val_loss: 0.6483 - val_accuracy: 0.6250 - val_auc: 0.7329 - 133s/epoch - 8s/step\n",
            "Epoch 127/150\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.63439\n",
            "16/16 - 133s - loss: 0.6233 - accuracy: 0.6749 - auc: 0.7494 - val_loss: 0.6433 - val_accuracy: 0.6094 - val_auc: 0.7366 - 133s/epoch - 8s/step\n",
            "Epoch 128/150\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.63439\n",
            "16/16 - 132s - loss: 0.6199 - accuracy: 0.7060 - auc: 0.7686 - val_loss: 0.6418 - val_accuracy: 0.6250 - val_auc: 0.7375 - 132s/epoch - 8s/step\n",
            "Epoch 129/150\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.63439\n",
            "16/16 - 132s - loss: 0.6127 - accuracy: 0.6936 - auc: 0.7720 - val_loss: 0.6405 - val_accuracy: 0.6250 - val_auc: 0.7388 - 132s/epoch - 8s/step\n",
            "Epoch 130/150\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.63439\n",
            "16/16 - 133s - loss: 0.6065 - accuracy: 0.7360 - auc: 0.7919 - val_loss: 0.6409 - val_accuracy: 0.6406 - val_auc: 0.7405 - 133s/epoch - 8s/step\n",
            "Epoch 131/150\n",
            "\n",
            "Epoch 131: val_loss improved from 0.63439 to 0.63379, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 136s - loss: 0.6199 - accuracy: 0.6832 - auc: 0.7598 - val_loss: 0.6338 - val_accuracy: 0.6406 - val_auc: 0.7527 - 136s/epoch - 8s/step\n",
            "Epoch 132/150\n",
            "\n",
            "Epoch 132: val_loss improved from 0.63379 to 0.63249, saving model to Cascade all Model Layers Graph/2022-09-04_09:50:26-model.hdf5\n",
            "16/16 - 137s - loss: 0.6190 - accuracy: 0.6874 - auc: 0.7467 - val_loss: 0.6325 - val_accuracy: 0.6406 - val_auc: 0.7502 - 137s/epoch - 9s/step\n",
            "Epoch 133/150\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.63249\n",
            "16/16 - 133s - loss: 0.6038 - accuracy: 0.7050 - auc: 0.7756 - val_loss: 0.6407 - val_accuracy: 0.6406 - val_auc: 0.7446 - 133s/epoch - 8s/step\n",
            "Epoch 134/150\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.63249\n",
            "16/16 - 133s - loss: 0.5938 - accuracy: 0.7319 - auc: 0.8012 - val_loss: 0.6441 - val_accuracy: 0.6406 - val_auc: 0.7324 - 133s/epoch - 8s/step\n",
            "Epoch 135/150\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.63249\n",
            "16/16 - 133s - loss: 0.6006 - accuracy: 0.7070 - auc: 0.7903 - val_loss: 0.6418 - val_accuracy: 0.6406 - val_auc: 0.7415 - 133s/epoch - 8s/step\n",
            "Epoch 136/150\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.63249\n",
            "16/16 - 135s - loss: 0.6055 - accuracy: 0.7008 - auc: 0.7675 - val_loss: 0.6430 - val_accuracy: 0.6406 - val_auc: 0.7363 - 135s/epoch - 8s/step\n",
            "Epoch 137/150\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.63249\n",
            "16/16 - 133s - loss: 0.5927 - accuracy: 0.7091 - auc: 0.7855 - val_loss: 0.6489 - val_accuracy: 0.6094 - val_auc: 0.7241 - 133s/epoch - 8s/step\n",
            "Epoch 138/150\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.63249\n",
            "16/16 - 135s - loss: 0.6167 - accuracy: 0.7060 - auc: 0.7703 - val_loss: 0.6629 - val_accuracy: 0.5625 - val_auc: 0.7246 - 135s/epoch - 8s/step\n",
            "Epoch 139/150\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.63249\n",
            "16/16 - 134s - loss: 0.5998 - accuracy: 0.7070 - auc: 0.7810 - val_loss: 0.6616 - val_accuracy: 0.5781 - val_auc: 0.7183 - 134s/epoch - 8s/step\n",
            "Epoch 140/150\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.63249\n",
            "16/16 - 133s - loss: 0.5988 - accuracy: 0.7122 - auc: 0.7857 - val_loss: 0.6679 - val_accuracy: 0.5781 - val_auc: 0.7090 - 133s/epoch - 8s/step\n",
            "Epoch 141/150\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.63249\n",
            "16/16 - 132s - loss: 0.5960 - accuracy: 0.7164 - auc: 0.7828 - val_loss: 0.6637 - val_accuracy: 0.5938 - val_auc: 0.7104 - 132s/epoch - 8s/step\n",
            "Epoch 142/150\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.63249\n",
            "16/16 - 131s - loss: 0.5905 - accuracy: 0.7257 - auc: 0.7956 - val_loss: 0.6618 - val_accuracy: 0.5938 - val_auc: 0.7229 - 131s/epoch - 8s/step\n",
            "Epoch 143/150\n",
            "\n",
            "Epoch 143: val_loss did not improve from 0.63249\n",
            "16/16 - 131s - loss: 0.5799 - accuracy: 0.7184 - auc: 0.8019 - val_loss: 0.6602 - val_accuracy: 0.5938 - val_auc: 0.7109 - 131s/epoch - 8s/step\n",
            "Epoch 144/150\n",
            "\n",
            "Epoch 144: val_loss did not improve from 0.63249\n",
            "16/16 - 131s - loss: 0.5801 - accuracy: 0.7298 - auc: 0.8004 - val_loss: 0.6598 - val_accuracy: 0.5938 - val_auc: 0.7122 - 131s/epoch - 8s/step\n",
            "Epoch 145/150\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.63249\n",
            "16/16 - 131s - loss: 0.5869 - accuracy: 0.7381 - auc: 0.7994 - val_loss: 0.6619 - val_accuracy: 0.5938 - val_auc: 0.7058 - 131s/epoch - 8s/step\n",
            "Epoch 146/150\n",
            "\n",
            "Epoch 146: val_loss did not improve from 0.63249\n",
            "16/16 - 131s - loss: 0.5890 - accuracy: 0.7122 - auc: 0.7874 - val_loss: 0.6515 - val_accuracy: 0.6094 - val_auc: 0.7202 - 131s/epoch - 8s/step\n",
            "Epoch 147/150\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.63249\n",
            "16/16 - 130s - loss: 0.5847 - accuracy: 0.7412 - auc: 0.8044 - val_loss: 0.6528 - val_accuracy: 0.6094 - val_auc: 0.7251 - 130s/epoch - 8s/step\n",
            "Epoch 148/150\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.63249\n",
            "16/16 - 131s - loss: 0.5725 - accuracy: 0.7381 - auc: 0.8082 - val_loss: 0.6556 - val_accuracy: 0.6250 - val_auc: 0.7246 - 131s/epoch - 8s/step\n",
            "Epoch 149/150\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.63249\n",
            "16/16 - 132s - loss: 0.5794 - accuracy: 0.7350 - auc: 0.8008 - val_loss: 0.6473 - val_accuracy: 0.6094 - val_auc: 0.7253 - 132s/epoch - 8s/step\n",
            "Epoch 150/150\n",
            "\n",
            "Epoch 150: val_loss did not improve from 0.63249\n",
            "16/16 - 132s - loss: 0.5963 - accuracy: 0.7277 - auc: 0.7957 - val_loss: 0.6465 - val_accuracy: 0.6094 - val_auc: 0.7240 - 132s/epoch - 8s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 242/242 [00:53<00:00,  4.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6946\n",
            "Recall: 0.9431\n",
            "Threshold: 0.3445\n",
            "F1 Score: 0.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1168/1168 [13:08<00:00,  1.48it/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprediction = np.max(tf.nn.softmax(model.predict(img_array)[0])[1])\\nprint(\"Chance of being malignant: {:.2f} %\".format(prediction))\\n'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_Name='E2E Model Saved'\n",
        "model = create_model_E2E()\n",
        "#model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history0 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,\n",
        "        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history0.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./E2E_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z14CU0LvBCw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArtxmPKh5dG8",
        "outputId": "6aacc00f-e576-45a3-bffe-ec53ca63e916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "layer 1 : input_1 is trainable: False\n",
            "layer 2 : conv1_pad is trainable: False\n",
            "layer 3 : conv1_conv is trainable: False\n",
            "layer 4 : conv1_bn is trainable: False\n",
            "layer 5 : conv1_relu is trainable: False\n",
            "layer 6 : pool1_pad is trainable: False\n",
            "layer 7 : pool1_pool is trainable: False\n",
            "layer 8 : conv2_block1_1_conv is trainable: False\n",
            "layer 9 : conv2_block1_1_bn is trainable: False\n",
            "layer 10 : conv2_block1_1_relu is trainable: False\n",
            "rows in train_df 966\n",
            "rows in val_df 242\n",
            "Found 966 non-validated image filenames.\n",
            "Found 242 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.40328, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 297s - loss: 0.7422 - accuracy: 0.6180 - auc: 0.6458 - val_loss: 1.4033 - val_accuracy: 0.4531 - val_auc: 0.5601 - 297s/epoch - 19s/step\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_loss did not improve from 1.40328\n",
            "16/16 - 113s - loss: 0.6727 - accuracy: 0.6656 - auc: 0.7239 - val_loss: 1.5510 - val_accuracy: 0.5469 - val_auc: 0.6206 - 113s/epoch - 7s/step\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_loss improved from 1.40328 to 1.08308, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 115s - loss: 0.6494 - accuracy: 0.6946 - auc: 0.7418 - val_loss: 1.0831 - val_accuracy: 0.5781 - val_auc: 0.6692 - 115s/epoch - 7s/step\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_loss improved from 1.08308 to 0.81529, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 115s - loss: 0.6503 - accuracy: 0.6884 - auc: 0.7359 - val_loss: 0.8153 - val_accuracy: 0.6250 - val_auc: 0.7095 - 115s/epoch - 7s/step\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.81529\n",
            "16/16 - 113s - loss: 0.6520 - accuracy: 0.6718 - auc: 0.7399 - val_loss: 1.5133 - val_accuracy: 0.4688 - val_auc: 0.6150 - 113s/epoch - 7s/step\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_loss improved from 0.81529 to 0.71629, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 115s - loss: 0.6478 - accuracy: 0.6801 - auc: 0.7446 - val_loss: 0.7163 - val_accuracy: 0.7344 - val_auc: 0.7874 - 115s/epoch - 7s/step\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.71629\n",
            "16/16 - 112s - loss: 0.6479 - accuracy: 0.6905 - auc: 0.7511 - val_loss: 0.9659 - val_accuracy: 0.5625 - val_auc: 0.6873 - 112s/epoch - 7s/step\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.71629\n",
            "16/16 - 112s - loss: 0.6290 - accuracy: 0.6977 - auc: 0.7667 - val_loss: 1.2160 - val_accuracy: 0.6875 - val_auc: 0.7258 - 112s/epoch - 7s/step\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.71629\n",
            "16/16 - 112s - loss: 0.6427 - accuracy: 0.7019 - auc: 0.7604 - val_loss: 0.7386 - val_accuracy: 0.6250 - val_auc: 0.7422 - 112s/epoch - 7s/step\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.71629\n",
            "16/16 - 112s - loss: 0.6403 - accuracy: 0.6884 - auc: 0.7527 - val_loss: 0.8260 - val_accuracy: 0.5938 - val_auc: 0.7087 - 112s/epoch - 7s/step\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.71629\n",
            "16/16 - 112s - loss: 0.6076 - accuracy: 0.7143 - auc: 0.7746 - val_loss: 0.9487 - val_accuracy: 0.6719 - val_auc: 0.7192 - 112s/epoch - 7s/step\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.71629\n",
            "16/16 - 111s - loss: 0.6319 - accuracy: 0.6853 - auc: 0.7560 - val_loss: 0.7170 - val_accuracy: 0.5938 - val_auc: 0.7209 - 111s/epoch - 7s/step\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.71629\n",
            "16/16 - 113s - loss: 0.6170 - accuracy: 0.7277 - auc: 0.7834 - val_loss: 0.8149 - val_accuracy: 0.5469 - val_auc: 0.6403 - 113s/epoch - 7s/step\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.71629\n",
            "16/16 - 112s - loss: 0.6335 - accuracy: 0.7050 - auc: 0.7721 - val_loss: 1.3120 - val_accuracy: 0.6094 - val_auc: 0.7310 - 112s/epoch - 7s/step\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.71629\n",
            "16/16 - 111s - loss: 0.6092 - accuracy: 0.7060 - auc: 0.7775 - val_loss: 1.0378 - val_accuracy: 0.5625 - val_auc: 0.6833 - 111s/epoch - 7s/step\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.71629\n",
            "16/16 - 112s - loss: 0.6277 - accuracy: 0.7070 - auc: 0.7657 - val_loss: 1.2595 - val_accuracy: 0.5625 - val_auc: 0.6216 - 112s/epoch - 7s/step\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_loss improved from 0.71629 to 0.60450, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 114s - loss: 0.6150 - accuracy: 0.7081 - auc: 0.7677 - val_loss: 0.6045 - val_accuracy: 0.6562 - val_auc: 0.7676 - 114s/epoch - 7s/step\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.60450\n",
            "16/16 - 112s - loss: 0.6138 - accuracy: 0.7164 - auc: 0.7748 - val_loss: 0.6595 - val_accuracy: 0.7188 - val_auc: 0.7798 - 112s/epoch - 7s/step\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.60450\n",
            "16/16 - 113s - loss: 0.6052 - accuracy: 0.7257 - auc: 0.7793 - val_loss: 0.8131 - val_accuracy: 0.6875 - val_auc: 0.7358 - 113s/epoch - 7s/step\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.60450\n",
            "16/16 - 112s - loss: 0.6073 - accuracy: 0.7153 - auc: 0.7752 - val_loss: 0.6211 - val_accuracy: 0.6719 - val_auc: 0.7537 - 112s/epoch - 7s/step\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.60450\n",
            "16/16 - 112s - loss: 0.6421 - accuracy: 0.6977 - auc: 0.7609 - val_loss: 1.3964 - val_accuracy: 0.5469 - val_auc: 0.6206 - 112s/epoch - 7s/step\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.60450\n",
            "16/16 - 111s - loss: 0.6217 - accuracy: 0.7112 - auc: 0.7692 - val_loss: 0.6118 - val_accuracy: 0.6406 - val_auc: 0.7620 - 111s/epoch - 7s/step\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.60450\n",
            "16/16 - 111s - loss: 0.6113 - accuracy: 0.6998 - auc: 0.7743 - val_loss: 0.7454 - val_accuracy: 0.5938 - val_auc: 0.6633 - 111s/epoch - 7s/step\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.60450\n",
            "16/16 - 111s - loss: 0.6095 - accuracy: 0.7133 - auc: 0.7800 - val_loss: 0.9235 - val_accuracy: 0.5625 - val_auc: 0.6459 - 111s/epoch - 7s/step\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.60450\n",
            "16/16 - 111s - loss: 0.6223 - accuracy: 0.7122 - auc: 0.7747 - val_loss: 1.5829 - val_accuracy: 0.5469 - val_auc: 0.6018 - 111s/epoch - 7s/step\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_loss improved from 0.60450 to 0.58271, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 114s - loss: 0.5981 - accuracy: 0.7236 - auc: 0.7867 - val_loss: 0.5827 - val_accuracy: 0.7656 - val_auc: 0.7915 - 114s/epoch - 7s/step\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.58271\n",
            "16/16 - 112s - loss: 0.6226 - accuracy: 0.7153 - auc: 0.7692 - val_loss: 0.6043 - val_accuracy: 0.7500 - val_auc: 0.7776 - 112s/epoch - 7s/step\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_loss improved from 0.58271 to 0.55432, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 114s - loss: 0.6084 - accuracy: 0.7101 - auc: 0.7793 - val_loss: 0.5543 - val_accuracy: 0.6875 - val_auc: 0.7964 - 114s/epoch - 7s/step\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.55432\n",
            "16/16 - 112s - loss: 0.5930 - accuracy: 0.7226 - auc: 0.7908 - val_loss: 0.6834 - val_accuracy: 0.6094 - val_auc: 0.7341 - 112s/epoch - 7s/step\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5986 - accuracy: 0.7174 - auc: 0.7915 - val_loss: 1.1018 - val_accuracy: 0.5625 - val_auc: 0.6647 - 111s/epoch - 7s/step\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6111 - accuracy: 0.7029 - auc: 0.7749 - val_loss: 0.7813 - val_accuracy: 0.7031 - val_auc: 0.7686 - 111s/epoch - 7s/step\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6268 - accuracy: 0.7060 - auc: 0.7675 - val_loss: 0.6913 - val_accuracy: 0.7031 - val_auc: 0.7874 - 111s/epoch - 7s/step\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6350 - accuracy: 0.7029 - auc: 0.7637 - val_loss: 1.4242 - val_accuracy: 0.6094 - val_auc: 0.7019 - 111s/epoch - 7s/step\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6353 - accuracy: 0.7174 - auc: 0.7640 - val_loss: 1.1360 - val_accuracy: 0.4688 - val_auc: 0.6042 - 111s/epoch - 7s/step\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5924 - accuracy: 0.7226 - auc: 0.7896 - val_loss: 0.6189 - val_accuracy: 0.6875 - val_auc: 0.7711 - 111s/epoch - 7s/step\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6085 - accuracy: 0.7133 - auc: 0.7764 - val_loss: 1.1564 - val_accuracy: 0.5469 - val_auc: 0.6619 - 111s/epoch - 7s/step\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5985 - accuracy: 0.7133 - auc: 0.7819 - val_loss: 0.7687 - val_accuracy: 0.6406 - val_auc: 0.7358 - 111s/epoch - 7s/step\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5854 - accuracy: 0.7257 - auc: 0.7897 - val_loss: 0.5725 - val_accuracy: 0.7344 - val_auc: 0.7849 - 111s/epoch - 7s/step\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5988 - accuracy: 0.7215 - auc: 0.7913 - val_loss: 1.5385 - val_accuracy: 0.5469 - val_auc: 0.5955 - 111s/epoch - 7s/step\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.55432\n",
            "16/16 - 112s - loss: 0.6122 - accuracy: 0.7133 - auc: 0.7781 - val_loss: 0.7282 - val_accuracy: 0.6094 - val_auc: 0.6799 - 112s/epoch - 7s/step\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5922 - accuracy: 0.7257 - auc: 0.7921 - val_loss: 0.6903 - val_accuracy: 0.6875 - val_auc: 0.7000 - 111s/epoch - 7s/step\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6018 - accuracy: 0.7060 - auc: 0.7787 - val_loss: 0.6666 - val_accuracy: 0.6094 - val_auc: 0.7366 - 111s/epoch - 7s/step\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6154 - accuracy: 0.7153 - auc: 0.7708 - val_loss: 0.9755 - val_accuracy: 0.5312 - val_auc: 0.6301 - 111s/epoch - 7s/step\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5897 - accuracy: 0.7246 - auc: 0.7868 - val_loss: 0.5862 - val_accuracy: 0.7344 - val_auc: 0.7781 - 111s/epoch - 7s/step\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6200 - accuracy: 0.6874 - auc: 0.7674 - val_loss: 2.3739 - val_accuracy: 0.5469 - val_auc: 0.5469 - 111s/epoch - 7s/step\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5912 - accuracy: 0.7215 - auc: 0.7879 - val_loss: 1.1668 - val_accuracy: 0.5781 - val_auc: 0.6755 - 111s/epoch - 7s/step\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5971 - accuracy: 0.7070 - auc: 0.7803 - val_loss: 0.8193 - val_accuracy: 0.5312 - val_auc: 0.6340 - 111s/epoch - 7s/step\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6201 - accuracy: 0.7195 - auc: 0.7762 - val_loss: 0.6578 - val_accuracy: 0.6562 - val_auc: 0.7573 - 111s/epoch - 7s/step\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.55432\n",
            "16/16 - 112s - loss: 0.5902 - accuracy: 0.7184 - auc: 0.7829 - val_loss: 0.7032 - val_accuracy: 0.7500 - val_auc: 0.7896 - 112s/epoch - 7s/step\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.55432\n",
            "16/16 - 112s - loss: 0.5869 - accuracy: 0.7226 - auc: 0.7941 - val_loss: 0.6281 - val_accuracy: 0.7656 - val_auc: 0.7598 - 112s/epoch - 7s/step\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5941 - accuracy: 0.7267 - auc: 0.7874 - val_loss: 0.6049 - val_accuracy: 0.7031 - val_auc: 0.7817 - 111s/epoch - 7s/step\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6046 - accuracy: 0.7215 - auc: 0.7903 - val_loss: 0.7180 - val_accuracy: 0.6250 - val_auc: 0.7361 - 111s/epoch - 7s/step\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6105 - accuracy: 0.7298 - auc: 0.7758 - val_loss: 0.8055 - val_accuracy: 0.6250 - val_auc: 0.7104 - 111s/epoch - 7s/step\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5895 - accuracy: 0.7422 - auc: 0.8001 - val_loss: 0.7791 - val_accuracy: 0.7188 - val_auc: 0.7173 - 111s/epoch - 7s/step\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.5943 - accuracy: 0.7257 - auc: 0.7918 - val_loss: 0.8193 - val_accuracy: 0.6094 - val_auc: 0.7292 - 111s/epoch - 7s/step\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.55432\n",
            "16/16 - 111s - loss: 0.6072 - accuracy: 0.7350 - auc: 0.7812 - val_loss: 1.1110 - val_accuracy: 0.5938 - val_auc: 0.7012 - 111s/epoch - 7s/step\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_loss improved from 0.55432 to 0.54828, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 114s - loss: 0.5835 - accuracy: 0.7277 - auc: 0.7966 - val_loss: 0.5483 - val_accuracy: 0.6875 - val_auc: 0.7925 - 114s/epoch - 7s/step\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.54828\n",
            "16/16 - 112s - loss: 0.5912 - accuracy: 0.7257 - auc: 0.7920 - val_loss: 0.6041 - val_accuracy: 0.7656 - val_auc: 0.7985 - 112s/epoch - 7s/step\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.54828\n",
            "16/16 - 112s - loss: 0.5971 - accuracy: 0.7288 - auc: 0.7960 - val_loss: 0.8731 - val_accuracy: 0.4844 - val_auc: 0.6187 - 112s/epoch - 7s/step\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5689 - accuracy: 0.7412 - auc: 0.8110 - val_loss: 0.7678 - val_accuracy: 0.6406 - val_auc: 0.7429 - 111s/epoch - 7s/step\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5915 - accuracy: 0.7246 - auc: 0.7880 - val_loss: 0.9991 - val_accuracy: 0.5938 - val_auc: 0.6738 - 111s/epoch - 7s/step\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5720 - accuracy: 0.7391 - auc: 0.8111 - val_loss: 0.7258 - val_accuracy: 0.6094 - val_auc: 0.6716 - 111s/epoch - 7s/step\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5952 - accuracy: 0.7371 - auc: 0.7876 - val_loss: 0.9075 - val_accuracy: 0.6094 - val_auc: 0.7109 - 111s/epoch - 7s/step\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5917 - accuracy: 0.7215 - auc: 0.7878 - val_loss: 0.5860 - val_accuracy: 0.7500 - val_auc: 0.7947 - 111s/epoch - 7s/step\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5966 - accuracy: 0.7246 - auc: 0.7895 - val_loss: 0.6254 - val_accuracy: 0.7344 - val_auc: 0.7678 - 111s/epoch - 7s/step\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5667 - accuracy: 0.7474 - auc: 0.8111 - val_loss: 0.8053 - val_accuracy: 0.5781 - val_auc: 0.7106 - 111s/epoch - 7s/step\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.6018 - accuracy: 0.7195 - auc: 0.7859 - val_loss: 1.5878 - val_accuracy: 0.5625 - val_auc: 0.6428 - 111s/epoch - 7s/step\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.6020 - accuracy: 0.7091 - auc: 0.7801 - val_loss: 0.5728 - val_accuracy: 0.7188 - val_auc: 0.7871 - 111s/epoch - 7s/step\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.6126 - accuracy: 0.7133 - auc: 0.7842 - val_loss: 0.7770 - val_accuracy: 0.6562 - val_auc: 0.7578 - 111s/epoch - 7s/step\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.54828\n",
            "16/16 - 111s - loss: 0.5928 - accuracy: 0.7184 - auc: 0.7919 - val_loss: 1.1151 - val_accuracy: 0.5625 - val_auc: 0.6594 - 111s/epoch - 7s/step\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_loss improved from 0.54828 to 0.53085, saving model to Cascade all Model Layers Graph/2022-09-05_17:22:20-model.hdf5\n",
            "16/16 - 113s - loss: 0.5932 - accuracy: 0.7319 - auc: 0.8005 - val_loss: 0.5308 - val_accuracy: 0.7344 - val_auc: 0.8103 - 113s/epoch - 7s/step\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5989 - accuracy: 0.7257 - auc: 0.7847 - val_loss: 0.5749 - val_accuracy: 0.7344 - val_auc: 0.8103 - 111s/epoch - 7s/step\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5796 - accuracy: 0.7308 - auc: 0.7984 - val_loss: 0.5481 - val_accuracy: 0.6875 - val_auc: 0.7953 - 111s/epoch - 7s/step\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5800 - accuracy: 0.7267 - auc: 0.7946 - val_loss: 0.5873 - val_accuracy: 0.7812 - val_auc: 0.8057 - 111s/epoch - 7s/step\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5961 - accuracy: 0.7205 - auc: 0.7862 - val_loss: 0.6168 - val_accuracy: 0.7500 - val_auc: 0.7563 - 111s/epoch - 7s/step\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5714 - accuracy: 0.7174 - auc: 0.7931 - val_loss: 0.6306 - val_accuracy: 0.6406 - val_auc: 0.7488 - 111s/epoch - 7s/step\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6008 - accuracy: 0.7267 - auc: 0.7896 - val_loss: 0.7821 - val_accuracy: 0.5781 - val_auc: 0.7209 - 111s/epoch - 7s/step\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6022 - accuracy: 0.7277 - auc: 0.7882 - val_loss: 0.8178 - val_accuracy: 0.5781 - val_auc: 0.7168 - 111s/epoch - 7s/step\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5957 - accuracy: 0.7174 - auc: 0.7863 - val_loss: 0.7003 - val_accuracy: 0.6094 - val_auc: 0.7219 - 111s/epoch - 7s/step\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6085 - accuracy: 0.7267 - auc: 0.7837 - val_loss: 0.6516 - val_accuracy: 0.6406 - val_auc: 0.7527 - 111s/epoch - 7s/step\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6071 - accuracy: 0.7205 - auc: 0.7791 - val_loss: 0.6955 - val_accuracy: 0.5938 - val_auc: 0.7446 - 111s/epoch - 7s/step\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6076 - accuracy: 0.7133 - auc: 0.7819 - val_loss: 0.6594 - val_accuracy: 0.7031 - val_auc: 0.7698 - 111s/epoch - 7s/step\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6024 - accuracy: 0.7277 - auc: 0.7835 - val_loss: 0.5783 - val_accuracy: 0.7656 - val_auc: 0.8090 - 111s/epoch - 7s/step\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6039 - accuracy: 0.7205 - auc: 0.7880 - val_loss: 0.5511 - val_accuracy: 0.6562 - val_auc: 0.7913 - 111s/epoch - 7s/step\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5838 - accuracy: 0.7391 - auc: 0.7963 - val_loss: 0.6303 - val_accuracy: 0.6250 - val_auc: 0.7465 - 111s/epoch - 7s/step\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.53085\n",
            "16/16 - 112s - loss: 0.5783 - accuracy: 0.7308 - auc: 0.8001 - val_loss: 0.5584 - val_accuracy: 0.7188 - val_auc: 0.7817 - 112s/epoch - 7s/step\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5800 - accuracy: 0.7329 - auc: 0.7969 - val_loss: 1.5950 - val_accuracy: 0.5469 - val_auc: 0.5791 - 111s/epoch - 7s/step\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.53085\n",
            "16/16 - 112s - loss: 0.5853 - accuracy: 0.7319 - auc: 0.7971 - val_loss: 0.6186 - val_accuracy: 0.6719 - val_auc: 0.7740 - 112s/epoch - 7s/step\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5805 - accuracy: 0.7226 - auc: 0.7917 - val_loss: 0.8880 - val_accuracy: 0.5781 - val_auc: 0.7015 - 111s/epoch - 7s/step\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5899 - accuracy: 0.7360 - auc: 0.7970 - val_loss: 0.5575 - val_accuracy: 0.7500 - val_auc: 0.7949 - 111s/epoch - 7s/step\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5933 - accuracy: 0.7288 - auc: 0.7881 - val_loss: 0.7089 - val_accuracy: 0.6250 - val_auc: 0.7258 - 111s/epoch - 7s/step\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5738 - accuracy: 0.7371 - auc: 0.8064 - val_loss: 0.6896 - val_accuracy: 0.6406 - val_auc: 0.7688 - 110s/epoch - 7s/step\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5770 - accuracy: 0.7412 - auc: 0.8005 - val_loss: 0.6949 - val_accuracy: 0.7031 - val_auc: 0.7153 - 111s/epoch - 7s/step\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5822 - accuracy: 0.7298 - auc: 0.7957 - val_loss: 0.6212 - val_accuracy: 0.7344 - val_auc: 0.7791 - 111s/epoch - 7s/step\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5991 - accuracy: 0.7215 - auc: 0.7872 - val_loss: 0.7004 - val_accuracy: 0.6875 - val_auc: 0.7008 - 111s/epoch - 7s/step\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5940 - accuracy: 0.7298 - auc: 0.7928 - val_loss: 0.6649 - val_accuracy: 0.6562 - val_auc: 0.7527 - 111s/epoch - 7s/step\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5987 - accuracy: 0.7184 - auc: 0.7836 - val_loss: 0.9403 - val_accuracy: 0.5938 - val_auc: 0.6904 - 111s/epoch - 7s/step\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6010 - accuracy: 0.7143 - auc: 0.7815 - val_loss: 0.7528 - val_accuracy: 0.7344 - val_auc: 0.7915 - 111s/epoch - 7s/step\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.6033 - accuracy: 0.7329 - auc: 0.7873 - val_loss: 0.5923 - val_accuracy: 0.6719 - val_auc: 0.7656 - 110s/epoch - 7s/step\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5947 - accuracy: 0.7340 - auc: 0.7929 - val_loss: 1.0481 - val_accuracy: 0.5625 - val_auc: 0.6741 - 110s/epoch - 7s/step\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5861 - accuracy: 0.7226 - auc: 0.7920 - val_loss: 0.9593 - val_accuracy: 0.6094 - val_auc: 0.6909 - 111s/epoch - 7s/step\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5721 - accuracy: 0.7402 - auc: 0.8010 - val_loss: 0.5902 - val_accuracy: 0.7344 - val_auc: 0.7874 - 110s/epoch - 7s/step\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5915 - accuracy: 0.7236 - auc: 0.7881 - val_loss: 0.7887 - val_accuracy: 0.6094 - val_auc: 0.7268 - 111s/epoch - 7s/step\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5669 - accuracy: 0.7391 - auc: 0.8047 - val_loss: 0.5988 - val_accuracy: 0.7344 - val_auc: 0.7748 - 110s/epoch - 7s/step\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5869 - accuracy: 0.7360 - auc: 0.7964 - val_loss: 0.6188 - val_accuracy: 0.7344 - val_auc: 0.7958 - 110s/epoch - 7s/step\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5881 - accuracy: 0.7246 - auc: 0.7940 - val_loss: 0.7215 - val_accuracy: 0.7188 - val_auc: 0.7825 - 111s/epoch - 7s/step\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5889 - accuracy: 0.7205 - auc: 0.7892 - val_loss: 0.6023 - val_accuracy: 0.6719 - val_auc: 0.7725 - 110s/epoch - 7s/step\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5899 - accuracy: 0.7257 - auc: 0.7898 - val_loss: 0.6429 - val_accuracy: 0.6406 - val_auc: 0.7461 - 110s/epoch - 7s/step\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5781 - accuracy: 0.7122 - auc: 0.7926 - val_loss: 0.6051 - val_accuracy: 0.7188 - val_auc: 0.7764 - 110s/epoch - 7s/step\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5851 - accuracy: 0.7308 - auc: 0.7935 - val_loss: 0.5506 - val_accuracy: 0.7656 - val_auc: 0.8235 - 110s/epoch - 7s/step\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5916 - accuracy: 0.7371 - auc: 0.7927 - val_loss: 0.5885 - val_accuracy: 0.7500 - val_auc: 0.7983 - 111s/epoch - 7s/step\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5800 - accuracy: 0.7474 - auc: 0.8028 - val_loss: 0.8012 - val_accuracy: 0.5938 - val_auc: 0.7168 - 110s/epoch - 7s/step\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.6039 - accuracy: 0.7174 - auc: 0.7913 - val_loss: 1.2312 - val_accuracy: 0.5469 - val_auc: 0.6487 - 110s/epoch - 7s/step\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5772 - accuracy: 0.7453 - auc: 0.8069 - val_loss: 0.6620 - val_accuracy: 0.6719 - val_auc: 0.7473 - 111s/epoch - 7s/step\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5685 - accuracy: 0.7257 - auc: 0.8052 - val_loss: 0.6131 - val_accuracy: 0.7344 - val_auc: 0.7888 - 111s/epoch - 7s/step\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.6018 - accuracy: 0.7298 - auc: 0.7850 - val_loss: 1.0572 - val_accuracy: 0.5781 - val_auc: 0.6846 - 111s/epoch - 7s/step\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5862 - accuracy: 0.6977 - auc: 0.7818 - val_loss: 1.3093 - val_accuracy: 0.5469 - val_auc: 0.6165 - 111s/epoch - 7s/step\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5660 - accuracy: 0.7246 - auc: 0.8011 - val_loss: 0.6958 - val_accuracy: 0.6094 - val_auc: 0.7390 - 111s/epoch - 7s/step\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5823 - accuracy: 0.7308 - auc: 0.7977 - val_loss: 0.6252 - val_accuracy: 0.6094 - val_auc: 0.7568 - 110s/epoch - 7s/step\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.53085\n",
            "16/16 - 111s - loss: 0.5919 - accuracy: 0.7226 - auc: 0.7871 - val_loss: 0.8789 - val_accuracy: 0.6719 - val_auc: 0.7053 - 111s/epoch - 7s/step\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.53085\n",
            "16/16 - 110s - loss: 0.5910 - accuracy: 0.7184 - auc: 0.7874 - val_loss: 0.7065 - val_accuracy: 0.7812 - val_auc: 0.7815 - 110s/epoch - 7s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 242/242 [01:40<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7357\n",
            "Recall: 0.8374\n",
            "Threshold: 0.522\n",
            "F1 Score: 0.7833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1168/1168 [13:00<00:00,  1.50it/s]\n"
          ]
        }
      ],
      "source": [
        "Model_Name='Pretrained plus 1st layer Model Saved(balanced Dataset)'\n",
        "model = create_model_Pretrained()\n",
        "#model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history1 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history1.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./PretrainedPlus1_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdl5AgKY5dG9"
      },
      "outputs": [],
      "source": [
        "Model_Name='Pretrained plus 1st layer Model Saved(balanced Dataset)'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 2nd layer Model Saved(balanced Dataset)'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history2 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history2.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./PretrainedPlus2_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zcRXqTgP5dG9"
      },
      "outputs": [],
      "source": [
        "Model_Name='Pretrained plus 2nd layer Model Saved(balanced Dataset)'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 3rd layer Model Saved(balanced Dataset)'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history3 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history3.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./PretrainedPlus3_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uxNB63Dx5dG-",
        "outputId": "2acb8f2d-1507-4f63-d156-c5f828b7a771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 2)                 74973830  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,974,984\n",
            "Trainable params: 51,385,480\n",
            "Non-trainable params: 23,589,504\n",
            "_________________________________________________________________\n",
            "rows in train_df 966\n",
            "rows in val_df 242\n",
            "Found 966 non-validated image filenames.\n",
            "Found 242 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "16/16 - 121s - loss: 0.8728 - accuracy: 0.4679 - auc: 0.4400 - val_loss: 0.7001 - val_accuracy: 0.3594 - val_auc: 0.3545 - 121s/epoch - 8s/step\n",
            "Epoch 2/150\n",
            "16/16 - 116s - loss: 0.8370 - accuracy: 0.4720 - auc: 0.4684 - val_loss: 0.7736 - val_accuracy: 0.3438 - val_auc: 0.3185 - 116s/epoch - 7s/step\n",
            "Epoch 3/150\n",
            "16/16 - 116s - loss: 0.8550 - accuracy: 0.4524 - auc: 0.4329 - val_loss: 0.7893 - val_accuracy: 0.4375 - val_auc: 0.3510 - 116s/epoch - 7s/step\n",
            "Epoch 4/150\n",
            "16/16 - 116s - loss: 0.8141 - accuracy: 0.5072 - auc: 0.5207 - val_loss: 0.7438 - val_accuracy: 0.5312 - val_auc: 0.5476 - 116s/epoch - 7s/step\n",
            "Epoch 5/150\n",
            "16/16 - 116s - loss: 0.8251 - accuracy: 0.4969 - auc: 0.4914 - val_loss: 0.7361 - val_accuracy: 0.6094 - val_auc: 0.5808 - 116s/epoch - 7s/step\n",
            "Epoch 6/150\n",
            "16/16 - 116s - loss: 0.7984 - accuracy: 0.5424 - auc: 0.5472 - val_loss: 0.7315 - val_accuracy: 0.6250 - val_auc: 0.6064 - 116s/epoch - 7s/step\n",
            "Epoch 7/150\n",
            "16/16 - 116s - loss: 0.7877 - accuracy: 0.5021 - auc: 0.5275 - val_loss: 0.7442 - val_accuracy: 0.5938 - val_auc: 0.5714 - 116s/epoch - 7s/step\n",
            "Epoch 8/150\n",
            "16/16 - 116s - loss: 0.7779 - accuracy: 0.5393 - auc: 0.5552 - val_loss: 0.7338 - val_accuracy: 0.5938 - val_auc: 0.5579 - 116s/epoch - 7s/step\n",
            "Epoch 9/150\n",
            "16/16 - 116s - loss: 0.7682 - accuracy: 0.5290 - auc: 0.5579 - val_loss: 0.7428 - val_accuracy: 0.6250 - val_auc: 0.5903 - 116s/epoch - 7s/step\n",
            "Epoch 10/150\n",
            "16/16 - 116s - loss: 0.7811 - accuracy: 0.5311 - auc: 0.5480 - val_loss: 0.7226 - val_accuracy: 0.6250 - val_auc: 0.5283 - 116s/epoch - 7s/step\n",
            "Epoch 11/150\n",
            "16/16 - 116s - loss: 0.7578 - accuracy: 0.5424 - auc: 0.5687 - val_loss: 0.7197 - val_accuracy: 0.6250 - val_auc: 0.5623 - 116s/epoch - 7s/step\n",
            "Epoch 12/150\n",
            "16/16 - 116s - loss: 0.7552 - accuracy: 0.5559 - auc: 0.5827 - val_loss: 0.6946 - val_accuracy: 0.6250 - val_auc: 0.6384 - 116s/epoch - 7s/step\n",
            "Epoch 13/150\n",
            "16/16 - 116s - loss: 0.7412 - accuracy: 0.5466 - auc: 0.5893 - val_loss: 0.7060 - val_accuracy: 0.6094 - val_auc: 0.5964 - 116s/epoch - 7s/step\n",
            "Epoch 14/150\n",
            "16/16 - 116s - loss: 0.7533 - accuracy: 0.5673 - auc: 0.5894 - val_loss: 0.6861 - val_accuracy: 0.5938 - val_auc: 0.6682 - 116s/epoch - 7s/step\n",
            "Epoch 15/150\n",
            "16/16 - 115s - loss: 0.7433 - accuracy: 0.5631 - auc: 0.5767 - val_loss: 0.6835 - val_accuracy: 0.6250 - val_auc: 0.6460 - 115s/epoch - 7s/step\n",
            "Epoch 16/150\n",
            "16/16 - 115s - loss: 0.7316 - accuracy: 0.5694 - auc: 0.5987 - val_loss: 0.6738 - val_accuracy: 0.6562 - val_auc: 0.6746 - 115s/epoch - 7s/step\n",
            "Epoch 17/150\n",
            "16/16 - 116s - loss: 0.7242 - accuracy: 0.5973 - auc: 0.6290 - val_loss: 0.6755 - val_accuracy: 0.5938 - val_auc: 0.6543 - 116s/epoch - 7s/step\n",
            "Epoch 18/150\n",
            "16/16 - 115s - loss: 0.7326 - accuracy: 0.5725 - auc: 0.5934 - val_loss: 0.6745 - val_accuracy: 0.6250 - val_auc: 0.6584 - 115s/epoch - 7s/step\n",
            "Epoch 19/150\n",
            "16/16 - 116s - loss: 0.7272 - accuracy: 0.5859 - auc: 0.6174 - val_loss: 0.6687 - val_accuracy: 0.6250 - val_auc: 0.6573 - 116s/epoch - 7s/step\n",
            "Epoch 20/150\n",
            "16/16 - 116s - loss: 0.7170 - accuracy: 0.5870 - auc: 0.6193 - val_loss: 0.6841 - val_accuracy: 0.6094 - val_auc: 0.6121 - 116s/epoch - 7s/step\n",
            "Epoch 21/150\n",
            "16/16 - 116s - loss: 0.7146 - accuracy: 0.5766 - auc: 0.6284 - val_loss: 0.6774 - val_accuracy: 0.6250 - val_auc: 0.6340 - 116s/epoch - 7s/step\n",
            "Epoch 22/150\n",
            "16/16 - 116s - loss: 0.7217 - accuracy: 0.5673 - auc: 0.6103 - val_loss: 0.6637 - val_accuracy: 0.6406 - val_auc: 0.6626 - 116s/epoch - 7s/step\n",
            "Epoch 23/150\n",
            "16/16 - 116s - loss: 0.7340 - accuracy: 0.5807 - auc: 0.6010 - val_loss: 0.6658 - val_accuracy: 0.6406 - val_auc: 0.6545 - 116s/epoch - 7s/step\n",
            "Epoch 24/150\n",
            "16/16 - 116s - loss: 0.7189 - accuracy: 0.5870 - auc: 0.6286 - val_loss: 0.6860 - val_accuracy: 0.6094 - val_auc: 0.6285 - 116s/epoch - 7s/step\n",
            "Epoch 25/150\n",
            "16/16 - 116s - loss: 0.7100 - accuracy: 0.5890 - auc: 0.6316 - val_loss: 0.6576 - val_accuracy: 0.6250 - val_auc: 0.6614 - 116s/epoch - 7s/step\n",
            "Epoch 26/150\n",
            "16/16 - 116s - loss: 0.7014 - accuracy: 0.6004 - auc: 0.6489 - val_loss: 0.6555 - val_accuracy: 0.6719 - val_auc: 0.6462 - 116s/epoch - 7s/step\n",
            "Epoch 27/150\n",
            "16/16 - 115s - loss: 0.7300 - accuracy: 0.5766 - auc: 0.6130 - val_loss: 0.6595 - val_accuracy: 0.6094 - val_auc: 0.6738 - 115s/epoch - 7s/step\n",
            "Epoch 28/150\n",
            "16/16 - 116s - loss: 0.7240 - accuracy: 0.5890 - auc: 0.6193 - val_loss: 0.6569 - val_accuracy: 0.6250 - val_auc: 0.6846 - 116s/epoch - 7s/step\n",
            "Epoch 29/150\n",
            "16/16 - 116s - loss: 0.6889 - accuracy: 0.6211 - auc: 0.6691 - val_loss: 0.6508 - val_accuracy: 0.6250 - val_auc: 0.6821 - 116s/epoch - 7s/step\n",
            "Epoch 30/150\n",
            "16/16 - 116s - loss: 0.7041 - accuracy: 0.6118 - auc: 0.6492 - val_loss: 0.6523 - val_accuracy: 0.6250 - val_auc: 0.6799 - 116s/epoch - 7s/step\n",
            "Epoch 31/150\n",
            "16/16 - 116s - loss: 0.6954 - accuracy: 0.6087 - auc: 0.6552 - val_loss: 0.6532 - val_accuracy: 0.6406 - val_auc: 0.6737 - 116s/epoch - 7s/step\n",
            "Epoch 32/150\n",
            "16/16 - 116s - loss: 0.6819 - accuracy: 0.6211 - auc: 0.6729 - val_loss: 0.6509 - val_accuracy: 0.6562 - val_auc: 0.6829 - 116s/epoch - 7s/step\n",
            "Epoch 33/150\n",
            "16/16 - 116s - loss: 0.6841 - accuracy: 0.6190 - auc: 0.6672 - val_loss: 0.6531 - val_accuracy: 0.6562 - val_auc: 0.6636 - 116s/epoch - 7s/step\n",
            "Epoch 34/150\n",
            "16/16 - 116s - loss: 0.6985 - accuracy: 0.6108 - auc: 0.6607 - val_loss: 0.6455 - val_accuracy: 0.6250 - val_auc: 0.6868 - 116s/epoch - 7s/step\n",
            "Epoch 35/150\n",
            "16/16 - 116s - loss: 0.6952 - accuracy: 0.6077 - auc: 0.6551 - val_loss: 0.6492 - val_accuracy: 0.6094 - val_auc: 0.6954 - 116s/epoch - 7s/step\n",
            "Epoch 36/150\n",
            "16/16 - 116s - loss: 0.7065 - accuracy: 0.6149 - auc: 0.6481 - val_loss: 0.6521 - val_accuracy: 0.6406 - val_auc: 0.6770 - 116s/epoch - 7s/step\n",
            "Epoch 37/150\n",
            "16/16 - 116s - loss: 0.6939 - accuracy: 0.6211 - auc: 0.6566 - val_loss: 0.6435 - val_accuracy: 0.6406 - val_auc: 0.6953 - 116s/epoch - 7s/step\n",
            "Epoch 38/150\n",
            "16/16 - 116s - loss: 0.6827 - accuracy: 0.6418 - auc: 0.6802 - val_loss: 0.6469 - val_accuracy: 0.6562 - val_auc: 0.6750 - 116s/epoch - 7s/step\n",
            "Epoch 39/150\n",
            "16/16 - 116s - loss: 0.7018 - accuracy: 0.6139 - auc: 0.6448 - val_loss: 0.6433 - val_accuracy: 0.5938 - val_auc: 0.6882 - 116s/epoch - 7s/step\n",
            "Epoch 40/150\n",
            "16/16 - 116s - loss: 0.6938 - accuracy: 0.6377 - auc: 0.6740 - val_loss: 0.6413 - val_accuracy: 0.6562 - val_auc: 0.6973 - 116s/epoch - 7s/step\n",
            "Epoch 41/150\n",
            "16/16 - 116s - loss: 0.6769 - accuracy: 0.6677 - auc: 0.7120 - val_loss: 0.6483 - val_accuracy: 0.6094 - val_auc: 0.6843 - 116s/epoch - 7s/step\n",
            "Epoch 42/150\n",
            "16/16 - 116s - loss: 0.6906 - accuracy: 0.6294 - auc: 0.6686 - val_loss: 0.6831 - val_accuracy: 0.6250 - val_auc: 0.6394 - 116s/epoch - 7s/step\n",
            "Epoch 43/150\n",
            "16/16 - 116s - loss: 0.6968 - accuracy: 0.6273 - auc: 0.6615 - val_loss: 0.6771 - val_accuracy: 0.6094 - val_auc: 0.6628 - 116s/epoch - 7s/step\n",
            "Epoch 44/150\n",
            "16/16 - 115s - loss: 0.6850 - accuracy: 0.6398 - auc: 0.6806 - val_loss: 0.6663 - val_accuracy: 0.6094 - val_auc: 0.6780 - 115s/epoch - 7s/step\n",
            "Epoch 45/150\n",
            "16/16 - 116s - loss: 0.6859 - accuracy: 0.6356 - auc: 0.6792 - val_loss: 0.6713 - val_accuracy: 0.6094 - val_auc: 0.6611 - 116s/epoch - 7s/step\n",
            "Epoch 46/150\n",
            "16/16 - 115s - loss: 0.6844 - accuracy: 0.6387 - auc: 0.6806 - val_loss: 0.6444 - val_accuracy: 0.6250 - val_auc: 0.6934 - 115s/epoch - 7s/step\n",
            "Epoch 47/150\n",
            "16/16 - 116s - loss: 0.6957 - accuracy: 0.6408 - auc: 0.6716 - val_loss: 0.6496 - val_accuracy: 0.6250 - val_auc: 0.6846 - 116s/epoch - 7s/step\n",
            "Epoch 48/150\n",
            "16/16 - 115s - loss: 0.6744 - accuracy: 0.6605 - auc: 0.6943 - val_loss: 0.6917 - val_accuracy: 0.6094 - val_auc: 0.6292 - 115s/epoch - 7s/step\n",
            "Epoch 49/150\n",
            "16/16 - 116s - loss: 0.6779 - accuracy: 0.6491 - auc: 0.6812 - val_loss: 0.6762 - val_accuracy: 0.6250 - val_auc: 0.6511 - 116s/epoch - 7s/step\n",
            "Epoch 50/150\n",
            "16/16 - 116s - loss: 0.6833 - accuracy: 0.6439 - auc: 0.6804 - val_loss: 0.6421 - val_accuracy: 0.6250 - val_auc: 0.6934 - 116s/epoch - 7s/step\n",
            "Epoch 51/150\n",
            "16/16 - 116s - loss: 0.6784 - accuracy: 0.6398 - auc: 0.6884 - val_loss: 0.6887 - val_accuracy: 0.6094 - val_auc: 0.6475 - 116s/epoch - 7s/step\n",
            "Epoch 52/150\n",
            "16/16 - 116s - loss: 0.6654 - accuracy: 0.6553 - auc: 0.7062 - val_loss: 0.7013 - val_accuracy: 0.5938 - val_auc: 0.6331 - 116s/epoch - 7s/step\n",
            "Epoch 53/150\n",
            "16/16 - 116s - loss: 0.6866 - accuracy: 0.6460 - auc: 0.6861 - val_loss: 0.6975 - val_accuracy: 0.5938 - val_auc: 0.6580 - 116s/epoch - 7s/step\n",
            "Epoch 54/150\n",
            "16/16 - 116s - loss: 0.6697 - accuracy: 0.6449 - auc: 0.7026 - val_loss: 0.7261 - val_accuracy: 0.5625 - val_auc: 0.6174 - 116s/epoch - 7s/step\n",
            "Epoch 55/150\n",
            "16/16 - 116s - loss: 0.6496 - accuracy: 0.6749 - auc: 0.7313 - val_loss: 0.6770 - val_accuracy: 0.6094 - val_auc: 0.6704 - 116s/epoch - 7s/step\n",
            "Epoch 56/150\n",
            "16/16 - 116s - loss: 0.6856 - accuracy: 0.6501 - auc: 0.6871 - val_loss: 0.6515 - val_accuracy: 0.6406 - val_auc: 0.6760 - 116s/epoch - 7s/step\n",
            "Epoch 57/150\n",
            "16/16 - 116s - loss: 0.6669 - accuracy: 0.6553 - auc: 0.7088 - val_loss: 0.7054 - val_accuracy: 0.5938 - val_auc: 0.6355 - 116s/epoch - 7s/step\n",
            "Epoch 58/150\n",
            "16/16 - 116s - loss: 0.6812 - accuracy: 0.6522 - auc: 0.6887 - val_loss: 0.6973 - val_accuracy: 0.6094 - val_auc: 0.6472 - 116s/epoch - 7s/step\n",
            "Epoch 59/150\n",
            "16/16 - 116s - loss: 0.6571 - accuracy: 0.6646 - auc: 0.7223 - val_loss: 0.6761 - val_accuracy: 0.6094 - val_auc: 0.6655 - 116s/epoch - 7s/step\n",
            "Epoch 60/150\n",
            "16/16 - 116s - loss: 0.6583 - accuracy: 0.6656 - auc: 0.7148 - val_loss: 0.6593 - val_accuracy: 0.6094 - val_auc: 0.6887 - 116s/epoch - 7s/step\n",
            "Epoch 61/150\n",
            "16/16 - 116s - loss: 0.6449 - accuracy: 0.6832 - auc: 0.7358 - val_loss: 0.6596 - val_accuracy: 0.6406 - val_auc: 0.6755 - 116s/epoch - 7s/step\n",
            "Epoch 62/150\n",
            "16/16 - 116s - loss: 0.6748 - accuracy: 0.6718 - auc: 0.7074 - val_loss: 0.6557 - val_accuracy: 0.6094 - val_auc: 0.6885 - 116s/epoch - 7s/step\n",
            "Epoch 63/150\n",
            "16/16 - 116s - loss: 0.6854 - accuracy: 0.6656 - auc: 0.6923 - val_loss: 0.6335 - val_accuracy: 0.6719 - val_auc: 0.7122 - 116s/epoch - 7s/step\n",
            "Epoch 64/150\n",
            "16/16 - 116s - loss: 0.6511 - accuracy: 0.6739 - auc: 0.7236 - val_loss: 0.7098 - val_accuracy: 0.5938 - val_auc: 0.6375 - 116s/epoch - 7s/step\n",
            "Epoch 65/150\n",
            "16/16 - 116s - loss: 0.6592 - accuracy: 0.6760 - auc: 0.7173 - val_loss: 0.6731 - val_accuracy: 0.6406 - val_auc: 0.6631 - 116s/epoch - 7s/step\n",
            "Epoch 66/150\n",
            "16/16 - 116s - loss: 0.6636 - accuracy: 0.6781 - auc: 0.7088 - val_loss: 0.6560 - val_accuracy: 0.6094 - val_auc: 0.6943 - 116s/epoch - 7s/step\n",
            "Epoch 67/150\n",
            "16/16 - 116s - loss: 0.6609 - accuracy: 0.6781 - auc: 0.7139 - val_loss: 0.6440 - val_accuracy: 0.6406 - val_auc: 0.6890 - 116s/epoch - 7s/step\n",
            "Epoch 68/150\n",
            "16/16 - 115s - loss: 0.6611 - accuracy: 0.6760 - auc: 0.7165 - val_loss: 0.6647 - val_accuracy: 0.6094 - val_auc: 0.6785 - 115s/epoch - 7s/step\n",
            "Epoch 69/150\n",
            "16/16 - 116s - loss: 0.6842 - accuracy: 0.6470 - auc: 0.6879 - val_loss: 0.7154 - val_accuracy: 0.6094 - val_auc: 0.6414 - 116s/epoch - 7s/step\n",
            "Epoch 70/150\n",
            "16/16 - 116s - loss: 0.6440 - accuracy: 0.6915 - auc: 0.7353 - val_loss: 0.6714 - val_accuracy: 0.6094 - val_auc: 0.6711 - 116s/epoch - 7s/step\n",
            "Epoch 71/150\n",
            "16/16 - 116s - loss: 0.6592 - accuracy: 0.6749 - auc: 0.7148 - val_loss: 0.6804 - val_accuracy: 0.6250 - val_auc: 0.6682 - 116s/epoch - 7s/step\n",
            "Epoch 72/150\n",
            "16/16 - 116s - loss: 0.6512 - accuracy: 0.6812 - auc: 0.7202 - val_loss: 0.7015 - val_accuracy: 0.5938 - val_auc: 0.6375 - 116s/epoch - 7s/step\n",
            "Epoch 73/150\n",
            "16/16 - 116s - loss: 0.6474 - accuracy: 0.6760 - auc: 0.7323 - val_loss: 0.6655 - val_accuracy: 0.6094 - val_auc: 0.6807 - 116s/epoch - 7s/step\n",
            "Epoch 74/150\n",
            "16/16 - 116s - loss: 0.6457 - accuracy: 0.6925 - auc: 0.7351 - val_loss: 0.6648 - val_accuracy: 0.6094 - val_auc: 0.6838 - 116s/epoch - 7s/step\n",
            "Epoch 75/150\n",
            "16/16 - 115s - loss: 0.6690 - accuracy: 0.6739 - auc: 0.7154 - val_loss: 0.6734 - val_accuracy: 0.6406 - val_auc: 0.6753 - 115s/epoch - 7s/step\n",
            "Epoch 76/150\n",
            "16/16 - 115s - loss: 0.6514 - accuracy: 0.6874 - auc: 0.7277 - val_loss: 0.6966 - val_accuracy: 0.6250 - val_auc: 0.6582 - 115s/epoch - 7s/step\n",
            "Epoch 77/150\n",
            "16/16 - 116s - loss: 0.6565 - accuracy: 0.6739 - auc: 0.7193 - val_loss: 0.6811 - val_accuracy: 0.6406 - val_auc: 0.6500 - 116s/epoch - 7s/step\n",
            "Epoch 78/150\n",
            "16/16 - 116s - loss: 0.6479 - accuracy: 0.6853 - auc: 0.7303 - val_loss: 0.6868 - val_accuracy: 0.6562 - val_auc: 0.6453 - 116s/epoch - 7s/step\n",
            "Epoch 79/150\n",
            "16/16 - 116s - loss: 0.6447 - accuracy: 0.6946 - auc: 0.7321 - val_loss: 0.7137 - val_accuracy: 0.6094 - val_auc: 0.6465 - 116s/epoch - 7s/step\n",
            "Epoch 80/150\n",
            "16/16 - 115s - loss: 0.6543 - accuracy: 0.6915 - auc: 0.7251 - val_loss: 0.6893 - val_accuracy: 0.5469 - val_auc: 0.6667 - 115s/epoch - 7s/step\n",
            "Epoch 81/150\n",
            "16/16 - 115s - loss: 0.6587 - accuracy: 0.6853 - auc: 0.7212 - val_loss: 0.6873 - val_accuracy: 0.6250 - val_auc: 0.6516 - 115s/epoch - 7s/step\n",
            "Epoch 82/150\n",
            "16/16 - 116s - loss: 0.6480 - accuracy: 0.6894 - auc: 0.7320 - val_loss: 0.6772 - val_accuracy: 0.6094 - val_auc: 0.6606 - 116s/epoch - 7s/step\n",
            "Epoch 83/150\n",
            "16/16 - 116s - loss: 0.6455 - accuracy: 0.6843 - auc: 0.7364 - val_loss: 0.6963 - val_accuracy: 0.6250 - val_auc: 0.6528 - 116s/epoch - 7s/step\n",
            "Epoch 84/150\n",
            "16/16 - 116s - loss: 0.6405 - accuracy: 0.6915 - auc: 0.7379 - val_loss: 0.7095 - val_accuracy: 0.6250 - val_auc: 0.6414 - 116s/epoch - 7s/step\n",
            "Epoch 85/150\n",
            "16/16 - 116s - loss: 0.6587 - accuracy: 0.6698 - auc: 0.7207 - val_loss: 0.7008 - val_accuracy: 0.6094 - val_auc: 0.6545 - 116s/epoch - 7s/step\n",
            "Epoch 86/150\n",
            "16/16 - 116s - loss: 0.6520 - accuracy: 0.6894 - auc: 0.7258 - val_loss: 0.6842 - val_accuracy: 0.6250 - val_auc: 0.6621 - 116s/epoch - 7s/step\n",
            "Epoch 87/150\n",
            "16/16 - 116s - loss: 0.6529 - accuracy: 0.6977 - auc: 0.7265 - val_loss: 0.6658 - val_accuracy: 0.6406 - val_auc: 0.6887 - 116s/epoch - 7s/step\n",
            "Epoch 88/150\n",
            "16/16 - 116s - loss: 0.6411 - accuracy: 0.6874 - auc: 0.7344 - val_loss: 0.7212 - val_accuracy: 0.6250 - val_auc: 0.6511 - 116s/epoch - 7s/step\n",
            "Epoch 89/150\n",
            "16/16 - 115s - loss: 0.6239 - accuracy: 0.7050 - auc: 0.7558 - val_loss: 0.7248 - val_accuracy: 0.6250 - val_auc: 0.6375 - 115s/epoch - 7s/step\n",
            "Epoch 90/150\n",
            "16/16 - 115s - loss: 0.6584 - accuracy: 0.6894 - auc: 0.7159 - val_loss: 0.7019 - val_accuracy: 0.6250 - val_auc: 0.6462 - 115s/epoch - 7s/step\n",
            "Epoch 91/150\n",
            "16/16 - 116s - loss: 0.6259 - accuracy: 0.6998 - auc: 0.7479 - val_loss: 0.7217 - val_accuracy: 0.6250 - val_auc: 0.6355 - 116s/epoch - 7s/step\n",
            "Epoch 92/150\n",
            "16/16 - 115s - loss: 0.6312 - accuracy: 0.7112 - auc: 0.7437 - val_loss: 0.6891 - val_accuracy: 0.6094 - val_auc: 0.6614 - 115s/epoch - 7s/step\n",
            "Epoch 93/150\n",
            "16/16 - 116s - loss: 0.6502 - accuracy: 0.6853 - auc: 0.7326 - val_loss: 0.7007 - val_accuracy: 0.6406 - val_auc: 0.6521 - 116s/epoch - 7s/step\n",
            "Epoch 94/150\n",
            "16/16 - 116s - loss: 0.6425 - accuracy: 0.6822 - auc: 0.7302 - val_loss: 0.6880 - val_accuracy: 0.5781 - val_auc: 0.6770 - 116s/epoch - 7s/step\n",
            "Epoch 95/150\n",
            "16/16 - 116s - loss: 0.6387 - accuracy: 0.7081 - auc: 0.7455 - val_loss: 0.7082 - val_accuracy: 0.6406 - val_auc: 0.6401 - 116s/epoch - 7s/step\n",
            "Epoch 96/150\n",
            "16/16 - 116s - loss: 0.6597 - accuracy: 0.6708 - auc: 0.7191 - val_loss: 0.7013 - val_accuracy: 0.6250 - val_auc: 0.6650 - 116s/epoch - 7s/step\n",
            "Epoch 97/150\n",
            "16/16 - 116s - loss: 0.6335 - accuracy: 0.7019 - auc: 0.7412 - val_loss: 0.7093 - val_accuracy: 0.6406 - val_auc: 0.6560 - 116s/epoch - 7s/step\n",
            "Epoch 98/150\n",
            "16/16 - 115s - loss: 0.6502 - accuracy: 0.6884 - auc: 0.7242 - val_loss: 0.7333 - val_accuracy: 0.6094 - val_auc: 0.6169 - 115s/epoch - 7s/step\n",
            "Epoch 99/150\n",
            "16/16 - 116s - loss: 0.6373 - accuracy: 0.7070 - auc: 0.7448 - val_loss: 0.6777 - val_accuracy: 0.6250 - val_auc: 0.6958 - 116s/epoch - 7s/step\n",
            "Epoch 100/150\n",
            "16/16 - 116s - loss: 0.6513 - accuracy: 0.6801 - auc: 0.7228 - val_loss: 0.6919 - val_accuracy: 0.5938 - val_auc: 0.6704 - 116s/epoch - 7s/step\n",
            "Epoch 101/150\n",
            "16/16 - 116s - loss: 0.6458 - accuracy: 0.6884 - auc: 0.7322 - val_loss: 0.6885 - val_accuracy: 0.5938 - val_auc: 0.6772 - 116s/epoch - 7s/step\n",
            "Epoch 102/150\n",
            "16/16 - 116s - loss: 0.6411 - accuracy: 0.6988 - auc: 0.7338 - val_loss: 0.6520 - val_accuracy: 0.6250 - val_auc: 0.6969 - 116s/epoch - 7s/step\n",
            "Epoch 103/150\n",
            "16/16 - 116s - loss: 0.6278 - accuracy: 0.7091 - auc: 0.7524 - val_loss: 0.6946 - val_accuracy: 0.5781 - val_auc: 0.6804 - 116s/epoch - 7s/step\n",
            "Epoch 104/150\n",
            "16/16 - 115s - loss: 0.6406 - accuracy: 0.7101 - auc: 0.7435 - val_loss: 0.7046 - val_accuracy: 0.6250 - val_auc: 0.6748 - 115s/epoch - 7s/step\n",
            "Epoch 105/150\n",
            "16/16 - 115s - loss: 0.6372 - accuracy: 0.7091 - auc: 0.7448 - val_loss: 0.7466 - val_accuracy: 0.6250 - val_auc: 0.6365 - 115s/epoch - 7s/step\n",
            "Epoch 106/150\n",
            "16/16 - 115s - loss: 0.6237 - accuracy: 0.6967 - auc: 0.7558 - val_loss: 0.7177 - val_accuracy: 0.6250 - val_auc: 0.6504 - 115s/epoch - 7s/step\n",
            "Epoch 107/150\n",
            "16/16 - 116s - loss: 0.6638 - accuracy: 0.7070 - auc: 0.7197 - val_loss: 0.7180 - val_accuracy: 0.6250 - val_auc: 0.6372 - 116s/epoch - 7s/step\n",
            "Epoch 108/150\n",
            "16/16 - 116s - loss: 0.6549 - accuracy: 0.6977 - auc: 0.7240 - val_loss: 0.7755 - val_accuracy: 0.5781 - val_auc: 0.6243 - 116s/epoch - 7s/step\n",
            "Epoch 109/150\n",
            "16/16 - 116s - loss: 0.6319 - accuracy: 0.7091 - auc: 0.7418 - val_loss: 0.7374 - val_accuracy: 0.6406 - val_auc: 0.6243 - 116s/epoch - 7s/step\n",
            "Epoch 110/150\n",
            "16/16 - 116s - loss: 0.6366 - accuracy: 0.7195 - auc: 0.7433 - val_loss: 0.6773 - val_accuracy: 0.6094 - val_auc: 0.6975 - 116s/epoch - 7s/step\n",
            "Epoch 111/150\n",
            "16/16 - 116s - loss: 0.6463 - accuracy: 0.6770 - auc: 0.7303 - val_loss: 0.6899 - val_accuracy: 0.5938 - val_auc: 0.6902 - 116s/epoch - 7s/step\n",
            "Epoch 112/150\n",
            "16/16 - 116s - loss: 0.6504 - accuracy: 0.7081 - auc: 0.7366 - val_loss: 0.6749 - val_accuracy: 0.6406 - val_auc: 0.6914 - 116s/epoch - 7s/step\n",
            "Epoch 113/150\n",
            "16/16 - 116s - loss: 0.6436 - accuracy: 0.7029 - auc: 0.7428 - val_loss: 0.7728 - val_accuracy: 0.5938 - val_auc: 0.6077 - 116s/epoch - 7s/step\n",
            "Epoch 114/150\n",
            "16/16 - 116s - loss: 0.6190 - accuracy: 0.7195 - auc: 0.7595 - val_loss: 0.7748 - val_accuracy: 0.6094 - val_auc: 0.6123 - 116s/epoch - 7s/step\n",
            "Epoch 115/150\n",
            "16/16 - 116s - loss: 0.6466 - accuracy: 0.6936 - auc: 0.7327 - val_loss: 0.6857 - val_accuracy: 0.6094 - val_auc: 0.6951 - 116s/epoch - 7s/step\n",
            "Epoch 116/150\n",
            "16/16 - 115s - loss: 0.6165 - accuracy: 0.7236 - auc: 0.7614 - val_loss: 0.7828 - val_accuracy: 0.5938 - val_auc: 0.6145 - 115s/epoch - 7s/step\n",
            "Epoch 117/150\n",
            "16/16 - 115s - loss: 0.6217 - accuracy: 0.7195 - auc: 0.7638 - val_loss: 0.7311 - val_accuracy: 0.6094 - val_auc: 0.6509 - 115s/epoch - 7s/step\n",
            "Epoch 118/150\n",
            "16/16 - 116s - loss: 0.6255 - accuracy: 0.7070 - auc: 0.7504 - val_loss: 0.7210 - val_accuracy: 0.6406 - val_auc: 0.6499 - 116s/epoch - 7s/step\n",
            "Epoch 119/150\n",
            "16/16 - 116s - loss: 0.6337 - accuracy: 0.7195 - auc: 0.7484 - val_loss: 0.7693 - val_accuracy: 0.5938 - val_auc: 0.6335 - 116s/epoch - 7s/step\n",
            "Epoch 120/150\n",
            "16/16 - 116s - loss: 0.6382 - accuracy: 0.7039 - auc: 0.7418 - val_loss: 0.6939 - val_accuracy: 0.6250 - val_auc: 0.6841 - 116s/epoch - 7s/step\n",
            "Epoch 121/150\n",
            "16/16 - 116s - loss: 0.6211 - accuracy: 0.7008 - auc: 0.7525 - val_loss: 0.6556 - val_accuracy: 0.6562 - val_auc: 0.6987 - 116s/epoch - 7s/step\n",
            "Epoch 122/150\n",
            "16/16 - 116s - loss: 0.6249 - accuracy: 0.7164 - auc: 0.7488 - val_loss: 0.7102 - val_accuracy: 0.5938 - val_auc: 0.6724 - 116s/epoch - 7s/step\n",
            "Epoch 123/150\n",
            "16/16 - 116s - loss: 0.6271 - accuracy: 0.7060 - auc: 0.7527 - val_loss: 0.6552 - val_accuracy: 0.6562 - val_auc: 0.6980 - 116s/epoch - 7s/step\n",
            "Epoch 124/150\n",
            "16/16 - 116s - loss: 0.6449 - accuracy: 0.6988 - auc: 0.7339 - val_loss: 0.6992 - val_accuracy: 0.6094 - val_auc: 0.6838 - 116s/epoch - 7s/step\n",
            "Epoch 125/150\n",
            "16/16 - 116s - loss: 0.6555 - accuracy: 0.6925 - auc: 0.7228 - val_loss: 0.7573 - val_accuracy: 0.6094 - val_auc: 0.6245 - 116s/epoch - 7s/step\n",
            "Epoch 126/150\n",
            "16/16 - 116s - loss: 0.6260 - accuracy: 0.7226 - auc: 0.7530 - val_loss: 0.7570 - val_accuracy: 0.5781 - val_auc: 0.6379 - 116s/epoch - 7s/step\n",
            "Epoch 127/150\n",
            "16/16 - 116s - loss: 0.6382 - accuracy: 0.7091 - auc: 0.7381 - val_loss: 0.7292 - val_accuracy: 0.5938 - val_auc: 0.6646 - 116s/epoch - 7s/step\n",
            "Epoch 128/150\n",
            "16/16 - 116s - loss: 0.6102 - accuracy: 0.7112 - auc: 0.7652 - val_loss: 0.7441 - val_accuracy: 0.5781 - val_auc: 0.6399 - 116s/epoch - 7s/step\n",
            "Epoch 129/150\n",
            "16/16 - 116s - loss: 0.6432 - accuracy: 0.6925 - auc: 0.7327 - val_loss: 0.8003 - val_accuracy: 0.5938 - val_auc: 0.5945 - 116s/epoch - 7s/step\n",
            "Epoch 130/150\n",
            "16/16 - 116s - loss: 0.6464 - accuracy: 0.6905 - auc: 0.7360 - val_loss: 0.7678 - val_accuracy: 0.5625 - val_auc: 0.6475 - 116s/epoch - 7s/step\n",
            "Epoch 131/150\n",
            "16/16 - 116s - loss: 0.6298 - accuracy: 0.6946 - auc: 0.7464 - val_loss: 0.6579 - val_accuracy: 0.6406 - val_auc: 0.6992 - 116s/epoch - 7s/step\n",
            "Epoch 132/150\n",
            "16/16 - 116s - loss: 0.6289 - accuracy: 0.7039 - auc: 0.7449 - val_loss: 0.7146 - val_accuracy: 0.5938 - val_auc: 0.6663 - 116s/epoch - 7s/step\n",
            "Epoch 133/150\n",
            "16/16 - 116s - loss: 0.6344 - accuracy: 0.7070 - auc: 0.7404 - val_loss: 0.7539 - val_accuracy: 0.5781 - val_auc: 0.6584 - 116s/epoch - 7s/step\n",
            "Epoch 134/150\n",
            "16/16 - 116s - loss: 0.6349 - accuracy: 0.6977 - auc: 0.7399 - val_loss: 0.8066 - val_accuracy: 0.5312 - val_auc: 0.6294 - 116s/epoch - 7s/step\n",
            "Epoch 135/150\n",
            "16/16 - 116s - loss: 0.6259 - accuracy: 0.7112 - auc: 0.7501 - val_loss: 0.6956 - val_accuracy: 0.6094 - val_auc: 0.6731 - 116s/epoch - 7s/step\n",
            "Epoch 136/150\n",
            "16/16 - 116s - loss: 0.6155 - accuracy: 0.7267 - auc: 0.7641 - val_loss: 0.7177 - val_accuracy: 0.6094 - val_auc: 0.6667 - 116s/epoch - 7s/step\n",
            "Epoch 137/150\n",
            "16/16 - 115s - loss: 0.6342 - accuracy: 0.7174 - auc: 0.7468 - val_loss: 0.7180 - val_accuracy: 0.5938 - val_auc: 0.6760 - 115s/epoch - 7s/step\n",
            "Epoch 138/150\n",
            "16/16 - 115s - loss: 0.6204 - accuracy: 0.7060 - auc: 0.7595 - val_loss: 0.6930 - val_accuracy: 0.5938 - val_auc: 0.6807 - 115s/epoch - 7s/step\n",
            "Epoch 139/150\n",
            "16/16 - 115s - loss: 0.6394 - accuracy: 0.7143 - auc: 0.7398 - val_loss: 0.6703 - val_accuracy: 0.6094 - val_auc: 0.6954 - 115s/epoch - 7s/step\n",
            "Epoch 140/150\n",
            "16/16 - 115s - loss: 0.6503 - accuracy: 0.6905 - auc: 0.7288 - val_loss: 0.7158 - val_accuracy: 0.6094 - val_auc: 0.6779 - 115s/epoch - 7s/step\n",
            "Epoch 141/150\n",
            "16/16 - 115s - loss: 0.6531 - accuracy: 0.6760 - auc: 0.7245 - val_loss: 0.7432 - val_accuracy: 0.5938 - val_auc: 0.6453 - 115s/epoch - 7s/step\n",
            "Epoch 142/150\n",
            "16/16 - 116s - loss: 0.6418 - accuracy: 0.6988 - auc: 0.7318 - val_loss: 0.7803 - val_accuracy: 0.5625 - val_auc: 0.6111 - 116s/epoch - 7s/step\n",
            "Epoch 143/150\n",
            "16/16 - 116s - loss: 0.6485 - accuracy: 0.7039 - auc: 0.7304 - val_loss: 0.7853 - val_accuracy: 0.6094 - val_auc: 0.6094 - 116s/epoch - 7s/step\n",
            "Epoch 144/150\n",
            "16/16 - 116s - loss: 0.6199 - accuracy: 0.7215 - auc: 0.7585 - val_loss: 0.6757 - val_accuracy: 0.6406 - val_auc: 0.6862 - 116s/epoch - 7s/step\n",
            "Epoch 145/150\n",
            "16/16 - 116s - loss: 0.6419 - accuracy: 0.7008 - auc: 0.7374 - val_loss: 0.6819 - val_accuracy: 0.6094 - val_auc: 0.6753 - 116s/epoch - 7s/step\n",
            "Epoch 146/150\n",
            "16/16 - 116s - loss: 0.6380 - accuracy: 0.6957 - auc: 0.7364 - val_loss: 0.6619 - val_accuracy: 0.6875 - val_auc: 0.6892 - 116s/epoch - 7s/step\n",
            "Epoch 147/150\n",
            "16/16 - 115s - loss: 0.6207 - accuracy: 0.7153 - auc: 0.7591 - val_loss: 0.6702 - val_accuracy: 0.6250 - val_auc: 0.6868 - 115s/epoch - 7s/step\n",
            "Epoch 148/150\n",
            "16/16 - 115s - loss: 0.6323 - accuracy: 0.7019 - auc: 0.7426 - val_loss: 0.6755 - val_accuracy: 0.6250 - val_auc: 0.6907 - 115s/epoch - 7s/step\n",
            "Epoch 149/150\n",
            "16/16 - 116s - loss: 0.6228 - accuracy: 0.7039 - auc: 0.7509 - val_loss: 0.7437 - val_accuracy: 0.5625 - val_auc: 0.6475 - 116s/epoch - 7s/step\n",
            "Epoch 150/150\n",
            "16/16 - 116s - loss: 0.6265 - accuracy: 0.7112 - auc: 0.7468 - val_loss: 0.7078 - val_accuracy: 0.6094 - val_auc: 0.6794 - 116s/epoch - 7s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 242/242 [00:49<00:00,  4.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7163\n",
            "Recall: 0.8211\n",
            "Threshold: 0.3051\n",
            "F1 Score: 0.7652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1168/1168 [03:50<00:00,  5.07it/s]\n"
          ]
        }
      ],
      "source": [
        "Model_Name='Pretrained plus 3rd layer Model Saved(balanced Dataset)'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 4th layer Model Saved(balanced Dataset)'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history4 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history4.history, timestamp,Model_Name)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./PretrainedPlus4_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkRRUEAD5dG_",
        "outputId": "78c94b1b-5352-4fe8-f0e6-a12e22821cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 2)                 74974984  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               384       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,976,138\n",
            "Trainable params: 51,386,378\n",
            "Non-trainable params: 23,589,760\n",
            "_________________________________________________________________\n",
            "rows in train_df 966\n",
            "rows in val_df 242\n",
            "Found 966 non-validated image filenames.\n",
            "Found 242 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "16/16 - 502s - loss: 0.7122 - accuracy: 0.5062 - auc: 0.4741 - val_loss: 0.6994 - val_accuracy: 0.4219 - val_auc: 0.3590 - 502s/epoch - 31s/step\n",
            "Epoch 2/150\n",
            "16/16 - 119s - loss: 0.7125 - accuracy: 0.4928 - auc: 0.4644 - val_loss: 0.7206 - val_accuracy: 0.4531 - val_auc: 0.3368 - 119s/epoch - 7s/step\n",
            "Epoch 3/150\n",
            "16/16 - 118s - loss: 0.7062 - accuracy: 0.4876 - auc: 0.4816 - val_loss: 0.7203 - val_accuracy: 0.4062 - val_auc: 0.3564 - 118s/epoch - 7s/step\n",
            "Epoch 4/150\n",
            "16/16 - 118s - loss: 0.6998 - accuracy: 0.5280 - auc: 0.5237 - val_loss: 0.7002 - val_accuracy: 0.5000 - val_auc: 0.5216 - 118s/epoch - 7s/step\n",
            "Epoch 5/150\n",
            "16/16 - 119s - loss: 0.6914 - accuracy: 0.5414 - auc: 0.5636 - val_loss: 0.6826 - val_accuracy: 0.5469 - val_auc: 0.6104 - 119s/epoch - 7s/step\n",
            "Epoch 6/150\n",
            "16/16 - 118s - loss: 0.6799 - accuracy: 0.5776 - auc: 0.6300 - val_loss: 0.6986 - val_accuracy: 0.4062 - val_auc: 0.4301 - 118s/epoch - 7s/step\n",
            "Epoch 7/150\n",
            "16/16 - 119s - loss: 0.6709 - accuracy: 0.6211 - auc: 0.6580 - val_loss: 0.7003 - val_accuracy: 0.6406 - val_auc: 0.5686 - 119s/epoch - 7s/step\n",
            "Epoch 8/150\n",
            "16/16 - 119s - loss: 0.6690 - accuracy: 0.6398 - auc: 0.6624 - val_loss: 0.6702 - val_accuracy: 0.7031 - val_auc: 0.6704 - 119s/epoch - 7s/step\n",
            "Epoch 9/150\n",
            "16/16 - 118s - loss: 0.6644 - accuracy: 0.6429 - auc: 0.6722 - val_loss: 0.6568 - val_accuracy: 0.7188 - val_auc: 0.6919 - 118s/epoch - 7s/step\n",
            "Epoch 10/150\n",
            "16/16 - 119s - loss: 0.6587 - accuracy: 0.6760 - auc: 0.6849 - val_loss: 0.6909 - val_accuracy: 0.6406 - val_auc: 0.5745 - 119s/epoch - 7s/step\n",
            "Epoch 11/150\n",
            "16/16 - 119s - loss: 0.6563 - accuracy: 0.6791 - auc: 0.6851 - val_loss: 0.6860 - val_accuracy: 0.6250 - val_auc: 0.5642 - 119s/epoch - 7s/step\n",
            "Epoch 12/150\n",
            "16/16 - 119s - loss: 0.6530 - accuracy: 0.6853 - auc: 0.6852 - val_loss: 0.6666 - val_accuracy: 0.6562 - val_auc: 0.6238 - 119s/epoch - 7s/step\n",
            "Epoch 13/150\n",
            "16/16 - 119s - loss: 0.6416 - accuracy: 0.6977 - auc: 0.7162 - val_loss: 0.6760 - val_accuracy: 0.6250 - val_auc: 0.5833 - 119s/epoch - 7s/step\n",
            "Epoch 14/150\n",
            "16/16 - 119s - loss: 0.6389 - accuracy: 0.7039 - auc: 0.7128 - val_loss: 0.6685 - val_accuracy: 0.6406 - val_auc: 0.5984 - 119s/epoch - 7s/step\n",
            "Epoch 15/150\n",
            "16/16 - 118s - loss: 0.6416 - accuracy: 0.7008 - auc: 0.6917 - val_loss: 0.6708 - val_accuracy: 0.6250 - val_auc: 0.5823 - 118s/epoch - 7s/step\n",
            "Epoch 16/150\n",
            "16/16 - 119s - loss: 0.6315 - accuracy: 0.6853 - auc: 0.7222 - val_loss: 0.6413 - val_accuracy: 0.6875 - val_auc: 0.6809 - 119s/epoch - 7s/step\n",
            "Epoch 17/150\n",
            "16/16 - 119s - loss: 0.6239 - accuracy: 0.7008 - auc: 0.7403 - val_loss: 0.6269 - val_accuracy: 0.7031 - val_auc: 0.6953 - 119s/epoch - 7s/step\n",
            "Epoch 18/150\n",
            "16/16 - 119s - loss: 0.6315 - accuracy: 0.6905 - auc: 0.7020 - val_loss: 0.6286 - val_accuracy: 0.7188 - val_auc: 0.6821 - 119s/epoch - 7s/step\n",
            "Epoch 19/150\n",
            "16/16 - 119s - loss: 0.6263 - accuracy: 0.7019 - auc: 0.7095 - val_loss: 0.6298 - val_accuracy: 0.6875 - val_auc: 0.6748 - 119s/epoch - 7s/step\n",
            "Epoch 20/150\n",
            "16/16 - 119s - loss: 0.6166 - accuracy: 0.7070 - auc: 0.7289 - val_loss: 0.6336 - val_accuracy: 0.6875 - val_auc: 0.6670 - 119s/epoch - 7s/step\n",
            "Epoch 21/150\n",
            "16/16 - 119s - loss: 0.6235 - accuracy: 0.6936 - auc: 0.7125 - val_loss: 0.6325 - val_accuracy: 0.6719 - val_auc: 0.6663 - 119s/epoch - 7s/step\n",
            "Epoch 22/150\n",
            "16/16 - 119s - loss: 0.6193 - accuracy: 0.7029 - auc: 0.7200 - val_loss: 0.6517 - val_accuracy: 0.6406 - val_auc: 0.6404 - 119s/epoch - 7s/step\n",
            "Epoch 23/150\n",
            "16/16 - 119s - loss: 0.6055 - accuracy: 0.7215 - auc: 0.7356 - val_loss: 0.6675 - val_accuracy: 0.6250 - val_auc: 0.6213 - 119s/epoch - 7s/step\n",
            "Epoch 24/150\n",
            "16/16 - 119s - loss: 0.5992 - accuracy: 0.7205 - auc: 0.7459 - val_loss: 0.6518 - val_accuracy: 0.6562 - val_auc: 0.5986 - 119s/epoch - 7s/step\n",
            "Epoch 25/150\n",
            "16/16 - 119s - loss: 0.6066 - accuracy: 0.7008 - auc: 0.7455 - val_loss: 0.6538 - val_accuracy: 0.6406 - val_auc: 0.6262 - 119s/epoch - 7s/step\n",
            "Epoch 26/150\n",
            "16/16 - 119s - loss: 0.5977 - accuracy: 0.7226 - auc: 0.7336 - val_loss: 0.6572 - val_accuracy: 0.6406 - val_auc: 0.6074 - 119s/epoch - 7s/step\n",
            "Epoch 27/150\n",
            "16/16 - 119s - loss: 0.6064 - accuracy: 0.7101 - auc: 0.7220 - val_loss: 0.6406 - val_accuracy: 0.6719 - val_auc: 0.6184 - 119s/epoch - 7s/step\n",
            "Epoch 28/150\n",
            "16/16 - 118s - loss: 0.5918 - accuracy: 0.7257 - auc: 0.7487 - val_loss: 0.6149 - val_accuracy: 0.6875 - val_auc: 0.6826 - 118s/epoch - 7s/step\n",
            "Epoch 29/150\n",
            "16/16 - 119s - loss: 0.5938 - accuracy: 0.7257 - auc: 0.7368 - val_loss: 0.6636 - val_accuracy: 0.6250 - val_auc: 0.6418 - 119s/epoch - 7s/step\n",
            "Epoch 30/150\n",
            "16/16 - 118s - loss: 0.6020 - accuracy: 0.7101 - auc: 0.7279 - val_loss: 0.6547 - val_accuracy: 0.6406 - val_auc: 0.6377 - 118s/epoch - 7s/step\n",
            "Epoch 31/150\n",
            "16/16 - 119s - loss: 0.5982 - accuracy: 0.7112 - auc: 0.7357 - val_loss: 0.6557 - val_accuracy: 0.6250 - val_auc: 0.6387 - 119s/epoch - 7s/step\n",
            "Epoch 32/150\n",
            "16/16 - 119s - loss: 0.5848 - accuracy: 0.7288 - auc: 0.7532 - val_loss: 0.6615 - val_accuracy: 0.6250 - val_auc: 0.6219 - 119s/epoch - 7s/step\n",
            "Epoch 33/150\n",
            "16/16 - 119s - loss: 0.5904 - accuracy: 0.7246 - auc: 0.7381 - val_loss: 0.6561 - val_accuracy: 0.6406 - val_auc: 0.6289 - 119s/epoch - 7s/step\n",
            "Epoch 34/150\n",
            "16/16 - 119s - loss: 0.5915 - accuracy: 0.7195 - auc: 0.7300 - val_loss: 0.6775 - val_accuracy: 0.5938 - val_auc: 0.6226 - 119s/epoch - 7s/step\n",
            "Epoch 35/150\n",
            "16/16 - 119s - loss: 0.6042 - accuracy: 0.7019 - auc: 0.7237 - val_loss: 0.6649 - val_accuracy: 0.6406 - val_auc: 0.6292 - 119s/epoch - 7s/step\n",
            "Epoch 36/150\n",
            "16/16 - 119s - loss: 0.5975 - accuracy: 0.7174 - auc: 0.7301 - val_loss: 0.6570 - val_accuracy: 0.6406 - val_auc: 0.6436 - 119s/epoch - 7s/step\n",
            "Epoch 37/150\n",
            "16/16 - 119s - loss: 0.5640 - accuracy: 0.7526 - auc: 0.7747 - val_loss: 0.6573 - val_accuracy: 0.6562 - val_auc: 0.6587 - 119s/epoch - 7s/step\n",
            "Epoch 38/150\n",
            "16/16 - 119s - loss: 0.5808 - accuracy: 0.7340 - auc: 0.7508 - val_loss: 0.6546 - val_accuracy: 0.6406 - val_auc: 0.6567 - 119s/epoch - 7s/step\n",
            "Epoch 39/150\n",
            "16/16 - 119s - loss: 0.5873 - accuracy: 0.7195 - auc: 0.7443 - val_loss: 0.6433 - val_accuracy: 0.6406 - val_auc: 0.6614 - 119s/epoch - 7s/step\n",
            "Epoch 40/150\n",
            "16/16 - 119s - loss: 0.5862 - accuracy: 0.7164 - auc: 0.7409 - val_loss: 0.6821 - val_accuracy: 0.6250 - val_auc: 0.6130 - 119s/epoch - 7s/step\n",
            "Epoch 41/150\n",
            "16/16 - 118s - loss: 0.5856 - accuracy: 0.7205 - auc: 0.7517 - val_loss: 0.6789 - val_accuracy: 0.6250 - val_auc: 0.6196 - 118s/epoch - 7s/step\n",
            "Epoch 42/150\n",
            "16/16 - 119s - loss: 0.5852 - accuracy: 0.7226 - auc: 0.7403 - val_loss: 0.6795 - val_accuracy: 0.6250 - val_auc: 0.6370 - 119s/epoch - 7s/step\n",
            "Epoch 43/150\n",
            "16/16 - 117s - loss: 0.5957 - accuracy: 0.7112 - auc: 0.7262 - val_loss: 0.6716 - val_accuracy: 0.6250 - val_auc: 0.6589 - 117s/epoch - 7s/step\n",
            "Epoch 44/150\n",
            "16/16 - 117s - loss: 0.5685 - accuracy: 0.7474 - auc: 0.7656 - val_loss: 0.6826 - val_accuracy: 0.6094 - val_auc: 0.6748 - 117s/epoch - 7s/step\n",
            "Epoch 45/150\n",
            "16/16 - 117s - loss: 0.5902 - accuracy: 0.7226 - auc: 0.7411 - val_loss: 0.6319 - val_accuracy: 0.6719 - val_auc: 0.6643 - 117s/epoch - 7s/step\n",
            "Epoch 46/150\n",
            "16/16 - 118s - loss: 0.5905 - accuracy: 0.7184 - auc: 0.7453 - val_loss: 0.6445 - val_accuracy: 0.6719 - val_auc: 0.7087 - 118s/epoch - 7s/step\n",
            "Epoch 47/150\n",
            "16/16 - 119s - loss: 0.5780 - accuracy: 0.7329 - auc: 0.7532 - val_loss: 0.6868 - val_accuracy: 0.6094 - val_auc: 0.6631 - 119s/epoch - 7s/step\n",
            "Epoch 48/150\n",
            "16/16 - 119s - loss: 0.5810 - accuracy: 0.7226 - auc: 0.7582 - val_loss: 0.6491 - val_accuracy: 0.6562 - val_auc: 0.7161 - 119s/epoch - 7s/step\n",
            "Epoch 49/150\n",
            "16/16 - 119s - loss: 0.5782 - accuracy: 0.7298 - auc: 0.7500 - val_loss: 0.6169 - val_accuracy: 0.6875 - val_auc: 0.7563 - 119s/epoch - 7s/step\n",
            "Epoch 50/150\n",
            "16/16 - 119s - loss: 0.5811 - accuracy: 0.7277 - auc: 0.7511 - val_loss: 0.7153 - val_accuracy: 0.5938 - val_auc: 0.6084 - 119s/epoch - 7s/step\n",
            "Epoch 51/150\n",
            "16/16 - 116s - loss: 0.5783 - accuracy: 0.7246 - auc: 0.7540 - val_loss: 0.7170 - val_accuracy: 0.5938 - val_auc: 0.6079 - 116s/epoch - 7s/step\n",
            "Epoch 52/150\n",
            "16/16 - 116s - loss: 0.5854 - accuracy: 0.7257 - auc: 0.7467 - val_loss: 0.6459 - val_accuracy: 0.6719 - val_auc: 0.6628 - 116s/epoch - 7s/step\n",
            "Epoch 53/150\n",
            "16/16 - 116s - loss: 0.6098 - accuracy: 0.6967 - auc: 0.7285 - val_loss: 0.6526 - val_accuracy: 0.6562 - val_auc: 0.7068 - 116s/epoch - 7s/step\n",
            "Epoch 54/150\n",
            "16/16 - 116s - loss: 0.5654 - accuracy: 0.7505 - auc: 0.7663 - val_loss: 0.7118 - val_accuracy: 0.6094 - val_auc: 0.6218 - 116s/epoch - 7s/step\n",
            "Epoch 55/150\n",
            "16/16 - 116s - loss: 0.5746 - accuracy: 0.7298 - auc: 0.7629 - val_loss: 0.7295 - val_accuracy: 0.5938 - val_auc: 0.6045 - 116s/epoch - 7s/step\n",
            "Epoch 56/150\n",
            "16/16 - 116s - loss: 0.5750 - accuracy: 0.7340 - auc: 0.7566 - val_loss: 0.7512 - val_accuracy: 0.5625 - val_auc: 0.5928 - 116s/epoch - 7s/step\n",
            "Epoch 57/150\n",
            "16/16 - 116s - loss: 0.5632 - accuracy: 0.7495 - auc: 0.7630 - val_loss: 0.7258 - val_accuracy: 0.5938 - val_auc: 0.6274 - 116s/epoch - 7s/step\n",
            "Epoch 58/150\n",
            "16/16 - 116s - loss: 0.5756 - accuracy: 0.7288 - auc: 0.7578 - val_loss: 0.6573 - val_accuracy: 0.6562 - val_auc: 0.6890 - 116s/epoch - 7s/step\n",
            "Epoch 59/150\n",
            "16/16 - 116s - loss: 0.5802 - accuracy: 0.7277 - auc: 0.7545 - val_loss: 0.6622 - val_accuracy: 0.6562 - val_auc: 0.6479 - 116s/epoch - 7s/step\n",
            "Epoch 60/150\n",
            "16/16 - 117s - loss: 0.5604 - accuracy: 0.7422 - auc: 0.7733 - val_loss: 0.6945 - val_accuracy: 0.6250 - val_auc: 0.6528 - 117s/epoch - 7s/step\n",
            "Epoch 61/150\n",
            "16/16 - 115s - loss: 0.5843 - accuracy: 0.7267 - auc: 0.7445 - val_loss: 0.6067 - val_accuracy: 0.7031 - val_auc: 0.7786 - 115s/epoch - 7s/step\n",
            "Epoch 62/150\n",
            "16/16 - 115s - loss: 0.5873 - accuracy: 0.7236 - auc: 0.7461 - val_loss: 0.6595 - val_accuracy: 0.6719 - val_auc: 0.6606 - 115s/epoch - 7s/step\n",
            "Epoch 63/150\n",
            "16/16 - 115s - loss: 0.5720 - accuracy: 0.7298 - auc: 0.7662 - val_loss: 0.6871 - val_accuracy: 0.6406 - val_auc: 0.6350 - 115s/epoch - 7s/step\n",
            "Epoch 64/150\n",
            "16/16 - 116s - loss: 0.5731 - accuracy: 0.7350 - auc: 0.7538 - val_loss: 0.6632 - val_accuracy: 0.6562 - val_auc: 0.6504 - 116s/epoch - 7s/step\n",
            "Epoch 65/150\n",
            "16/16 - 116s - loss: 0.6002 - accuracy: 0.7081 - auc: 0.7332 - val_loss: 0.6754 - val_accuracy: 0.6250 - val_auc: 0.6636 - 116s/epoch - 7s/step\n",
            "Epoch 66/150\n",
            "16/16 - 116s - loss: 0.5649 - accuracy: 0.7453 - auc: 0.7701 - val_loss: 0.6624 - val_accuracy: 0.6562 - val_auc: 0.6479 - 116s/epoch - 7s/step\n",
            "Epoch 67/150\n",
            "16/16 - 117s - loss: 0.5763 - accuracy: 0.7340 - auc: 0.7596 - val_loss: 0.6646 - val_accuracy: 0.6562 - val_auc: 0.6504 - 117s/epoch - 7s/step\n",
            "Epoch 68/150\n",
            "16/16 - 117s - loss: 0.5714 - accuracy: 0.7402 - auc: 0.7589 - val_loss: 0.6430 - val_accuracy: 0.6719 - val_auc: 0.7134 - 117s/epoch - 7s/step\n",
            "Epoch 69/150\n",
            "16/16 - 117s - loss: 0.5707 - accuracy: 0.7402 - auc: 0.7548 - val_loss: 0.7119 - val_accuracy: 0.6250 - val_auc: 0.6248 - 117s/epoch - 7s/step\n",
            "Epoch 70/150\n",
            "16/16 - 116s - loss: 0.5740 - accuracy: 0.7422 - auc: 0.7527 - val_loss: 0.6850 - val_accuracy: 0.6406 - val_auc: 0.6509 - 116s/epoch - 7s/step\n",
            "Epoch 71/150\n",
            "16/16 - 117s - loss: 0.5855 - accuracy: 0.7153 - auc: 0.7544 - val_loss: 0.6660 - val_accuracy: 0.6562 - val_auc: 0.6475 - 117s/epoch - 7s/step\n",
            "Epoch 72/150\n",
            "16/16 - 117s - loss: 0.5682 - accuracy: 0.7329 - auc: 0.7670 - val_loss: 0.6623 - val_accuracy: 0.6562 - val_auc: 0.6506 - 117s/epoch - 7s/step\n",
            "Epoch 73/150\n",
            "16/16 - 116s - loss: 0.5921 - accuracy: 0.7174 - auc: 0.7366 - val_loss: 0.6918 - val_accuracy: 0.6250 - val_auc: 0.6370 - 116s/epoch - 7s/step\n",
            "Epoch 74/150\n",
            "16/16 - 116s - loss: 0.5768 - accuracy: 0.7288 - auc: 0.7515 - val_loss: 0.6662 - val_accuracy: 0.6406 - val_auc: 0.6528 - 116s/epoch - 7s/step\n",
            "Epoch 75/150\n",
            "16/16 - 116s - loss: 0.5733 - accuracy: 0.7381 - auc: 0.7509 - val_loss: 0.6697 - val_accuracy: 0.6562 - val_auc: 0.6455 - 116s/epoch - 7s/step\n",
            "Epoch 76/150\n",
            "16/16 - 116s - loss: 0.5707 - accuracy: 0.7319 - auc: 0.7711 - val_loss: 0.6544 - val_accuracy: 0.6250 - val_auc: 0.7307 - 116s/epoch - 7s/step\n",
            "Epoch 77/150\n",
            "16/16 - 116s - loss: 0.5635 - accuracy: 0.7422 - auc: 0.7627 - val_loss: 0.6826 - val_accuracy: 0.6562 - val_auc: 0.6443 - 116s/epoch - 7s/step\n",
            "Epoch 78/150\n",
            "16/16 - 116s - loss: 0.5823 - accuracy: 0.7246 - auc: 0.7470 - val_loss: 0.6023 - val_accuracy: 0.7188 - val_auc: 0.7532 - 116s/epoch - 7s/step\n",
            "Epoch 79/150\n",
            "16/16 - 116s - loss: 0.5892 - accuracy: 0.7205 - auc: 0.7504 - val_loss: 0.6734 - val_accuracy: 0.6406 - val_auc: 0.6582 - 116s/epoch - 7s/step\n",
            "Epoch 80/150\n",
            "16/16 - 116s - loss: 0.5718 - accuracy: 0.7371 - auc: 0.7602 - val_loss: 0.6539 - val_accuracy: 0.6719 - val_auc: 0.7004 - 116s/epoch - 7s/step\n",
            "Epoch 81/150\n",
            "16/16 - 116s - loss: 0.5940 - accuracy: 0.7112 - auc: 0.7445 - val_loss: 0.6419 - val_accuracy: 0.6562 - val_auc: 0.7271 - 116s/epoch - 7s/step\n",
            "Epoch 82/150\n",
            "16/16 - 116s - loss: 0.5715 - accuracy: 0.7371 - auc: 0.7618 - val_loss: 0.6566 - val_accuracy: 0.6562 - val_auc: 0.6846 - 116s/epoch - 7s/step\n",
            "Epoch 83/150\n",
            "16/16 - 115s - loss: 0.5645 - accuracy: 0.7371 - auc: 0.7728 - val_loss: 0.6797 - val_accuracy: 0.6406 - val_auc: 0.6475 - 115s/epoch - 7s/step\n",
            "Epoch 84/150\n",
            "16/16 - 116s - loss: 0.5723 - accuracy: 0.7319 - auc: 0.7657 - val_loss: 0.6863 - val_accuracy: 0.6406 - val_auc: 0.6558 - 116s/epoch - 7s/step\n",
            "Epoch 85/150\n",
            "16/16 - 116s - loss: 0.5810 - accuracy: 0.7246 - auc: 0.7573 - val_loss: 0.5947 - val_accuracy: 0.7031 - val_auc: 0.7566 - 116s/epoch - 7s/step\n",
            "Epoch 86/150\n",
            "16/16 - 116s - loss: 0.5704 - accuracy: 0.7360 - auc: 0.7590 - val_loss: 0.5975 - val_accuracy: 0.7188 - val_auc: 0.7510 - 116s/epoch - 7s/step\n",
            "Epoch 87/150\n",
            "16/16 - 116s - loss: 0.5796 - accuracy: 0.7288 - auc: 0.7540 - val_loss: 0.7211 - val_accuracy: 0.6094 - val_auc: 0.6343 - 116s/epoch - 7s/step\n",
            "Epoch 88/150\n",
            "16/16 - 116s - loss: 0.5710 - accuracy: 0.7360 - auc: 0.7636 - val_loss: 0.6695 - val_accuracy: 0.6406 - val_auc: 0.6802 - 116s/epoch - 7s/step\n",
            "Epoch 89/150\n",
            "16/16 - 116s - loss: 0.5646 - accuracy: 0.7371 - auc: 0.7779 - val_loss: 0.6687 - val_accuracy: 0.6719 - val_auc: 0.6555 - 116s/epoch - 7s/step\n",
            "Epoch 90/150\n",
            "16/16 - 116s - loss: 0.5708 - accuracy: 0.7371 - auc: 0.7643 - val_loss: 0.6602 - val_accuracy: 0.6562 - val_auc: 0.6721 - 116s/epoch - 7s/step\n",
            "Epoch 91/150\n",
            "16/16 - 116s - loss: 0.5880 - accuracy: 0.7164 - auc: 0.7521 - val_loss: 0.7064 - val_accuracy: 0.6250 - val_auc: 0.6326 - 116s/epoch - 7s/step\n",
            "Epoch 92/150\n",
            "16/16 - 116s - loss: 0.5702 - accuracy: 0.7391 - auc: 0.7670 - val_loss: 0.6513 - val_accuracy: 0.6562 - val_auc: 0.7231 - 116s/epoch - 7s/step\n",
            "Epoch 93/150\n",
            "16/16 - 116s - loss: 0.5749 - accuracy: 0.7319 - auc: 0.7584 - val_loss: 0.7286 - val_accuracy: 0.6094 - val_auc: 0.6201 - 116s/epoch - 7s/step\n",
            "Epoch 94/150\n",
            "16/16 - 116s - loss: 0.5618 - accuracy: 0.7464 - auc: 0.7674 - val_loss: 0.6935 - val_accuracy: 0.6406 - val_auc: 0.6418 - 116s/epoch - 7s/step\n",
            "Epoch 95/150\n",
            "16/16 - 116s - loss: 0.5679 - accuracy: 0.7381 - auc: 0.7681 - val_loss: 0.7143 - val_accuracy: 0.6094 - val_auc: 0.6189 - 116s/epoch - 7s/step\n",
            "Epoch 96/150\n",
            "16/16 - 116s - loss: 0.5765 - accuracy: 0.7340 - auc: 0.7456 - val_loss: 0.7073 - val_accuracy: 0.6250 - val_auc: 0.6350 - 116s/epoch - 7s/step\n",
            "Epoch 97/150\n",
            "16/16 - 116s - loss: 0.5702 - accuracy: 0.7381 - auc: 0.7717 - val_loss: 0.6481 - val_accuracy: 0.6875 - val_auc: 0.6626 - 116s/epoch - 7s/step\n",
            "Epoch 98/150\n",
            "16/16 - 116s - loss: 0.5860 - accuracy: 0.7195 - auc: 0.7509 - val_loss: 0.6605 - val_accuracy: 0.6562 - val_auc: 0.7090 - 116s/epoch - 7s/step\n",
            "Epoch 99/150\n",
            "16/16 - 116s - loss: 0.5773 - accuracy: 0.7288 - auc: 0.7622 - val_loss: 0.6669 - val_accuracy: 0.6406 - val_auc: 0.6919 - 116s/epoch - 7s/step\n",
            "Epoch 100/150\n",
            "16/16 - 116s - loss: 0.5883 - accuracy: 0.7236 - auc: 0.7477 - val_loss: 0.7323 - val_accuracy: 0.5938 - val_auc: 0.6082 - 116s/epoch - 7s/step\n",
            "Epoch 101/150\n",
            "16/16 - 116s - loss: 0.5788 - accuracy: 0.7267 - auc: 0.7589 - val_loss: 0.6803 - val_accuracy: 0.6406 - val_auc: 0.6448 - 116s/epoch - 7s/step\n",
            "Epoch 102/150\n",
            "16/16 - 116s - loss: 0.5642 - accuracy: 0.7433 - auc: 0.7738 - val_loss: 0.7179 - val_accuracy: 0.6094 - val_auc: 0.6360 - 116s/epoch - 7s/step\n",
            "Epoch 103/150\n",
            "16/16 - 116s - loss: 0.5744 - accuracy: 0.7371 - auc: 0.7589 - val_loss: 0.6642 - val_accuracy: 0.6562 - val_auc: 0.6562 - 116s/epoch - 7s/step\n",
            "Epoch 104/150\n",
            "16/16 - 116s - loss: 0.5776 - accuracy: 0.7340 - auc: 0.7468 - val_loss: 0.6747 - val_accuracy: 0.6406 - val_auc: 0.6616 - 116s/epoch - 7s/step\n",
            "Epoch 105/150\n",
            "16/16 - 116s - loss: 0.5637 - accuracy: 0.7371 - auc: 0.7766 - val_loss: 0.6609 - val_accuracy: 0.6562 - val_auc: 0.6699 - 116s/epoch - 7s/step\n",
            "Epoch 106/150\n",
            "16/16 - 116s - loss: 0.5776 - accuracy: 0.7267 - auc: 0.7589 - val_loss: 0.6601 - val_accuracy: 0.6719 - val_auc: 0.6599 - 116s/epoch - 7s/step\n",
            "Epoch 107/150\n",
            "16/16 - 116s - loss: 0.5873 - accuracy: 0.7184 - auc: 0.7492 - val_loss: 0.7047 - val_accuracy: 0.6094 - val_auc: 0.6497 - 116s/epoch - 7s/step\n",
            "Epoch 108/150\n",
            "16/16 - 116s - loss: 0.5821 - accuracy: 0.7215 - auc: 0.7527 - val_loss: 0.7102 - val_accuracy: 0.6250 - val_auc: 0.6121 - 116s/epoch - 7s/step\n",
            "Epoch 109/150\n",
            "16/16 - 116s - loss: 0.5731 - accuracy: 0.7329 - auc: 0.7647 - val_loss: 0.6522 - val_accuracy: 0.6562 - val_auc: 0.6946 - 116s/epoch - 7s/step\n",
            "Epoch 110/150\n",
            "16/16 - 117s - loss: 0.5794 - accuracy: 0.7288 - auc: 0.7546 - val_loss: 0.6694 - val_accuracy: 0.6562 - val_auc: 0.6780 - 117s/epoch - 7s/step\n",
            "Epoch 111/150\n",
            "16/16 - 116s - loss: 0.5978 - accuracy: 0.7081 - auc: 0.7409 - val_loss: 0.6240 - val_accuracy: 0.6875 - val_auc: 0.7358 - 116s/epoch - 7s/step\n",
            "Epoch 112/150\n",
            "16/16 - 116s - loss: 0.5917 - accuracy: 0.7143 - auc: 0.7425 - val_loss: 0.6588 - val_accuracy: 0.6406 - val_auc: 0.7004 - 116s/epoch - 7s/step\n",
            "Epoch 113/150\n",
            "16/16 - 116s - loss: 0.5807 - accuracy: 0.7257 - auc: 0.7550 - val_loss: 0.6688 - val_accuracy: 0.6406 - val_auc: 0.6672 - 116s/epoch - 7s/step\n",
            "Epoch 114/150\n",
            "16/16 - 117s - loss: 0.5781 - accuracy: 0.7288 - auc: 0.7517 - val_loss: 0.6720 - val_accuracy: 0.6250 - val_auc: 0.7056 - 117s/epoch - 7s/step\n",
            "Epoch 115/150\n",
            "16/16 - 116s - loss: 0.5757 - accuracy: 0.7267 - auc: 0.7576 - val_loss: 0.6740 - val_accuracy: 0.6406 - val_auc: 0.6604 - 116s/epoch - 7s/step\n",
            "Epoch 116/150\n",
            "16/16 - 116s - loss: 0.5734 - accuracy: 0.7308 - auc: 0.7573 - val_loss: 0.6240 - val_accuracy: 0.6875 - val_auc: 0.7361 - 116s/epoch - 7s/step\n",
            "Epoch 117/150\n",
            "16/16 - 115s - loss: 0.5832 - accuracy: 0.7195 - auc: 0.7514 - val_loss: 0.6724 - val_accuracy: 0.6562 - val_auc: 0.6709 - 115s/epoch - 7s/step\n",
            "Epoch 118/150\n",
            "16/16 - 115s - loss: 0.5685 - accuracy: 0.7371 - auc: 0.7696 - val_loss: 0.7143 - val_accuracy: 0.6094 - val_auc: 0.6260 - 115s/epoch - 7s/step\n",
            "Epoch 119/150\n",
            "16/16 - 116s - loss: 0.5775 - accuracy: 0.7288 - auc: 0.7542 - val_loss: 0.6807 - val_accuracy: 0.6562 - val_auc: 0.6384 - 116s/epoch - 7s/step\n",
            "Epoch 120/150\n",
            "16/16 - 116s - loss: 0.5752 - accuracy: 0.7308 - auc: 0.7560 - val_loss: 0.6957 - val_accuracy: 0.6250 - val_auc: 0.6438 - 116s/epoch - 7s/step\n",
            "Epoch 121/150\n",
            "16/16 - 115s - loss: 0.5643 - accuracy: 0.7464 - auc: 0.7671 - val_loss: 0.6665 - val_accuracy: 0.6719 - val_auc: 0.6475 - 115s/epoch - 7s/step\n",
            "Epoch 122/150\n",
            "16/16 - 116s - loss: 0.5823 - accuracy: 0.7277 - auc: 0.7503 - val_loss: 0.6825 - val_accuracy: 0.6250 - val_auc: 0.6729 - 116s/epoch - 7s/step\n",
            "Epoch 123/150\n",
            "16/16 - 115s - loss: 0.5774 - accuracy: 0.7267 - auc: 0.7539 - val_loss: 0.6844 - val_accuracy: 0.6406 - val_auc: 0.6499 - 115s/epoch - 7s/step\n",
            "Epoch 124/150\n",
            "16/16 - 115s - loss: 0.5629 - accuracy: 0.7453 - auc: 0.7712 - val_loss: 0.6924 - val_accuracy: 0.6406 - val_auc: 0.6521 - 115s/epoch - 7s/step\n",
            "Epoch 125/150\n",
            "16/16 - 116s - loss: 0.5578 - accuracy: 0.7495 - auc: 0.7808 - val_loss: 0.6923 - val_accuracy: 0.6406 - val_auc: 0.6453 - 116s/epoch - 7s/step\n",
            "Epoch 126/150\n",
            "16/16 - 116s - loss: 0.5916 - accuracy: 0.7153 - auc: 0.7378 - val_loss: 0.6952 - val_accuracy: 0.6250 - val_auc: 0.6470 - 116s/epoch - 7s/step\n",
            "Epoch 127/150\n",
            "16/16 - 116s - loss: 0.5819 - accuracy: 0.7205 - auc: 0.7511 - val_loss: 0.6288 - val_accuracy: 0.6875 - val_auc: 0.7412 - 116s/epoch - 7s/step\n",
            "Epoch 128/150\n",
            "16/16 - 116s - loss: 0.5650 - accuracy: 0.7391 - auc: 0.7649 - val_loss: 0.6616 - val_accuracy: 0.6562 - val_auc: 0.6750 - 116s/epoch - 7s/step\n",
            "Epoch 129/150\n",
            "16/16 - 116s - loss: 0.5718 - accuracy: 0.7350 - auc: 0.7687 - val_loss: 0.6652 - val_accuracy: 0.6562 - val_auc: 0.6614 - 116s/epoch - 7s/step\n",
            "Epoch 130/150\n",
            "16/16 - 116s - loss: 0.5738 - accuracy: 0.7298 - auc: 0.7611 - val_loss: 0.6153 - val_accuracy: 0.7031 - val_auc: 0.7502 - 116s/epoch - 7s/step\n",
            "Epoch 131/150\n",
            "16/16 - 116s - loss: 0.5866 - accuracy: 0.7236 - auc: 0.7467 - val_loss: 0.7250 - val_accuracy: 0.6094 - val_auc: 0.6145 - 116s/epoch - 7s/step\n",
            "Epoch 132/150\n",
            "16/16 - 116s - loss: 0.5542 - accuracy: 0.7484 - auc: 0.7824 - val_loss: 0.7095 - val_accuracy: 0.6250 - val_auc: 0.6348 - 116s/epoch - 7s/step\n",
            "Epoch 133/150\n",
            "16/16 - 117s - loss: 0.5831 - accuracy: 0.7195 - auc: 0.7550 - val_loss: 0.6825 - val_accuracy: 0.6406 - val_auc: 0.6792 - 117s/epoch - 7s/step\n",
            "Epoch 134/150\n",
            "16/16 - 116s - loss: 0.5657 - accuracy: 0.7391 - auc: 0.7687 - val_loss: 0.5960 - val_accuracy: 0.7188 - val_auc: 0.7427 - 116s/epoch - 7s/step\n",
            "Epoch 135/150\n",
            "16/16 - 116s - loss: 0.5765 - accuracy: 0.7298 - auc: 0.7573 - val_loss: 0.7079 - val_accuracy: 0.6250 - val_auc: 0.6401 - 116s/epoch - 7s/step\n",
            "Epoch 136/150\n",
            "16/16 - 116s - loss: 0.5570 - accuracy: 0.7474 - auc: 0.7751 - val_loss: 0.6964 - val_accuracy: 0.6406 - val_auc: 0.6335 - 116s/epoch - 7s/step\n",
            "Epoch 137/150\n",
            "16/16 - 115s - loss: 0.5730 - accuracy: 0.7340 - auc: 0.7578 - val_loss: 0.6838 - val_accuracy: 0.6406 - val_auc: 0.6907 - 115s/epoch - 7s/step\n",
            "Epoch 138/150\n",
            "16/16 - 115s - loss: 0.5735 - accuracy: 0.7402 - auc: 0.7593 - val_loss: 0.6095 - val_accuracy: 0.7188 - val_auc: 0.7322 - 115s/epoch - 7s/step\n",
            "Epoch 139/150\n",
            "16/16 - 115s - loss: 0.5659 - accuracy: 0.7381 - auc: 0.7747 - val_loss: 0.6817 - val_accuracy: 0.6406 - val_auc: 0.6641 - 115s/epoch - 7s/step\n",
            "Epoch 140/150\n",
            "16/16 - 115s - loss: 0.5587 - accuracy: 0.7453 - auc: 0.7778 - val_loss: 0.6880 - val_accuracy: 0.6562 - val_auc: 0.6406 - 115s/epoch - 7s/step\n",
            "Epoch 141/150\n",
            "16/16 - 115s - loss: 0.5796 - accuracy: 0.7267 - auc: 0.7610 - val_loss: 0.6882 - val_accuracy: 0.6406 - val_auc: 0.6553 - 115s/epoch - 7s/step\n",
            "Epoch 142/150\n",
            "16/16 - 115s - loss: 0.5575 - accuracy: 0.7484 - auc: 0.7778 - val_loss: 0.7115 - val_accuracy: 0.6094 - val_auc: 0.6248 - 115s/epoch - 7s/step\n",
            "Epoch 143/150\n",
            "16/16 - 116s - loss: 0.5673 - accuracy: 0.7381 - auc: 0.7696 - val_loss: 0.6766 - val_accuracy: 0.6562 - val_auc: 0.7029 - 116s/epoch - 7s/step\n",
            "Epoch 144/150\n",
            "16/16 - 116s - loss: 0.5741 - accuracy: 0.7298 - auc: 0.7559 - val_loss: 0.6893 - val_accuracy: 0.6406 - val_auc: 0.6492 - 116s/epoch - 7s/step\n",
            "Epoch 145/150\n",
            "16/16 - 117s - loss: 0.5776 - accuracy: 0.7226 - auc: 0.7606 - val_loss: 0.6196 - val_accuracy: 0.6719 - val_auc: 0.7576 - 117s/epoch - 7s/step\n",
            "Epoch 146/150\n",
            "16/16 - 116s - loss: 0.5568 - accuracy: 0.7464 - auc: 0.7856 - val_loss: 0.6458 - val_accuracy: 0.6875 - val_auc: 0.6694 - 116s/epoch - 7s/step\n",
            "Epoch 147/150\n",
            "16/16 - 116s - loss: 0.5785 - accuracy: 0.7298 - auc: 0.7455 - val_loss: 0.7537 - val_accuracy: 0.5781 - val_auc: 0.6128 - 116s/epoch - 7s/step\n",
            "Epoch 148/150\n",
            "16/16 - 116s - loss: 0.5744 - accuracy: 0.7308 - auc: 0.7601 - val_loss: 0.6769 - val_accuracy: 0.6406 - val_auc: 0.6602 - 116s/epoch - 7s/step\n",
            "Epoch 149/150\n",
            "16/16 - 116s - loss: 0.5837 - accuracy: 0.7153 - auc: 0.7599 - val_loss: 0.6546 - val_accuracy: 0.6719 - val_auc: 0.6831 - 116s/epoch - 7s/step\n",
            "Epoch 150/150\n",
            "16/16 - 116s - loss: 0.5755 - accuracy: 0.7277 - auc: 0.7608 - val_loss: 0.6715 - val_accuracy: 0.6562 - val_auc: 0.6458 - 116s/epoch - 7s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 242/242 [02:05<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6647\n",
            "Recall: 0.9187\n",
            "Threshold: 0.3019\n",
            "F1 Score: 0.7713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1168/1168 [13:31<00:00,  1.44it/s]\n"
          ]
        }
      ],
      "source": [
        "Model_Name='Pretrained plus 4th layer Model Saved(balanced Dataset)'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 5th layer Model Saved(balanced Dataset)'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history5 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history5.history, timestamp,Model_Name)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./PretrainedPlus5_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUHBUFDh5dG_"
      },
      "outputs": [],
      "source": [
        "Model_Name='Pretrained plus 5th layer Model Saved(balanced Dataset)'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 6th layer Model Saved(balanced Dataset)'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history6 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history6.history, timestamp,Model_Name)\n",
        "plt.savefig(Model_Name+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./PretrainedPlus6_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT_ERoe45dG_"
      },
      "outputs": [],
      "source": [
        "Model_Name='Pretrained plus 6th layer Model Saved(balanced Dataset)'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 7th layer Model Saved(balanced Dataset)'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history7 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history7.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./PretrainedPlus7_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJnHnD-N5dHA"
      },
      "outputs": [],
      "source": [
        "Model_Name='Pretrained plus 7th layer Model Saved(balanced Dataset)'\n",
        "trained_model = keras.models.load_model(Model_Name)\n",
        "Model_Name='Pretrained plus 8th layer Model Saved(balanced Dataset)'\n",
        "model = create_model(trained_model)\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='auc', mode='auto', patience=150)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/'+ timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='auc',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history8 = model.fit(\n",
        "        train_gen, epochs=Epochs_ResNet, verbose=VERBOSE_LEVEL,validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history8.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "\n",
        "#plt.savefig('VGG_40epochs Model_Loss.pdf',format='pdf') #saving the plot as a pdf file of name figure'''\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./Pretrained Model_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq8t77_o5dHA",
        "outputId": "2df2e222-4a97-40db-d587-048c9835f2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer 1 : input_1 is trainable: True\n",
            "layer 2 : conv1_pad is trainable: True\n",
            "layer 3 : conv1_conv is trainable: True\n",
            "layer 4 : conv1_bn is trainable: True\n",
            "layer 5 : conv1_relu is trainable: True\n",
            "layer 6 : pool1_pad is trainable: True\n",
            "layer 7 : pool1_pool is trainable: True\n",
            "layer 8 : conv2_block1_1_conv is trainable: True\n",
            "layer 9 : conv2_block1_1_bn is trainable: True\n",
            "layer 10 : conv2_block1_1_relu is trainable: True\n",
            "create model\n",
            "create model\n",
            "layer 1 : input_1 is trainable: True\n",
            "layer 2 : conv1_pad is trainable: True\n",
            "layer 3 : conv1_conv is trainable: True\n",
            "layer 4 : conv1_bn is trainable: True\n",
            "layer 5 : conv1_relu is trainable: True\n",
            "layer 6 : pool1_pad is trainable: True\n",
            "layer 7 : pool1_pool is trainable: True\n",
            "layer 8 : conv2_block1_1_conv is trainable: True\n",
            "layer 9 : conv2_block1_1_bn is trainable: True\n",
            "layer 10 : conv2_block1_1_relu is trainable: True\n",
            "rows in train_df 966\n",
            "rows in val_df 242\n",
            "Found 966 non-validated image filenames.\n",
            "Found 242 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "16/16 - 126s - loss: 1.2577 - accuracy: 0.5580 - auc: 0.5770 - val_loss: 0.6928 - val_accuracy: 0.5625 - val_auc: 0.5597 - 126s/epoch - 8s/step\n",
            "Epoch 2/150\n",
            "16/16 - 116s - loss: 0.9912 - accuracy: 0.6542 - auc: 0.7094 - val_loss: 0.7113 - val_accuracy: 0.4375 - val_auc: 0.4565 - 116s/epoch - 7s/step\n",
            "Epoch 3/150\n",
            "16/16 - 115s - loss: 0.9097 - accuracy: 0.7060 - auc: 0.7622 - val_loss: 0.7893 - val_accuracy: 0.4219 - val_auc: 0.4071 - 115s/epoch - 7s/step\n",
            "Epoch 4/150\n",
            "16/16 - 114s - loss: 0.8573 - accuracy: 0.7174 - auc: 0.7893 - val_loss: 0.8310 - val_accuracy: 0.5312 - val_auc: 0.4883 - 114s/epoch - 7s/step\n",
            "Epoch 5/150\n",
            "16/16 - 114s - loss: 0.8518 - accuracy: 0.7174 - auc: 0.7938 - val_loss: 0.8257 - val_accuracy: 0.5312 - val_auc: 0.4885 - 114s/epoch - 7s/step\n",
            "Epoch 6/150\n",
            "16/16 - 114s - loss: 0.8281 - accuracy: 0.7308 - auc: 0.8049 - val_loss: 0.8729 - val_accuracy: 0.4531 - val_auc: 0.4045 - 114s/epoch - 7s/step\n",
            "Epoch 7/150\n",
            "16/16 - 114s - loss: 0.7969 - accuracy: 0.7516 - auc: 0.8210 - val_loss: 0.9369 - val_accuracy: 0.4531 - val_auc: 0.3953 - 114s/epoch - 7s/step\n",
            "Epoch 8/150\n",
            "16/16 - 114s - loss: 0.7797 - accuracy: 0.7453 - auc: 0.8180 - val_loss: 1.0290 - val_accuracy: 0.4531 - val_auc: 0.3652 - 114s/epoch - 7s/step\n",
            "Epoch 9/150\n",
            "16/16 - 114s - loss: 0.7784 - accuracy: 0.7422 - auc: 0.8231 - val_loss: 1.3483 - val_accuracy: 0.4531 - val_auc: 0.4019 - 114s/epoch - 7s/step\n",
            "Epoch 10/150\n",
            "16/16 - 115s - loss: 0.7752 - accuracy: 0.7505 - auc: 0.8312 - val_loss: 1.9120 - val_accuracy: 0.4531 - val_auc: 0.4531 - 115s/epoch - 7s/step\n",
            "Epoch 11/150\n",
            "16/16 - 114s - loss: 0.6834 - accuracy: 0.7867 - auc: 0.8596 - val_loss: 2.4560 - val_accuracy: 0.4531 - val_auc: 0.4531 - 114s/epoch - 7s/step\n",
            "Epoch 12/150\n",
            "16/16 - 114s - loss: 0.6962 - accuracy: 0.7650 - auc: 0.8413 - val_loss: 2.4966 - val_accuracy: 0.4531 - val_auc: 0.4531 - 114s/epoch - 7s/step\n",
            "Epoch 13/150\n",
            "16/16 - 114s - loss: 0.6562 - accuracy: 0.7847 - auc: 0.8625 - val_loss: 2.7926 - val_accuracy: 0.4531 - val_auc: 0.4531 - 114s/epoch - 7s/step\n",
            "Epoch 14/150\n",
            "16/16 - 114s - loss: 0.6520 - accuracy: 0.8012 - auc: 0.8681 - val_loss: 1.8069 - val_accuracy: 0.4531 - val_auc: 0.4519 - 114s/epoch - 7s/step\n",
            "Epoch 15/150\n",
            "16/16 - 115s - loss: 0.6316 - accuracy: 0.7847 - auc: 0.8724 - val_loss: 1.6864 - val_accuracy: 0.4531 - val_auc: 0.4255 - 115s/epoch - 7s/step\n",
            "Epoch 16/150\n",
            "16/16 - 115s - loss: 0.6321 - accuracy: 0.7909 - auc: 0.8631 - val_loss: 1.7774 - val_accuracy: 0.4531 - val_auc: 0.4402 - 115s/epoch - 7s/step\n",
            "Epoch 17/150\n",
            "16/16 - 116s - loss: 0.6134 - accuracy: 0.7909 - auc: 0.8738 - val_loss: 1.7902 - val_accuracy: 0.4531 - val_auc: 0.4336 - 116s/epoch - 7s/step\n",
            "Epoch 18/150\n",
            "16/16 - 115s - loss: 0.6034 - accuracy: 0.8095 - auc: 0.8792 - val_loss: 1.7091 - val_accuracy: 0.4531 - val_auc: 0.4275 - 115s/epoch - 7s/step\n",
            "Epoch 19/150\n",
            "16/16 - 114s - loss: 0.6210 - accuracy: 0.8002 - auc: 0.8767 - val_loss: 1.8436 - val_accuracy: 0.4531 - val_auc: 0.4473 - 114s/epoch - 7s/step\n",
            "Epoch 20/150\n",
            "16/16 - 115s - loss: 0.5634 - accuracy: 0.8126 - auc: 0.8906 - val_loss: 1.8418 - val_accuracy: 0.4531 - val_auc: 0.4524 - 115s/epoch - 7s/step\n",
            "Epoch 21/150\n",
            "16/16 - 114s - loss: 0.5848 - accuracy: 0.8043 - auc: 0.8829 - val_loss: 1.9659 - val_accuracy: 0.4531 - val_auc: 0.4570 - 114s/epoch - 7s/step\n",
            "Epoch 22/150\n",
            "16/16 - 115s - loss: 0.5325 - accuracy: 0.8147 - auc: 0.8999 - val_loss: 2.8752 - val_accuracy: 0.4531 - val_auc: 0.4602 - 115s/epoch - 7s/step\n",
            "Epoch 23/150\n",
            "16/16 - 114s - loss: 0.5623 - accuracy: 0.7992 - auc: 0.8811 - val_loss: 2.5250 - val_accuracy: 0.4531 - val_auc: 0.4673 - 114s/epoch - 7s/step\n",
            "Epoch 24/150\n",
            "16/16 - 114s - loss: 0.4734 - accuracy: 0.8364 - auc: 0.9173 - val_loss: 3.0274 - val_accuracy: 0.4531 - val_auc: 0.4602 - 114s/epoch - 7s/step\n",
            "Epoch 25/150\n",
            "16/16 - 114s - loss: 0.4925 - accuracy: 0.8416 - auc: 0.9113 - val_loss: 2.9866 - val_accuracy: 0.4531 - val_auc: 0.4673 - 114s/epoch - 7s/step\n",
            "Epoch 26/150\n",
            "16/16 - 114s - loss: 0.4885 - accuracy: 0.8520 - auc: 0.9100 - val_loss: 2.2870 - val_accuracy: 0.4531 - val_auc: 0.4573 - 114s/epoch - 7s/step\n",
            "Epoch 27/150\n",
            "16/16 - 114s - loss: 0.4794 - accuracy: 0.8333 - auc: 0.9142 - val_loss: 1.2693 - val_accuracy: 0.4531 - val_auc: 0.4688 - 114s/epoch - 7s/step\n",
            "Epoch 28/150\n",
            "16/16 - 114s - loss: 0.4616 - accuracy: 0.8427 - auc: 0.9205 - val_loss: 1.3185 - val_accuracy: 0.4688 - val_auc: 0.4785 - 114s/epoch - 7s/step\n",
            "Epoch 29/150\n",
            "16/16 - 114s - loss: 0.4429 - accuracy: 0.8561 - auc: 0.9255 - val_loss: 1.3439 - val_accuracy: 0.4688 - val_auc: 0.4707 - 114s/epoch - 7s/step\n",
            "Epoch 30/150\n",
            "16/16 - 114s - loss: 0.4494 - accuracy: 0.8416 - auc: 0.9237 - val_loss: 1.5489 - val_accuracy: 0.4531 - val_auc: 0.4270 - 114s/epoch - 7s/step\n",
            "Epoch 31/150\n",
            "16/16 - 114s - loss: 0.4299 - accuracy: 0.8602 - auc: 0.9337 - val_loss: 1.7531 - val_accuracy: 0.4688 - val_auc: 0.4475 - 114s/epoch - 7s/step\n",
            "Epoch 32/150\n",
            "16/16 - 115s - loss: 0.3897 - accuracy: 0.8602 - auc: 0.9361 - val_loss: 1.8353 - val_accuracy: 0.4531 - val_auc: 0.4541 - 115s/epoch - 7s/step\n",
            "Epoch 33/150\n",
            "16/16 - 114s - loss: 0.3757 - accuracy: 0.8675 - auc: 0.9411 - val_loss: 2.0589 - val_accuracy: 0.4531 - val_auc: 0.4653 - 114s/epoch - 7s/step\n",
            "Epoch 34/150\n",
            "16/16 - 114s - loss: 0.3935 - accuracy: 0.8675 - auc: 0.9404 - val_loss: 1.9003 - val_accuracy: 0.4375 - val_auc: 0.4822 - 114s/epoch - 7s/step\n",
            "Epoch 35/150\n",
            "16/16 - 114s - loss: 0.3581 - accuracy: 0.8830 - auc: 0.9481 - val_loss: 1.9719 - val_accuracy: 0.4688 - val_auc: 0.4705 - 114s/epoch - 7s/step\n",
            "Epoch 36/150\n",
            "16/16 - 114s - loss: 0.3757 - accuracy: 0.8768 - auc: 0.9422 - val_loss: 2.2929 - val_accuracy: 0.4531 - val_auc: 0.4761 - 114s/epoch - 7s/step\n",
            "Epoch 37/150\n",
            "16/16 - 114s - loss: 0.3687 - accuracy: 0.8654 - auc: 0.9417 - val_loss: 2.4550 - val_accuracy: 0.4531 - val_auc: 0.4790 - 114s/epoch - 7s/step\n",
            "Epoch 38/150\n",
            "16/16 - 114s - loss: 0.3285 - accuracy: 0.8892 - auc: 0.9562 - val_loss: 1.4892 - val_accuracy: 0.4844 - val_auc: 0.5239 - 114s/epoch - 7s/step\n",
            "Epoch 39/150\n",
            "16/16 - 114s - loss: 0.3318 - accuracy: 0.8934 - auc: 0.9528 - val_loss: 1.5231 - val_accuracy: 0.4844 - val_auc: 0.5188 - 114s/epoch - 7s/step\n",
            "Epoch 40/150\n",
            "16/16 - 114s - loss: 0.3455 - accuracy: 0.8841 - auc: 0.9487 - val_loss: 1.2687 - val_accuracy: 0.5469 - val_auc: 0.5247 - 114s/epoch - 7s/step\n",
            "Epoch 41/150\n",
            "16/16 - 115s - loss: 0.3373 - accuracy: 0.8830 - auc: 0.9467 - val_loss: 1.6533 - val_accuracy: 0.5156 - val_auc: 0.4963 - 115s/epoch - 7s/step\n",
            "Epoch 42/150\n",
            "16/16 - 114s - loss: 0.3198 - accuracy: 0.8975 - auc: 0.9534 - val_loss: 1.7446 - val_accuracy: 0.5156 - val_auc: 0.4807 - 114s/epoch - 7s/step\n",
            "Epoch 43/150\n",
            "16/16 - 114s - loss: 0.3197 - accuracy: 0.8944 - auc: 0.9495 - val_loss: 1.4177 - val_accuracy: 0.5156 - val_auc: 0.5195 - 114s/epoch - 7s/step\n",
            "Epoch 44/150\n",
            "16/16 - 114s - loss: 0.3215 - accuracy: 0.8872 - auc: 0.9586 - val_loss: 1.7112 - val_accuracy: 0.5156 - val_auc: 0.4814 - 114s/epoch - 7s/step\n",
            "Epoch 45/150\n",
            "16/16 - 114s - loss: 0.2758 - accuracy: 0.9099 - auc: 0.9677 - val_loss: 1.8537 - val_accuracy: 0.4844 - val_auc: 0.4875 - 114s/epoch - 7s/step\n",
            "Epoch 46/150\n",
            "16/16 - 114s - loss: 0.2762 - accuracy: 0.9079 - auc: 0.9661 - val_loss: 1.9843 - val_accuracy: 0.4844 - val_auc: 0.5215 - 114s/epoch - 7s/step\n",
            "Epoch 47/150\n",
            "16/16 - 114s - loss: 0.2936 - accuracy: 0.8965 - auc: 0.9569 - val_loss: 1.5499 - val_accuracy: 0.5000 - val_auc: 0.5258 - 114s/epoch - 7s/step\n",
            "Epoch 48/150\n",
            "16/16 - 114s - loss: 0.2973 - accuracy: 0.8996 - auc: 0.9547 - val_loss: 1.0522 - val_accuracy: 0.5781 - val_auc: 0.5996 - 114s/epoch - 7s/step\n",
            "Epoch 49/150\n",
            "16/16 - 114s - loss: 0.2601 - accuracy: 0.9130 - auc: 0.9686 - val_loss: 1.0077 - val_accuracy: 0.5938 - val_auc: 0.6276 - 114s/epoch - 7s/step\n",
            "Epoch 50/150\n",
            "16/16 - 114s - loss: 0.2287 - accuracy: 0.9234 - auc: 0.9758 - val_loss: 1.2574 - val_accuracy: 0.5625 - val_auc: 0.6096 - 114s/epoch - 7s/step\n",
            "Epoch 51/150\n",
            "16/16 - 115s - loss: 0.2596 - accuracy: 0.9058 - auc: 0.9692 - val_loss: 1.5477 - val_accuracy: 0.5312 - val_auc: 0.6160 - 115s/epoch - 7s/step\n",
            "Epoch 52/150\n",
            "16/16 - 115s - loss: 0.2296 - accuracy: 0.9172 - auc: 0.9745 - val_loss: 1.1273 - val_accuracy: 0.6250 - val_auc: 0.6670 - 115s/epoch - 7s/step\n",
            "Epoch 53/150\n",
            "16/16 - 114s - loss: 0.2373 - accuracy: 0.9306 - auc: 0.9716 - val_loss: 1.1682 - val_accuracy: 0.6250 - val_auc: 0.6824 - 114s/epoch - 7s/step\n",
            "Epoch 54/150\n",
            "16/16 - 115s - loss: 0.2717 - accuracy: 0.9099 - auc: 0.9695 - val_loss: 1.1196 - val_accuracy: 0.6250 - val_auc: 0.7056 - 115s/epoch - 7s/step\n",
            "Epoch 55/150\n",
            "16/16 - 115s - loss: 0.2329 - accuracy: 0.9224 - auc: 0.9770 - val_loss: 1.1692 - val_accuracy: 0.6406 - val_auc: 0.7078 - 115s/epoch - 7s/step\n",
            "Epoch 56/150\n",
            "16/16 - 115s - loss: 0.2406 - accuracy: 0.9161 - auc: 0.9713 - val_loss: 1.2981 - val_accuracy: 0.6719 - val_auc: 0.6814 - 115s/epoch - 7s/step\n",
            "Epoch 57/150\n",
            "16/16 - 115s - loss: 0.2373 - accuracy: 0.9337 - auc: 0.9727 - val_loss: 1.4599 - val_accuracy: 0.6250 - val_auc: 0.6631 - 115s/epoch - 7s/step\n",
            "Epoch 58/150\n",
            "16/16 - 115s - loss: 0.2394 - accuracy: 0.9224 - auc: 0.9736 - val_loss: 1.0621 - val_accuracy: 0.7188 - val_auc: 0.7488 - 115s/epoch - 7s/step\n",
            "Epoch 59/150\n",
            "16/16 - 115s - loss: 0.2231 - accuracy: 0.9234 - auc: 0.9723 - val_loss: 0.9959 - val_accuracy: 0.7031 - val_auc: 0.7903 - 115s/epoch - 7s/step\n",
            "Epoch 60/150\n",
            "16/16 - 114s - loss: 0.1876 - accuracy: 0.9482 - auc: 0.9812 - val_loss: 0.9697 - val_accuracy: 0.7031 - val_auc: 0.8013 - 114s/epoch - 7s/step\n",
            "Epoch 61/150\n",
            "16/16 - 115s - loss: 0.1782 - accuracy: 0.9431 - auc: 0.9823 - val_loss: 0.9171 - val_accuracy: 0.7500 - val_auc: 0.8110 - 115s/epoch - 7s/step\n",
            "Epoch 62/150\n",
            "16/16 - 115s - loss: 0.2025 - accuracy: 0.9255 - auc: 0.9807 - val_loss: 0.9981 - val_accuracy: 0.7188 - val_auc: 0.7908 - 115s/epoch - 7s/step\n",
            "Epoch 63/150\n",
            "16/16 - 115s - loss: 0.1810 - accuracy: 0.9400 - auc: 0.9841 - val_loss: 1.1727 - val_accuracy: 0.7344 - val_auc: 0.7688 - 115s/epoch - 7s/step\n",
            "Epoch 64/150\n",
            "16/16 - 115s - loss: 0.1457 - accuracy: 0.9586 - auc: 0.9885 - val_loss: 1.1012 - val_accuracy: 0.7188 - val_auc: 0.7786 - 115s/epoch - 7s/step\n",
            "Epoch 65/150\n",
            "16/16 - 115s - loss: 0.1768 - accuracy: 0.9389 - auc: 0.9817 - val_loss: 1.1061 - val_accuracy: 0.6875 - val_auc: 0.7781 - 115s/epoch - 7s/step\n",
            "Epoch 66/150\n",
            "16/16 - 115s - loss: 0.1834 - accuracy: 0.9410 - auc: 0.9806 - val_loss: 1.1553 - val_accuracy: 0.6875 - val_auc: 0.7759 - 115s/epoch - 7s/step\n",
            "Epoch 67/150\n",
            "16/16 - 115s - loss: 0.1643 - accuracy: 0.9462 - auc: 0.9845 - val_loss: 1.1382 - val_accuracy: 0.7344 - val_auc: 0.7947 - 115s/epoch - 7s/step\n",
            "Epoch 68/150\n",
            "16/16 - 115s - loss: 0.1834 - accuracy: 0.9431 - auc: 0.9799 - val_loss: 1.2266 - val_accuracy: 0.7344 - val_auc: 0.7722 - 115s/epoch - 7s/step\n",
            "Epoch 69/150\n",
            "16/16 - 115s - loss: 0.1805 - accuracy: 0.9431 - auc: 0.9847 - val_loss: 1.1856 - val_accuracy: 0.7344 - val_auc: 0.7966 - 115s/epoch - 7s/step\n",
            "Epoch 70/150\n",
            "16/16 - 114s - loss: 0.1466 - accuracy: 0.9576 - auc: 0.9887 - val_loss: 1.1256 - val_accuracy: 0.7656 - val_auc: 0.7966 - 114s/epoch - 7s/step\n",
            "Epoch 71/150\n",
            "16/16 - 115s - loss: 0.1616 - accuracy: 0.9420 - auc: 0.9849 - val_loss: 0.9240 - val_accuracy: 0.7500 - val_auc: 0.8220 - 115s/epoch - 7s/step\n",
            "Epoch 72/150\n",
            "16/16 - 115s - loss: 0.1719 - accuracy: 0.9462 - auc: 0.9802 - val_loss: 0.8680 - val_accuracy: 0.7344 - val_auc: 0.8120 - 115s/epoch - 7s/step\n",
            "Epoch 73/150\n",
            "16/16 - 115s - loss: 0.1431 - accuracy: 0.9513 - auc: 0.9880 - val_loss: 0.8264 - val_accuracy: 0.8438 - val_auc: 0.8420 - 115s/epoch - 7s/step\n",
            "Epoch 74/150\n",
            "16/16 - 115s - loss: 0.1634 - accuracy: 0.9431 - auc: 0.9839 - val_loss: 0.7357 - val_accuracy: 0.8281 - val_auc: 0.8438 - 115s/epoch - 7s/step\n",
            "Epoch 75/150\n",
            "16/16 - 115s - loss: 0.1507 - accuracy: 0.9565 - auc: 0.9835 - val_loss: 0.5564 - val_accuracy: 0.8438 - val_auc: 0.8713 - 115s/epoch - 7s/step\n",
            "Epoch 76/150\n",
            "16/16 - 115s - loss: 0.1615 - accuracy: 0.9493 - auc: 0.9824 - val_loss: 0.6326 - val_accuracy: 0.8594 - val_auc: 0.8445 - 115s/epoch - 7s/step\n",
            "Epoch 77/150\n",
            "16/16 - 115s - loss: 0.1628 - accuracy: 0.9441 - auc: 0.9867 - val_loss: 0.6787 - val_accuracy: 0.8125 - val_auc: 0.8594 - 115s/epoch - 7s/step\n",
            "Epoch 78/150\n",
            "16/16 - 115s - loss: 0.1163 - accuracy: 0.9648 - auc: 0.9901 - val_loss: 0.7236 - val_accuracy: 0.7969 - val_auc: 0.8596 - 115s/epoch - 7s/step\n",
            "Epoch 79/150\n",
            "16/16 - 115s - loss: 0.1499 - accuracy: 0.9513 - auc: 0.9858 - val_loss: 0.7261 - val_accuracy: 0.7656 - val_auc: 0.8245 - 115s/epoch - 7s/step\n",
            "Epoch 80/150\n",
            "16/16 - 115s - loss: 0.1053 - accuracy: 0.9731 - auc: 0.9929 - val_loss: 0.8228 - val_accuracy: 0.8125 - val_auc: 0.8169 - 115s/epoch - 7s/step\n",
            "Epoch 81/150\n",
            "16/16 - 115s - loss: 0.1366 - accuracy: 0.9638 - auc: 0.9880 - val_loss: 0.8566 - val_accuracy: 0.7969 - val_auc: 0.8235 - 115s/epoch - 7s/step\n",
            "Epoch 82/150\n",
            "16/16 - 115s - loss: 0.1381 - accuracy: 0.9565 - auc: 0.9882 - val_loss: 0.8728 - val_accuracy: 0.7500 - val_auc: 0.8198 - 115s/epoch - 7s/step\n",
            "Epoch 83/150\n",
            "16/16 - 115s - loss: 0.1071 - accuracy: 0.9669 - auc: 0.9931 - val_loss: 0.8630 - val_accuracy: 0.7812 - val_auc: 0.8286 - 115s/epoch - 7s/step\n",
            "Epoch 84/150\n",
            "16/16 - 115s - loss: 0.1304 - accuracy: 0.9648 - auc: 0.9882 - val_loss: 1.1295 - val_accuracy: 0.7812 - val_auc: 0.7883 - 115s/epoch - 7s/step\n",
            "Epoch 85/150\n",
            "16/16 - 115s - loss: 0.1038 - accuracy: 0.9689 - auc: 0.9914 - val_loss: 1.0390 - val_accuracy: 0.7500 - val_auc: 0.7969 - 115s/epoch - 7s/step\n",
            "Epoch 86/150\n",
            "16/16 - 115s - loss: 0.0773 - accuracy: 0.9752 - auc: 0.9973 - val_loss: 1.0848 - val_accuracy: 0.7188 - val_auc: 0.8013 - 115s/epoch - 7s/step\n",
            "Epoch 87/150\n",
            "16/16 - 115s - loss: 0.0737 - accuracy: 0.9772 - auc: 0.9958 - val_loss: 1.0620 - val_accuracy: 0.7188 - val_auc: 0.7898 - 115s/epoch - 7s/step\n",
            "Epoch 88/150\n",
            "16/16 - 114s - loss: 0.0747 - accuracy: 0.9772 - auc: 0.9955 - val_loss: 1.0875 - val_accuracy: 0.7344 - val_auc: 0.7834 - 114s/epoch - 7s/step\n",
            "Epoch 89/150\n",
            "16/16 - 114s - loss: 0.0742 - accuracy: 0.9741 - auc: 0.9964 - val_loss: 1.0887 - val_accuracy: 0.7812 - val_auc: 0.7932 - 114s/epoch - 7s/step\n",
            "Epoch 90/150\n",
            "16/16 - 115s - loss: 0.0934 - accuracy: 0.9720 - auc: 0.9936 - val_loss: 1.3064 - val_accuracy: 0.7344 - val_auc: 0.7874 - 115s/epoch - 7s/step\n",
            "Epoch 91/150\n",
            "16/16 - 115s - loss: 0.0964 - accuracy: 0.9752 - auc: 0.9951 - val_loss: 1.3203 - val_accuracy: 0.7969 - val_auc: 0.8149 - 115s/epoch - 7s/step\n",
            "Epoch 92/150\n",
            "16/16 - 115s - loss: 0.0751 - accuracy: 0.9752 - auc: 0.9955 - val_loss: 1.1042 - val_accuracy: 0.7500 - val_auc: 0.8140 - 115s/epoch - 7s/step\n",
            "Epoch 93/150\n",
            "16/16 - 114s - loss: 0.1101 - accuracy: 0.9700 - auc: 0.9896 - val_loss: 0.8227 - val_accuracy: 0.7656 - val_auc: 0.8508 - 114s/epoch - 7s/step\n",
            "Epoch 94/150\n",
            "16/16 - 115s - loss: 0.0932 - accuracy: 0.9772 - auc: 0.9933 - val_loss: 0.8562 - val_accuracy: 0.7656 - val_auc: 0.8433 - 115s/epoch - 7s/step\n",
            "Epoch 95/150\n",
            "16/16 - 114s - loss: 0.1020 - accuracy: 0.9710 - auc: 0.9926 - val_loss: 0.7495 - val_accuracy: 0.7812 - val_auc: 0.8542 - 114s/epoch - 7s/step\n",
            "Epoch 96/150\n",
            "16/16 - 114s - loss: 0.1080 - accuracy: 0.9731 - auc: 0.9848 - val_loss: 1.0952 - val_accuracy: 0.7500 - val_auc: 0.7764 - 114s/epoch - 7s/step\n",
            "Epoch 97/150\n",
            "16/16 - 114s - loss: 0.1037 - accuracy: 0.9658 - auc: 0.9872 - val_loss: 0.9184 - val_accuracy: 0.7500 - val_auc: 0.8007 - 114s/epoch - 7s/step\n",
            "Epoch 98/150\n",
            "16/16 - 114s - loss: 0.0956 - accuracy: 0.9720 - auc: 0.9907 - val_loss: 1.0691 - val_accuracy: 0.7344 - val_auc: 0.7749 - 114s/epoch - 7s/step\n",
            "Epoch 99/150\n",
            "16/16 - 115s - loss: 0.0680 - accuracy: 0.9793 - auc: 0.9971 - val_loss: 1.0119 - val_accuracy: 0.7344 - val_auc: 0.8108 - 115s/epoch - 7s/step\n",
            "Epoch 100/150\n",
            "16/16 - 114s - loss: 0.0828 - accuracy: 0.9834 - auc: 0.9939 - val_loss: 1.0919 - val_accuracy: 0.7344 - val_auc: 0.7864 - 114s/epoch - 7s/step\n",
            "Epoch 101/150\n",
            "16/16 - 115s - loss: 0.0615 - accuracy: 0.9814 - auc: 0.9968 - val_loss: 1.1270 - val_accuracy: 0.7031 - val_auc: 0.7900 - 115s/epoch - 7s/step\n",
            "Epoch 102/150\n",
            "16/16 - 115s - loss: 0.0904 - accuracy: 0.9720 - auc: 0.9920 - val_loss: 1.1774 - val_accuracy: 0.7188 - val_auc: 0.7976 - 115s/epoch - 7s/step\n",
            "Epoch 103/150\n",
            "16/16 - 115s - loss: 0.0919 - accuracy: 0.9731 - auc: 0.9932 - val_loss: 1.3039 - val_accuracy: 0.7031 - val_auc: 0.7869 - 115s/epoch - 7s/step\n",
            "Epoch 104/150\n",
            "16/16 - 115s - loss: 0.1376 - accuracy: 0.9607 - auc: 0.9875 - val_loss: 2.0651 - val_accuracy: 0.6250 - val_auc: 0.6589 - 115s/epoch - 7s/step\n",
            "Epoch 105/150\n",
            "16/16 - 114s - loss: 0.1213 - accuracy: 0.9648 - auc: 0.9893 - val_loss: 1.6854 - val_accuracy: 0.7188 - val_auc: 0.7249 - 114s/epoch - 7s/step\n",
            "Epoch 106/150\n",
            "16/16 - 115s - loss: 0.0923 - accuracy: 0.9783 - auc: 0.9912 - val_loss: 1.6537 - val_accuracy: 0.6875 - val_auc: 0.7390 - 115s/epoch - 7s/step\n",
            "Epoch 107/150\n",
            "16/16 - 114s - loss: 0.1027 - accuracy: 0.9679 - auc: 0.9895 - val_loss: 1.7840 - val_accuracy: 0.7188 - val_auc: 0.7229 - 114s/epoch - 7s/step\n",
            "Epoch 108/150\n",
            "16/16 - 115s - loss: 0.0701 - accuracy: 0.9814 - auc: 0.9966 - val_loss: 1.6278 - val_accuracy: 0.7031 - val_auc: 0.7424 - 115s/epoch - 7s/step\n",
            "Epoch 109/150\n",
            "16/16 - 114s - loss: 0.0606 - accuracy: 0.9824 - auc: 0.9971 - val_loss: 1.4106 - val_accuracy: 0.7344 - val_auc: 0.7666 - 114s/epoch - 7s/step\n",
            "Epoch 110/150\n",
            "16/16 - 114s - loss: 0.0766 - accuracy: 0.9731 - auc: 0.9954 - val_loss: 1.4446 - val_accuracy: 0.7344 - val_auc: 0.7341 - 114s/epoch - 7s/step\n",
            "Epoch 111/150\n",
            "16/16 - 115s - loss: 0.0985 - accuracy: 0.9710 - auc: 0.9915 - val_loss: 1.4449 - val_accuracy: 0.7188 - val_auc: 0.7705 - 115s/epoch - 7s/step\n",
            "Epoch 112/150\n",
            "16/16 - 115s - loss: 0.0790 - accuracy: 0.9803 - auc: 0.9948 - val_loss: 1.6084 - val_accuracy: 0.7188 - val_auc: 0.7678 - 115s/epoch - 7s/step\n",
            "Epoch 113/150\n",
            "16/16 - 115s - loss: 0.0779 - accuracy: 0.9731 - auc: 0.9952 - val_loss: 1.6858 - val_accuracy: 0.7188 - val_auc: 0.7549 - 115s/epoch - 7s/step\n",
            "Epoch 114/150\n",
            "16/16 - 115s - loss: 0.0675 - accuracy: 0.9824 - auc: 0.9948 - val_loss: 1.9132 - val_accuracy: 0.7031 - val_auc: 0.7122 - 115s/epoch - 7s/step\n",
            "Epoch 115/150\n",
            "16/16 - 115s - loss: 0.0694 - accuracy: 0.9834 - auc: 0.9947 - val_loss: 1.9662 - val_accuracy: 0.6875 - val_auc: 0.6992 - 115s/epoch - 7s/step\n",
            "Epoch 116/150\n",
            "16/16 - 114s - loss: 0.0536 - accuracy: 0.9845 - auc: 0.9982 - val_loss: 1.8045 - val_accuracy: 0.6875 - val_auc: 0.7158 - 114s/epoch - 7s/step\n",
            "Epoch 117/150\n",
            "16/16 - 115s - loss: 0.0614 - accuracy: 0.9855 - auc: 0.9943 - val_loss: 1.4161 - val_accuracy: 0.7344 - val_auc: 0.7598 - 115s/epoch - 7s/step\n",
            "Epoch 118/150\n",
            "16/16 - 115s - loss: 0.0894 - accuracy: 0.9783 - auc: 0.9924 - val_loss: 1.3769 - val_accuracy: 0.7656 - val_auc: 0.7607 - 115s/epoch - 7s/step\n",
            "Epoch 119/150\n",
            "16/16 - 114s - loss: 0.1220 - accuracy: 0.9638 - auc: 0.9869 - val_loss: 1.2401 - val_accuracy: 0.7500 - val_auc: 0.7844 - 114s/epoch - 7s/step\n",
            "Epoch 120/150\n",
            "16/16 - 115s - loss: 0.0616 - accuracy: 0.9814 - auc: 0.9959 - val_loss: 1.6534 - val_accuracy: 0.7031 - val_auc: 0.7473 - 115s/epoch - 7s/step\n",
            "Epoch 121/150\n",
            "16/16 - 115s - loss: 0.0655 - accuracy: 0.9824 - auc: 0.9960 - val_loss: 1.5943 - val_accuracy: 0.7344 - val_auc: 0.7703 - 115s/epoch - 7s/step\n",
            "Epoch 122/150\n",
            "16/16 - 115s - loss: 0.0512 - accuracy: 0.9855 - auc: 0.9954 - val_loss: 1.3246 - val_accuracy: 0.7500 - val_auc: 0.8042 - 115s/epoch - 7s/step\n",
            "Epoch 123/150\n",
            "16/16 - 115s - loss: 0.0521 - accuracy: 0.9855 - auc: 0.9973 - val_loss: 1.4219 - val_accuracy: 0.7500 - val_auc: 0.7832 - 115s/epoch - 7s/step\n",
            "Epoch 124/150\n",
            "16/16 - 115s - loss: 0.0465 - accuracy: 0.9876 - auc: 0.9974 - val_loss: 1.4131 - val_accuracy: 0.7031 - val_auc: 0.7629 - 115s/epoch - 7s/step\n",
            "Epoch 125/150\n",
            "16/16 - 115s - loss: 0.0234 - accuracy: 0.9969 - auc: 0.9999 - val_loss: 1.3523 - val_accuracy: 0.7500 - val_auc: 0.8093 - 115s/epoch - 7s/step\n",
            "Epoch 126/150\n",
            "16/16 - 115s - loss: 0.0490 - accuracy: 0.9845 - auc: 0.9983 - val_loss: 1.3979 - val_accuracy: 0.7500 - val_auc: 0.7957 - 115s/epoch - 7s/step\n",
            "Epoch 127/150\n",
            "16/16 - 115s - loss: 0.0593 - accuracy: 0.9803 - auc: 0.9969 - val_loss: 1.6582 - val_accuracy: 0.7031 - val_auc: 0.7517 - 115s/epoch - 7s/step\n",
            "Epoch 128/150\n",
            "16/16 - 115s - loss: 0.0580 - accuracy: 0.9772 - auc: 0.9968 - val_loss: 1.9762 - val_accuracy: 0.6719 - val_auc: 0.7249 - 115s/epoch - 7s/step\n",
            "Epoch 129/150\n",
            "16/16 - 115s - loss: 0.0637 - accuracy: 0.9783 - auc: 0.9928 - val_loss: 1.6793 - val_accuracy: 0.7188 - val_auc: 0.7480 - 115s/epoch - 7s/step\n",
            "Epoch 130/150\n",
            "16/16 - 115s - loss: 0.0473 - accuracy: 0.9865 - auc: 0.9972 - val_loss: 1.4667 - val_accuracy: 0.7500 - val_auc: 0.7656 - 115s/epoch - 7s/step\n",
            "Epoch 131/150\n",
            "16/16 - 114s - loss: 0.0480 - accuracy: 0.9896 - auc: 0.9974 - val_loss: 1.5256 - val_accuracy: 0.7188 - val_auc: 0.7653 - 114s/epoch - 7s/step\n",
            "Epoch 132/150\n",
            "16/16 - 115s - loss: 0.0805 - accuracy: 0.9803 - auc: 0.9909 - val_loss: 1.7910 - val_accuracy: 0.7188 - val_auc: 0.7593 - 115s/epoch - 7s/step\n",
            "Epoch 133/150\n",
            "16/16 - 114s - loss: 0.0614 - accuracy: 0.9803 - auc: 0.9949 - val_loss: 1.4129 - val_accuracy: 0.7344 - val_auc: 0.8171 - 114s/epoch - 7s/step\n",
            "Epoch 134/150\n",
            "16/16 - 115s - loss: 0.0686 - accuracy: 0.9845 - auc: 0.9943 - val_loss: 1.5716 - val_accuracy: 0.7188 - val_auc: 0.7715 - 115s/epoch - 7s/step\n",
            "Epoch 135/150\n",
            "16/16 - 115s - loss: 0.0674 - accuracy: 0.9772 - auc: 0.9948 - val_loss: 1.6092 - val_accuracy: 0.7188 - val_auc: 0.7979 - 115s/epoch - 7s/step\n",
            "Epoch 136/150\n",
            "16/16 - 116s - loss: 0.0484 - accuracy: 0.9855 - auc: 0.9964 - val_loss: 1.3816 - val_accuracy: 0.7188 - val_auc: 0.8142 - 116s/epoch - 7s/step\n",
            "Epoch 137/150\n",
            "16/16 - 116s - loss: 0.0363 - accuracy: 0.9907 - auc: 0.9987 - val_loss: 1.4338 - val_accuracy: 0.7344 - val_auc: 0.8010 - 116s/epoch - 7s/step\n",
            "Epoch 138/150\n",
            "16/16 - 115s - loss: 0.0351 - accuracy: 0.9907 - auc: 0.9978 - val_loss: 1.4162 - val_accuracy: 0.7500 - val_auc: 0.8069 - 115s/epoch - 7s/step\n",
            "Epoch 139/150\n",
            "16/16 - 116s - loss: 0.0659 - accuracy: 0.9824 - auc: 0.9929 - val_loss: 1.7546 - val_accuracy: 0.7188 - val_auc: 0.7576 - 116s/epoch - 7s/step\n",
            "Epoch 140/150\n",
            "16/16 - 116s - loss: 0.0527 - accuracy: 0.9824 - auc: 0.9972 - val_loss: 1.8970 - val_accuracy: 0.7188 - val_auc: 0.7520 - 116s/epoch - 7s/step\n",
            "Epoch 141/150\n",
            "16/16 - 116s - loss: 0.0323 - accuracy: 0.9917 - auc: 0.9987 - val_loss: 1.9519 - val_accuracy: 0.7188 - val_auc: 0.7407 - 116s/epoch - 7s/step\n",
            "Epoch 142/150\n",
            "16/16 - 116s - loss: 0.0263 - accuracy: 0.9959 - auc: 0.9999 - val_loss: 2.0046 - val_accuracy: 0.7188 - val_auc: 0.7119 - 116s/epoch - 7s/step\n",
            "Epoch 143/150\n",
            "16/16 - 116s - loss: 0.0466 - accuracy: 0.9865 - auc: 0.9974 - val_loss: 1.3832 - val_accuracy: 0.8125 - val_auc: 0.8306 - 116s/epoch - 7s/step\n",
            "Epoch 144/150\n",
            "16/16 - 116s - loss: 0.0765 - accuracy: 0.9803 - auc: 0.9909 - val_loss: 1.0952 - val_accuracy: 0.7969 - val_auc: 0.8323 - 116s/epoch - 7s/step\n",
            "Epoch 145/150\n",
            "16/16 - 116s - loss: 0.0880 - accuracy: 0.9814 - auc: 0.9939 - val_loss: 1.0263 - val_accuracy: 0.8594 - val_auc: 0.8643 - 116s/epoch - 7s/step\n",
            "Epoch 146/150\n",
            "16/16 - 116s - loss: 0.0403 - accuracy: 0.9855 - auc: 0.9965 - val_loss: 1.2803 - val_accuracy: 0.7656 - val_auc: 0.8079 - 116s/epoch - 7s/step\n",
            "Epoch 147/150\n",
            "16/16 - 116s - loss: 0.0558 - accuracy: 0.9824 - auc: 0.9951 - val_loss: 1.2020 - val_accuracy: 0.7500 - val_auc: 0.8103 - 116s/epoch - 7s/step\n",
            "Epoch 148/150\n",
            "16/16 - 116s - loss: 0.0473 - accuracy: 0.9876 - auc: 0.9974 - val_loss: 1.0932 - val_accuracy: 0.8125 - val_auc: 0.8328 - 116s/epoch - 7s/step\n",
            "Epoch 149/150\n",
            "16/16 - 116s - loss: 0.0449 - accuracy: 0.9876 - auc: 0.9975 - val_loss: 1.1029 - val_accuracy: 0.8125 - val_auc: 0.8276 - 116s/epoch - 7s/step\n",
            "Epoch 150/150\n",
            "16/16 - 115s - loss: 0.0486 - accuracy: 0.9845 - auc: 0.9974 - val_loss: 1.2417 - val_accuracy: 0.7188 - val_auc: 0.7695 - 115s/epoch - 7s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 242/242 [00:42<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.763\n",
            "Recall: 0.8374\n",
            "Threshold: 0.2689\n",
            "F1 Score: 0.7984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1168/1168 [03:36<00:00,  5.39it/s]\n"
          ]
        }
      ],
      "source": [
        "Model_Name='ResNet Model Saved(balanced Dataset)'\n",
        "ResNet50 = ResNet50(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "for layer in ResNet50.layers[:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "for idx, layer in enumerate(ResNet50.layers[:10]):\n",
        "    print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "\n",
        "model = create_model_ResNet()\n",
        "print('create model')\n",
        "for idx, layer in enumerate(ResNet50.layers[:10]):\n",
        "    print(\"layer\", idx + 1, \":\", layer.name, \"is trainable:\", layer.trainable)\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history0 = model.fit(\n",
        "        train_gen, epochs=150, verbose=VERBOSE_LEVEL, validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history0.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./ResNet_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRQOzj-b5dHA",
        "outputId": "ddaefce9-93f0-432a-dd7b-dede0355d728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "layer 1 : input_2 is trainable: True\n",
            "layer 2 : block1_conv1 is trainable: True\n",
            "layer 3 : block1_conv2 is trainable: True\n",
            "layer 4 : block1_pool is trainable: True\n",
            "layer 5 : block2_conv1 is trainable: True\n",
            "layer 6 : block2_conv2 is trainable: True\n",
            "layer 7 : block2_pool is trainable: True\n",
            "layer 8 : block3_conv1 is trainable: True\n",
            "layer 9 : block3_conv2 is trainable: True\n",
            "layer 10 : block3_conv3 is trainable: True\n",
            "layer 11 : block3_pool is trainable: True\n",
            "layer 12 : block4_conv1 is trainable: True\n",
            "layer 13 : block4_conv2 is trainable: True\n",
            "layer 14 : block4_conv3 is trainable: True\n",
            "layer 15 : block4_pool is trainable: True\n",
            "layer 16 : block5_conv1 is trainable: True\n",
            "layer 17 : block5_conv2 is trainable: True\n",
            "layer 18 : block5_conv3 is trainable: True\n",
            "layer 19 : block5_pool is trainable: True\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 14,764,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "rows in train_df 966\n",
            "rows in val_df 242\n",
            "Found 966 non-validated image filenames.\n",
            "Found 242 non-validated image filenames.\n",
            "Epoch 1/150\n",
            "16/16 - 130s - loss: 0.6787 - accuracy: 0.5932 - auc: 0.6383 - val_loss: 0.6168 - val_accuracy: 0.6719 - val_auc: 0.7325 - 130s/epoch - 8s/step\n",
            "Epoch 2/150\n",
            "16/16 - 125s - loss: 0.6342 - accuracy: 0.6677 - auc: 0.7226 - val_loss: 0.5854 - val_accuracy: 0.7031 - val_auc: 0.7574 - 125s/epoch - 8s/step\n",
            "Epoch 3/150\n",
            "16/16 - 124s - loss: 0.5777 - accuracy: 0.7215 - auc: 0.7865 - val_loss: 0.5433 - val_accuracy: 0.7031 - val_auc: 0.8004 - 124s/epoch - 8s/step\n",
            "Epoch 4/150\n",
            "16/16 - 124s - loss: 0.5370 - accuracy: 0.7412 - auc: 0.8182 - val_loss: 0.5313 - val_accuracy: 0.7031 - val_auc: 0.8018 - 124s/epoch - 8s/step\n",
            "Epoch 5/150\n",
            "16/16 - 124s - loss: 0.5391 - accuracy: 0.7267 - auc: 0.8154 - val_loss: 0.5387 - val_accuracy: 0.7344 - val_auc: 0.8091 - 124s/epoch - 8s/step\n",
            "Epoch 6/150\n",
            "16/16 - 124s - loss: 0.5250 - accuracy: 0.7526 - auc: 0.8305 - val_loss: 0.5334 - val_accuracy: 0.7188 - val_auc: 0.8064 - 124s/epoch - 8s/step\n",
            "Epoch 7/150\n",
            "16/16 - 124s - loss: 0.5021 - accuracy: 0.7702 - auc: 0.8458 - val_loss: 0.5483 - val_accuracy: 0.7031 - val_auc: 0.8047 - 124s/epoch - 8s/step\n",
            "Epoch 8/150\n",
            "16/16 - 124s - loss: 0.4860 - accuracy: 0.7629 - auc: 0.8540 - val_loss: 0.5206 - val_accuracy: 0.7344 - val_auc: 0.8186 - 124s/epoch - 8s/step\n",
            "Epoch 9/150\n",
            "16/16 - 123s - loss: 0.4881 - accuracy: 0.7712 - auc: 0.8533 - val_loss: 0.5948 - val_accuracy: 0.7031 - val_auc: 0.7671 - 123s/epoch - 8s/step\n",
            "Epoch 10/150\n",
            "16/16 - 124s - loss: 0.4782 - accuracy: 0.7660 - auc: 0.8587 - val_loss: 0.5334 - val_accuracy: 0.7344 - val_auc: 0.8220 - 124s/epoch - 8s/step\n",
            "Epoch 11/150\n",
            "16/16 - 123s - loss: 0.4630 - accuracy: 0.7878 - auc: 0.8659 - val_loss: 0.5290 - val_accuracy: 0.7500 - val_auc: 0.8245 - 123s/epoch - 8s/step\n",
            "Epoch 12/150\n",
            "16/16 - 124s - loss: 0.4613 - accuracy: 0.7816 - auc: 0.8686 - val_loss: 0.5631 - val_accuracy: 0.7344 - val_auc: 0.8025 - 124s/epoch - 8s/step\n",
            "Epoch 13/150\n",
            "16/16 - 123s - loss: 0.4490 - accuracy: 0.7909 - auc: 0.8763 - val_loss: 0.5500 - val_accuracy: 0.7344 - val_auc: 0.8022 - 123s/epoch - 8s/step\n",
            "Epoch 14/150\n",
            "16/16 - 123s - loss: 0.4548 - accuracy: 0.7909 - auc: 0.8758 - val_loss: 0.5099 - val_accuracy: 0.7188 - val_auc: 0.8315 - 123s/epoch - 8s/step\n",
            "Epoch 15/150\n",
            "16/16 - 123s - loss: 0.4653 - accuracy: 0.7702 - auc: 0.8632 - val_loss: 0.5184 - val_accuracy: 0.7031 - val_auc: 0.8180 - 123s/epoch - 8s/step\n",
            "Epoch 16/150\n",
            "16/16 - 124s - loss: 0.4494 - accuracy: 0.7940 - auc: 0.8770 - val_loss: 0.4981 - val_accuracy: 0.7500 - val_auc: 0.8337 - 124s/epoch - 8s/step\n",
            "Epoch 17/150\n",
            "16/16 - 123s - loss: 0.4263 - accuracy: 0.8023 - auc: 0.8883 - val_loss: 0.5106 - val_accuracy: 0.7500 - val_auc: 0.8345 - 123s/epoch - 8s/step\n",
            "Epoch 18/150\n",
            "16/16 - 124s - loss: 0.4232 - accuracy: 0.8064 - auc: 0.8917 - val_loss: 0.5392 - val_accuracy: 0.7656 - val_auc: 0.8228 - 124s/epoch - 8s/step\n",
            "Epoch 19/150\n",
            "16/16 - 123s - loss: 0.4300 - accuracy: 0.8126 - auc: 0.8860 - val_loss: 0.5829 - val_accuracy: 0.7188 - val_auc: 0.7815 - 123s/epoch - 8s/step\n",
            "Epoch 20/150\n",
            "16/16 - 124s - loss: 0.4147 - accuracy: 0.8085 - auc: 0.8935 - val_loss: 0.5236 - val_accuracy: 0.7188 - val_auc: 0.8376 - 124s/epoch - 8s/step\n",
            "Epoch 21/150\n",
            "16/16 - 124s - loss: 0.4072 - accuracy: 0.8147 - auc: 0.8966 - val_loss: 0.5806 - val_accuracy: 0.7031 - val_auc: 0.7986 - 124s/epoch - 8s/step\n",
            "Epoch 22/150\n",
            "16/16 - 123s - loss: 0.4262 - accuracy: 0.8012 - auc: 0.8853 - val_loss: 0.5618 - val_accuracy: 0.7188 - val_auc: 0.8018 - 123s/epoch - 8s/step\n",
            "Epoch 23/150\n",
            "16/16 - 124s - loss: 0.4170 - accuracy: 0.8033 - auc: 0.8904 - val_loss: 0.5492 - val_accuracy: 0.7031 - val_auc: 0.8005 - 124s/epoch - 8s/step\n",
            "Epoch 24/150\n",
            "16/16 - 123s - loss: 0.4505 - accuracy: 0.7857 - auc: 0.8714 - val_loss: 0.5787 - val_accuracy: 0.6719 - val_auc: 0.7673 - 123s/epoch - 8s/step\n",
            "Epoch 25/150\n",
            "16/16 - 124s - loss: 0.4255 - accuracy: 0.8054 - auc: 0.8892 - val_loss: 0.4902 - val_accuracy: 0.7500 - val_auc: 0.8542 - 124s/epoch - 8s/step\n",
            "Epoch 26/150\n",
            "16/16 - 123s - loss: 0.3962 - accuracy: 0.8199 - auc: 0.9058 - val_loss: 0.5953 - val_accuracy: 0.6875 - val_auc: 0.7954 - 123s/epoch - 8s/step\n",
            "Epoch 27/150\n",
            "16/16 - 124s - loss: 0.3838 - accuracy: 0.8344 - auc: 0.9085 - val_loss: 0.5290 - val_accuracy: 0.7656 - val_auc: 0.8264 - 124s/epoch - 8s/step\n",
            "Epoch 28/150\n",
            "16/16 - 123s - loss: 0.3616 - accuracy: 0.8354 - auc: 0.9203 - val_loss: 0.5969 - val_accuracy: 0.6875 - val_auc: 0.7927 - 123s/epoch - 8s/step\n",
            "Epoch 29/150\n",
            "16/16 - 124s - loss: 0.3840 - accuracy: 0.8261 - auc: 0.9113 - val_loss: 0.4908 - val_accuracy: 0.7656 - val_auc: 0.8501 - 124s/epoch - 8s/step\n",
            "Epoch 30/150\n",
            "16/16 - 124s - loss: 0.3821 - accuracy: 0.8282 - auc: 0.9107 - val_loss: 0.5552 - val_accuracy: 0.7344 - val_auc: 0.8123 - 124s/epoch - 8s/step\n",
            "Epoch 31/150\n",
            "16/16 - 123s - loss: 0.3827 - accuracy: 0.8188 - auc: 0.9084 - val_loss: 0.5736 - val_accuracy: 0.7031 - val_auc: 0.8138 - 123s/epoch - 8s/step\n",
            "Epoch 32/150\n",
            "16/16 - 123s - loss: 0.3645 - accuracy: 0.8364 - auc: 0.9190 - val_loss: 0.5358 - val_accuracy: 0.7344 - val_auc: 0.8325 - 123s/epoch - 8s/step\n",
            "Epoch 33/150\n",
            "16/16 - 123s - loss: 0.3315 - accuracy: 0.8561 - auc: 0.9346 - val_loss: 0.6579 - val_accuracy: 0.6719 - val_auc: 0.7563 - 123s/epoch - 8s/step\n",
            "Epoch 34/150\n",
            "16/16 - 123s - loss: 0.4271 - accuracy: 0.8085 - auc: 0.8849 - val_loss: 0.6258 - val_accuracy: 0.7344 - val_auc: 0.7981 - 123s/epoch - 8s/step\n",
            "Epoch 35/150\n",
            "16/16 - 124s - loss: 0.3602 - accuracy: 0.8395 - auc: 0.9226 - val_loss: 0.5017 - val_accuracy: 0.7656 - val_auc: 0.8545 - 124s/epoch - 8s/step\n",
            "Epoch 36/150\n",
            "16/16 - 123s - loss: 0.3248 - accuracy: 0.8437 - auc: 0.9373 - val_loss: 0.5894 - val_accuracy: 0.7344 - val_auc: 0.8274 - 123s/epoch - 8s/step\n",
            "Epoch 37/150\n",
            "16/16 - 124s - loss: 0.3265 - accuracy: 0.8644 - auc: 0.9365 - val_loss: 0.5814 - val_accuracy: 0.7969 - val_auc: 0.8231 - 124s/epoch - 8s/step\n",
            "Epoch 38/150\n",
            "16/16 - 124s - loss: 0.3265 - accuracy: 0.8561 - auc: 0.9345 - val_loss: 0.5451 - val_accuracy: 0.7500 - val_auc: 0.8582 - 124s/epoch - 8s/step\n",
            "Epoch 39/150\n",
            "16/16 - 123s - loss: 0.3107 - accuracy: 0.8716 - auc: 0.9399 - val_loss: 0.5802 - val_accuracy: 0.6719 - val_auc: 0.7810 - 123s/epoch - 8s/step\n",
            "Epoch 40/150\n",
            "16/16 - 124s - loss: 0.3557 - accuracy: 0.8395 - auc: 0.9214 - val_loss: 0.5086 - val_accuracy: 0.7500 - val_auc: 0.8435 - 124s/epoch - 8s/step\n",
            "Epoch 41/150\n",
            "16/16 - 124s - loss: 0.3183 - accuracy: 0.8530 - auc: 0.9397 - val_loss: 0.5586 - val_accuracy: 0.7656 - val_auc: 0.8281 - 124s/epoch - 8s/step\n",
            "Epoch 42/150\n",
            "16/16 - 124s - loss: 0.3170 - accuracy: 0.8706 - auc: 0.9405 - val_loss: 0.5249 - val_accuracy: 0.7656 - val_auc: 0.8491 - 124s/epoch - 8s/step\n",
            "Epoch 43/150\n",
            "16/16 - 123s - loss: 0.3398 - accuracy: 0.8406 - auc: 0.9329 - val_loss: 0.5158 - val_accuracy: 0.7500 - val_auc: 0.8479 - 123s/epoch - 8s/step\n",
            "Epoch 44/150\n",
            "16/16 - 124s - loss: 0.3415 - accuracy: 0.8499 - auc: 0.9284 - val_loss: 0.5327 - val_accuracy: 0.7344 - val_auc: 0.8141 - 124s/epoch - 8s/step\n",
            "Epoch 45/150\n",
            "16/16 - 123s - loss: 0.3327 - accuracy: 0.8385 - auc: 0.9324 - val_loss: 0.5709 - val_accuracy: 0.7344 - val_auc: 0.8230 - 123s/epoch - 8s/step\n",
            "Epoch 46/150\n",
            "16/16 - 124s - loss: 0.2862 - accuracy: 0.8706 - auc: 0.9506 - val_loss: 0.5869 - val_accuracy: 0.7031 - val_auc: 0.8242 - 124s/epoch - 8s/step\n",
            "Epoch 47/150\n",
            "16/16 - 124s - loss: 0.2811 - accuracy: 0.8737 - auc: 0.9523 - val_loss: 0.5230 - val_accuracy: 0.8125 - val_auc: 0.8661 - 124s/epoch - 8s/step\n",
            "Epoch 48/150\n",
            "16/16 - 124s - loss: 0.2928 - accuracy: 0.8706 - auc: 0.9459 - val_loss: 0.6103 - val_accuracy: 0.7656 - val_auc: 0.8271 - 124s/epoch - 8s/step\n",
            "Epoch 49/150\n",
            "16/16 - 123s - loss: 0.2773 - accuracy: 0.8716 - auc: 0.9525 - val_loss: 0.5712 - val_accuracy: 0.7656 - val_auc: 0.8345 - 123s/epoch - 8s/step\n",
            "Epoch 50/150\n",
            "16/16 - 123s - loss: 0.2665 - accuracy: 0.8913 - auc: 0.9585 - val_loss: 0.5751 - val_accuracy: 0.7500 - val_auc: 0.8347 - 123s/epoch - 8s/step\n",
            "Epoch 51/150\n",
            "16/16 - 123s - loss: 0.2813 - accuracy: 0.8810 - auc: 0.9495 - val_loss: 0.5239 - val_accuracy: 0.7656 - val_auc: 0.8364 - 123s/epoch - 8s/step\n",
            "Epoch 52/150\n",
            "16/16 - 123s - loss: 0.3071 - accuracy: 0.8623 - auc: 0.9433 - val_loss: 0.5644 - val_accuracy: 0.7031 - val_auc: 0.8413 - 123s/epoch - 8s/step\n",
            "Epoch 53/150\n",
            "16/16 - 123s - loss: 0.3787 - accuracy: 0.8126 - auc: 0.9084 - val_loss: 0.6654 - val_accuracy: 0.7500 - val_auc: 0.8010 - 123s/epoch - 8s/step\n",
            "Epoch 54/150\n",
            "16/16 - 123s - loss: 0.2921 - accuracy: 0.8789 - auc: 0.9492 - val_loss: 0.5270 - val_accuracy: 0.7812 - val_auc: 0.8547 - 123s/epoch - 8s/step\n",
            "Epoch 55/150\n",
            "16/16 - 123s - loss: 0.2475 - accuracy: 0.8841 - auc: 0.9657 - val_loss: 0.5817 - val_accuracy: 0.8125 - val_auc: 0.8569 - 123s/epoch - 8s/step\n",
            "Epoch 56/150\n",
            "16/16 - 123s - loss: 0.2547 - accuracy: 0.8810 - auc: 0.9612 - val_loss: 0.6527 - val_accuracy: 0.7344 - val_auc: 0.8251 - 123s/epoch - 8s/step\n",
            "Epoch 57/150\n",
            "16/16 - 123s - loss: 0.2410 - accuracy: 0.8944 - auc: 0.9629 - val_loss: 0.5993 - val_accuracy: 0.7656 - val_auc: 0.8402 - 123s/epoch - 8s/step\n",
            "Epoch 58/150\n",
            "16/16 - 123s - loss: 0.2691 - accuracy: 0.8882 - auc: 0.9562 - val_loss: 0.7369 - val_accuracy: 0.7344 - val_auc: 0.7554 - 123s/epoch - 8s/step\n",
            "Epoch 59/150\n",
            "16/16 - 123s - loss: 0.2974 - accuracy: 0.8634 - auc: 0.9461 - val_loss: 0.6353 - val_accuracy: 0.7031 - val_auc: 0.7964 - 123s/epoch - 8s/step\n",
            "Epoch 60/150\n",
            "16/16 - 123s - loss: 0.2863 - accuracy: 0.8716 - auc: 0.9511 - val_loss: 0.6497 - val_accuracy: 0.7188 - val_auc: 0.8137 - 123s/epoch - 8s/step\n",
            "Epoch 61/150\n",
            "16/16 - 123s - loss: 0.2815 - accuracy: 0.8810 - auc: 0.9483 - val_loss: 0.5247 - val_accuracy: 0.7812 - val_auc: 0.8313 - 123s/epoch - 8s/step\n",
            "Epoch 62/150\n",
            "16/16 - 123s - loss: 0.2403 - accuracy: 0.8986 - auc: 0.9642 - val_loss: 0.5818 - val_accuracy: 0.7500 - val_auc: 0.8215 - 123s/epoch - 8s/step\n",
            "Epoch 63/150\n",
            "16/16 - 123s - loss: 0.2563 - accuracy: 0.8913 - auc: 0.9581 - val_loss: 0.6468 - val_accuracy: 0.7344 - val_auc: 0.7903 - 123s/epoch - 8s/step\n",
            "Epoch 64/150\n",
            "16/16 - 123s - loss: 0.2054 - accuracy: 0.9286 - auc: 0.9764 - val_loss: 0.7263 - val_accuracy: 0.7344 - val_auc: 0.7966 - 123s/epoch - 8s/step\n",
            "Epoch 65/150\n",
            "16/16 - 123s - loss: 0.1996 - accuracy: 0.9193 - auc: 0.9771 - val_loss: 0.5413 - val_accuracy: 0.7812 - val_auc: 0.8464 - 123s/epoch - 8s/step\n",
            "Epoch 66/150\n",
            "16/16 - 123s - loss: 0.2665 - accuracy: 0.8872 - auc: 0.9571 - val_loss: 0.7726 - val_accuracy: 0.7500 - val_auc: 0.8005 - 123s/epoch - 8s/step\n",
            "Epoch 67/150\n",
            "16/16 - 123s - loss: 0.2070 - accuracy: 0.9203 - auc: 0.9756 - val_loss: 0.6817 - val_accuracy: 0.7188 - val_auc: 0.7922 - 123s/epoch - 8s/step\n",
            "Epoch 68/150\n",
            "16/16 - 123s - loss: 0.1915 - accuracy: 0.9172 - auc: 0.9783 - val_loss: 0.6225 - val_accuracy: 0.7812 - val_auc: 0.8582 - 123s/epoch - 8s/step\n",
            "Epoch 69/150\n",
            "16/16 - 123s - loss: 0.2114 - accuracy: 0.9172 - auc: 0.9713 - val_loss: 0.6682 - val_accuracy: 0.7656 - val_auc: 0.8066 - 123s/epoch - 8s/step\n",
            "Epoch 70/150\n",
            "16/16 - 123s - loss: 0.3408 - accuracy: 0.8344 - auc: 0.9261 - val_loss: 0.6225 - val_accuracy: 0.7031 - val_auc: 0.8079 - 123s/epoch - 8s/step\n",
            "Epoch 71/150\n",
            "16/16 - 123s - loss: 0.2841 - accuracy: 0.8830 - auc: 0.9519 - val_loss: 0.7164 - val_accuracy: 0.7500 - val_auc: 0.8379 - 123s/epoch - 8s/step\n",
            "Epoch 72/150\n",
            "16/16 - 123s - loss: 0.2212 - accuracy: 0.9068 - auc: 0.9698 - val_loss: 0.7813 - val_accuracy: 0.7656 - val_auc: 0.8071 - 123s/epoch - 8s/step\n",
            "Epoch 73/150\n",
            "16/16 - 123s - loss: 0.1927 - accuracy: 0.9244 - auc: 0.9773 - val_loss: 0.9014 - val_accuracy: 0.7188 - val_auc: 0.7703 - 123s/epoch - 8s/step\n",
            "Epoch 74/150\n",
            "16/16 - 123s - loss: 0.1643 - accuracy: 0.9317 - auc: 0.9834 - val_loss: 0.7800 - val_accuracy: 0.7656 - val_auc: 0.8096 - 123s/epoch - 8s/step\n",
            "Epoch 75/150\n",
            "16/16 - 123s - loss: 0.1783 - accuracy: 0.9296 - auc: 0.9813 - val_loss: 0.7558 - val_accuracy: 0.7656 - val_auc: 0.8372 - 123s/epoch - 8s/step\n",
            "Epoch 76/150\n",
            "16/16 - 123s - loss: 0.2395 - accuracy: 0.9017 - auc: 0.9641 - val_loss: 0.6414 - val_accuracy: 0.7500 - val_auc: 0.8096 - 123s/epoch - 8s/step\n",
            "Epoch 77/150\n",
            "16/16 - 123s - loss: 0.2253 - accuracy: 0.8986 - auc: 0.9694 - val_loss: 0.8830 - val_accuracy: 0.7344 - val_auc: 0.8142 - 123s/epoch - 8s/step\n",
            "Epoch 78/150\n",
            "16/16 - 123s - loss: 0.1921 - accuracy: 0.9182 - auc: 0.9773 - val_loss: 0.6485 - val_accuracy: 0.7188 - val_auc: 0.8167 - 123s/epoch - 8s/step\n",
            "Epoch 79/150\n",
            "16/16 - 123s - loss: 0.1827 - accuracy: 0.9265 - auc: 0.9801 - val_loss: 0.7541 - val_accuracy: 0.7812 - val_auc: 0.8337 - 123s/epoch - 8s/step\n",
            "Epoch 80/150\n",
            "16/16 - 123s - loss: 0.1538 - accuracy: 0.9420 - auc: 0.9848 - val_loss: 0.7535 - val_accuracy: 0.7031 - val_auc: 0.7736 - 123s/epoch - 8s/step\n",
            "Epoch 81/150\n",
            "16/16 - 123s - loss: 0.1640 - accuracy: 0.9348 - auc: 0.9819 - val_loss: 0.9964 - val_accuracy: 0.7500 - val_auc: 0.7920 - 123s/epoch - 8s/step\n",
            "Epoch 82/150\n",
            "16/16 - 123s - loss: 0.1576 - accuracy: 0.9358 - auc: 0.9825 - val_loss: 0.8406 - val_accuracy: 0.7188 - val_auc: 0.7754 - 123s/epoch - 8s/step\n",
            "Epoch 83/150\n",
            "16/16 - 123s - loss: 0.1679 - accuracy: 0.9389 - auc: 0.9832 - val_loss: 0.6564 - val_accuracy: 0.7656 - val_auc: 0.8015 - 123s/epoch - 8s/step\n",
            "Epoch 84/150\n",
            "16/16 - 123s - loss: 0.1835 - accuracy: 0.9400 - auc: 0.9767 - val_loss: 0.7272 - val_accuracy: 0.7344 - val_auc: 0.8396 - 123s/epoch - 8s/step\n",
            "Epoch 85/150\n",
            "16/16 - 123s - loss: 0.1643 - accuracy: 0.9389 - auc: 0.9830 - val_loss: 0.8363 - val_accuracy: 0.7656 - val_auc: 0.8223 - 123s/epoch - 8s/step\n",
            "Epoch 86/150\n",
            "16/16 - 123s - loss: 0.1440 - accuracy: 0.9410 - auc: 0.9890 - val_loss: 0.7442 - val_accuracy: 0.7188 - val_auc: 0.8445 - 123s/epoch - 8s/step\n",
            "Epoch 87/150\n",
            "16/16 - 123s - loss: 0.1508 - accuracy: 0.9348 - auc: 0.9822 - val_loss: 0.8785 - val_accuracy: 0.7500 - val_auc: 0.7795 - 123s/epoch - 8s/step\n",
            "Epoch 88/150\n",
            "16/16 - 123s - loss: 0.1145 - accuracy: 0.9648 - auc: 0.9922 - val_loss: 0.8890 - val_accuracy: 0.7969 - val_auc: 0.8079 - 123s/epoch - 8s/step\n",
            "Epoch 89/150\n",
            "16/16 - 123s - loss: 0.1044 - accuracy: 0.9586 - auc: 0.9930 - val_loss: 1.0820 - val_accuracy: 0.7500 - val_auc: 0.7913 - 123s/epoch - 8s/step\n",
            "Epoch 90/150\n",
            "16/16 - 123s - loss: 0.1317 - accuracy: 0.9462 - auc: 0.9849 - val_loss: 0.9382 - val_accuracy: 0.7188 - val_auc: 0.7849 - 123s/epoch - 8s/step\n",
            "Epoch 91/150\n",
            "16/16 - 125s - loss: 0.1614 - accuracy: 0.9389 - auc: 0.9821 - val_loss: 0.7359 - val_accuracy: 0.7656 - val_auc: 0.8022 - 125s/epoch - 8s/step\n",
            "Epoch 92/150\n",
            "16/16 - 123s - loss: 0.1739 - accuracy: 0.9244 - auc: 0.9803 - val_loss: 0.7515 - val_accuracy: 0.7500 - val_auc: 0.8040 - 123s/epoch - 8s/step\n",
            "Epoch 93/150\n",
            "16/16 - 123s - loss: 0.1316 - accuracy: 0.9565 - auc: 0.9911 - val_loss: 0.8185 - val_accuracy: 0.7344 - val_auc: 0.7844 - 123s/epoch - 8s/step\n",
            "Epoch 94/150\n",
            "16/16 - 123s - loss: 0.1221 - accuracy: 0.9534 - auc: 0.9883 - val_loss: 0.7233 - val_accuracy: 0.7188 - val_auc: 0.7839 - 123s/epoch - 8s/step\n",
            "Epoch 95/150\n",
            "16/16 - 123s - loss: 0.1496 - accuracy: 0.9369 - auc: 0.9834 - val_loss: 0.7630 - val_accuracy: 0.7188 - val_auc: 0.8005 - 123s/epoch - 8s/step\n",
            "Epoch 96/150\n",
            "16/16 - 123s - loss: 0.1050 - accuracy: 0.9617 - auc: 0.9932 - val_loss: 0.7575 - val_accuracy: 0.7812 - val_auc: 0.8457 - 123s/epoch - 8s/step\n",
            "Epoch 97/150\n",
            "16/16 - 123s - loss: 0.1206 - accuracy: 0.9565 - auc: 0.9884 - val_loss: 0.8086 - val_accuracy: 0.7344 - val_auc: 0.8137 - 123s/epoch - 8s/step\n",
            "Epoch 98/150\n",
            "16/16 - 123s - loss: 0.0910 - accuracy: 0.9741 - auc: 0.9944 - val_loss: 0.8671 - val_accuracy: 0.7500 - val_auc: 0.7996 - 123s/epoch - 8s/step\n",
            "Epoch 99/150\n",
            "16/16 - 123s - loss: 0.1297 - accuracy: 0.9503 - auc: 0.9891 - val_loss: 0.8003 - val_accuracy: 0.7656 - val_auc: 0.8359 - 123s/epoch - 8s/step\n",
            "Epoch 100/150\n",
            "16/16 - 123s - loss: 0.0798 - accuracy: 0.9710 - auc: 0.9972 - val_loss: 1.0773 - val_accuracy: 0.7656 - val_auc: 0.7681 - 123s/epoch - 8s/step\n",
            "Epoch 101/150\n",
            "16/16 - 123s - loss: 0.0991 - accuracy: 0.9638 - auc: 0.9914 - val_loss: 0.9547 - val_accuracy: 0.7188 - val_auc: 0.8132 - 123s/epoch - 8s/step\n",
            "Epoch 102/150\n",
            "16/16 - 124s - loss: 0.0992 - accuracy: 0.9627 - auc: 0.9933 - val_loss: 0.9029 - val_accuracy: 0.7500 - val_auc: 0.7930 - 124s/epoch - 8s/step\n",
            "Epoch 103/150\n",
            "16/16 - 125s - loss: 0.1029 - accuracy: 0.9596 - auc: 0.9921 - val_loss: 0.9282 - val_accuracy: 0.7656 - val_auc: 0.8108 - 125s/epoch - 8s/step\n",
            "Epoch 104/150\n",
            "16/16 - 124s - loss: 0.0917 - accuracy: 0.9658 - auc: 0.9949 - val_loss: 0.8591 - val_accuracy: 0.7812 - val_auc: 0.8040 - 124s/epoch - 8s/step\n",
            "Epoch 105/150\n",
            "16/16 - 123s - loss: 0.0968 - accuracy: 0.9689 - auc: 0.9927 - val_loss: 0.8673 - val_accuracy: 0.7188 - val_auc: 0.8027 - 123s/epoch - 8s/step\n",
            "Epoch 106/150\n",
            "16/16 - 123s - loss: 0.0833 - accuracy: 0.9700 - auc: 0.9968 - val_loss: 1.2054 - val_accuracy: 0.7656 - val_auc: 0.7996 - 123s/epoch - 8s/step\n",
            "Epoch 107/150\n",
            "16/16 - 123s - loss: 0.0901 - accuracy: 0.9648 - auc: 0.9950 - val_loss: 0.9498 - val_accuracy: 0.7188 - val_auc: 0.8057 - 123s/epoch - 8s/step\n",
            "Epoch 108/150\n",
            "16/16 - 123s - loss: 0.0945 - accuracy: 0.9627 - auc: 0.9917 - val_loss: 0.9190 - val_accuracy: 0.7344 - val_auc: 0.7778 - 123s/epoch - 8s/step\n",
            "Epoch 109/150\n",
            "16/16 - 123s - loss: 0.1051 - accuracy: 0.9555 - auc: 0.9924 - val_loss: 0.9335 - val_accuracy: 0.6875 - val_auc: 0.7811 - 123s/epoch - 8s/step\n",
            "Epoch 110/150\n",
            "16/16 - 123s - loss: 0.0719 - accuracy: 0.9793 - auc: 0.9978 - val_loss: 1.0575 - val_accuracy: 0.7656 - val_auc: 0.8062 - 123s/epoch - 8s/step\n",
            "Epoch 111/150\n",
            "16/16 - 123s - loss: 0.0728 - accuracy: 0.9762 - auc: 0.9959 - val_loss: 1.0729 - val_accuracy: 0.7812 - val_auc: 0.8099 - 123s/epoch - 8s/step\n",
            "Epoch 112/150\n",
            "16/16 - 123s - loss: 0.0659 - accuracy: 0.9720 - auc: 0.9979 - val_loss: 1.2501 - val_accuracy: 0.7500 - val_auc: 0.7634 - 123s/epoch - 8s/step\n",
            "Epoch 113/150\n",
            "16/16 - 123s - loss: 0.1017 - accuracy: 0.9617 - auc: 0.9897 - val_loss: 1.0280 - val_accuracy: 0.6875 - val_auc: 0.7766 - 123s/epoch - 8s/step\n",
            "Epoch 114/150\n",
            "16/16 - 123s - loss: 0.0834 - accuracy: 0.9658 - auc: 0.9957 - val_loss: 1.1457 - val_accuracy: 0.7344 - val_auc: 0.7600 - 123s/epoch - 8s/step\n",
            "Epoch 115/150\n",
            "16/16 - 123s - loss: 0.0728 - accuracy: 0.9824 - auc: 0.9949 - val_loss: 1.3741 - val_accuracy: 0.7500 - val_auc: 0.7402 - 123s/epoch - 8s/step\n",
            "Epoch 116/150\n",
            "16/16 - 123s - loss: 0.1062 - accuracy: 0.9617 - auc: 0.9907 - val_loss: 0.8847 - val_accuracy: 0.7188 - val_auc: 0.7906 - 123s/epoch - 8s/step\n",
            "Epoch 117/150\n",
            "16/16 - 123s - loss: 0.0892 - accuracy: 0.9679 - auc: 0.9941 - val_loss: 1.1449 - val_accuracy: 0.7188 - val_auc: 0.7957 - 123s/epoch - 8s/step\n",
            "Epoch 118/150\n",
            "16/16 - 124s - loss: 0.0613 - accuracy: 0.9803 - auc: 0.9973 - val_loss: 1.0352 - val_accuracy: 0.7344 - val_auc: 0.8145 - 124s/epoch - 8s/step\n",
            "Epoch 119/150\n",
            "16/16 - 124s - loss: 0.0514 - accuracy: 0.9886 - auc: 0.9960 - val_loss: 1.1769 - val_accuracy: 0.7500 - val_auc: 0.8359 - 124s/epoch - 8s/step\n",
            "Epoch 120/150\n",
            "16/16 - 124s - loss: 0.0742 - accuracy: 0.9762 - auc: 0.9928 - val_loss: 1.0928 - val_accuracy: 0.7656 - val_auc: 0.8193 - 124s/epoch - 8s/step\n",
            "Epoch 121/150\n",
            "16/16 - 123s - loss: 0.0835 - accuracy: 0.9731 - auc: 0.9917 - val_loss: 1.1644 - val_accuracy: 0.7500 - val_auc: 0.8040 - 123s/epoch - 8s/step\n",
            "Epoch 122/150\n",
            "16/16 - 124s - loss: 0.0858 - accuracy: 0.9700 - auc: 0.9940 - val_loss: 1.0516 - val_accuracy: 0.7500 - val_auc: 0.7886 - 124s/epoch - 8s/step\n",
            "Epoch 123/150\n",
            "16/16 - 124s - loss: 0.0471 - accuracy: 0.9845 - auc: 0.9983 - val_loss: 1.3911 - val_accuracy: 0.7656 - val_auc: 0.7991 - 124s/epoch - 8s/step\n",
            "Epoch 124/150\n",
            "16/16 - 124s - loss: 0.0497 - accuracy: 0.9876 - auc: 0.9979 - val_loss: 0.9610 - val_accuracy: 0.7500 - val_auc: 0.7893 - 124s/epoch - 8s/step\n",
            "Epoch 125/150\n",
            "16/16 - 123s - loss: 0.0734 - accuracy: 0.9762 - auc: 0.9952 - val_loss: 1.6081 - val_accuracy: 0.7188 - val_auc: 0.7493 - 123s/epoch - 8s/step\n",
            "Epoch 126/150\n",
            "16/16 - 123s - loss: 0.2526 - accuracy: 0.9265 - auc: 0.9673 - val_loss: 1.1158 - val_accuracy: 0.7031 - val_auc: 0.7625 - 123s/epoch - 8s/step\n",
            "Epoch 127/150\n",
            "16/16 - 123s - loss: 0.4983 - accuracy: 0.8002 - auc: 0.8707 - val_loss: 0.7765 - val_accuracy: 0.7031 - val_auc: 0.7754 - 123s/epoch - 8s/step\n",
            "Epoch 128/150\n",
            "16/16 - 124s - loss: 0.2752 - accuracy: 0.8872 - auc: 0.9553 - val_loss: 0.6458 - val_accuracy: 0.7188 - val_auc: 0.8027 - 124s/epoch - 8s/step\n",
            "Epoch 129/150\n",
            "16/16 - 124s - loss: 0.1845 - accuracy: 0.9255 - auc: 0.9797 - val_loss: 0.7119 - val_accuracy: 0.7031 - val_auc: 0.8018 - 124s/epoch - 8s/step\n",
            "Epoch 130/150\n",
            "16/16 - 124s - loss: 0.1637 - accuracy: 0.9369 - auc: 0.9791 - val_loss: 1.1197 - val_accuracy: 0.7188 - val_auc: 0.7817 - 124s/epoch - 8s/step\n",
            "Epoch 131/150\n",
            "16/16 - 123s - loss: 0.1178 - accuracy: 0.9576 - auc: 0.9913 - val_loss: 0.9946 - val_accuracy: 0.7344 - val_auc: 0.8008 - 123s/epoch - 8s/step\n",
            "Epoch 132/150\n",
            "16/16 - 123s - loss: 0.0867 - accuracy: 0.9700 - auc: 0.9966 - val_loss: 0.9461 - val_accuracy: 0.7188 - val_auc: 0.8003 - 123s/epoch - 8s/step\n",
            "Epoch 133/150\n",
            "16/16 - 123s - loss: 0.0857 - accuracy: 0.9731 - auc: 0.9941 - val_loss: 1.3757 - val_accuracy: 0.7188 - val_auc: 0.7605 - 123s/epoch - 8s/step\n",
            "Epoch 134/150\n",
            "16/16 - 123s - loss: 0.0768 - accuracy: 0.9772 - auc: 0.9945 - val_loss: 1.1269 - val_accuracy: 0.7188 - val_auc: 0.7729 - 123s/epoch - 8s/step\n",
            "Epoch 135/150\n",
            "16/16 - 123s - loss: 0.0601 - accuracy: 0.9855 - auc: 0.9967 - val_loss: 1.1070 - val_accuracy: 0.7500 - val_auc: 0.7722 - 123s/epoch - 8s/step\n",
            "Epoch 136/150\n",
            "16/16 - 123s - loss: 0.0523 - accuracy: 0.9834 - auc: 0.9979 - val_loss: 1.1575 - val_accuracy: 0.7656 - val_auc: 0.8088 - 123s/epoch - 8s/step\n",
            "Epoch 137/150\n",
            "16/16 - 123s - loss: 0.0628 - accuracy: 0.9741 - auc: 0.9953 - val_loss: 1.2662 - val_accuracy: 0.7188 - val_auc: 0.7354 - 123s/epoch - 8s/step\n",
            "Epoch 138/150\n",
            "16/16 - 124s - loss: 0.0658 - accuracy: 0.9783 - auc: 0.9945 - val_loss: 1.4902 - val_accuracy: 0.7500 - val_auc: 0.7634 - 124s/epoch - 8s/step\n",
            "Epoch 139/150\n",
            "16/16 - 123s - loss: 0.0555 - accuracy: 0.9834 - auc: 0.9967 - val_loss: 1.4325 - val_accuracy: 0.7188 - val_auc: 0.7659 - 123s/epoch - 8s/step\n",
            "Epoch 140/150\n",
            "16/16 - 123s - loss: 0.0611 - accuracy: 0.9793 - auc: 0.9972 - val_loss: 1.3754 - val_accuracy: 0.7188 - val_auc: 0.7891 - 123s/epoch - 8s/step\n",
            "Epoch 141/150\n",
            "16/16 - 123s - loss: 0.0552 - accuracy: 0.9793 - auc: 0.9975 - val_loss: 1.3399 - val_accuracy: 0.7031 - val_auc: 0.7874 - 123s/epoch - 8s/step\n",
            "Epoch 142/150\n",
            "16/16 - 123s - loss: 0.0551 - accuracy: 0.9793 - auc: 0.9957 - val_loss: 1.2001 - val_accuracy: 0.7344 - val_auc: 0.8076 - 123s/epoch - 8s/step\n",
            "Epoch 143/150\n",
            "16/16 - 123s - loss: 0.0463 - accuracy: 0.9824 - auc: 0.9982 - val_loss: 1.5482 - val_accuracy: 0.7188 - val_auc: 0.7634 - 123s/epoch - 8s/step\n",
            "Epoch 144/150\n",
            "16/16 - 123s - loss: 0.1455 - accuracy: 0.9503 - auc: 0.9823 - val_loss: 1.2311 - val_accuracy: 0.7188 - val_auc: 0.8032 - 123s/epoch - 8s/step\n",
            "Epoch 145/150\n",
            "16/16 - 123s - loss: 0.1144 - accuracy: 0.9596 - auc: 0.9890 - val_loss: 0.8797 - val_accuracy: 0.7969 - val_auc: 0.8479 - 123s/epoch - 8s/step\n",
            "Epoch 146/150\n",
            "16/16 - 123s - loss: 0.0862 - accuracy: 0.9648 - auc: 0.9927 - val_loss: 1.0272 - val_accuracy: 0.7500 - val_auc: 0.7578 - 123s/epoch - 8s/step\n",
            "Epoch 147/150\n",
            "16/16 - 123s - loss: 0.1207 - accuracy: 0.9565 - auc: 0.9856 - val_loss: 1.0172 - val_accuracy: 0.7500 - val_auc: 0.8215 - 123s/epoch - 8s/step\n",
            "Epoch 148/150\n",
            "16/16 - 124s - loss: 0.0630 - accuracy: 0.9803 - auc: 0.9973 - val_loss: 1.2057 - val_accuracy: 0.7656 - val_auc: 0.7927 - 124s/epoch - 8s/step\n",
            "Epoch 149/150\n",
            "16/16 - 124s - loss: 0.0481 - accuracy: 0.9855 - auc: 0.9970 - val_loss: 1.4376 - val_accuracy: 0.7656 - val_auc: 0.7854 - 124s/epoch - 8s/step\n",
            "Epoch 150/150\n",
            "16/16 - 124s - loss: 0.0459 - accuracy: 0.9845 - auc: 0.9980 - val_loss: 1.4307 - val_accuracy: 0.7656 - val_auc: 0.7964 - 124s/epoch - 8s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 242/242 [00:40<00:00,  5.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6938\n",
            "Recall: 0.9024\n",
            "Threshold: 0.2691\n",
            "F1 Score: 0.7845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1168/1168 [03:29<00:00,  5.57it/s]\n"
          ]
        }
      ],
      "source": [
        "Model_Name='VGG Model Saved(balanced Dataset)'\n",
        "model = create_model_VGG()\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "\n",
        "model.compile(\n",
        "    loss=LOSS,\n",
        "    metrics=METRICS,\n",
        "    optimizer=OPTIMIZER,\n",
        ")\n",
        "history0 = model.fit(train_gen, epochs=150, verbose=VERBOSE_LEVEL, validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "save_history(history0.history, timestamp,Model_Name)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./VGG_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nyyohsh3vA_7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaRy7x8hp-9I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omhd17qW9HHF"
      },
      "source": [
        "#The model resuts all 0 and 1(No Training):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm-QQKSRpApk"
      },
      "source": [
        "##Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCSwD3tFpwo0",
        "outputId": "380f9f15-0e61-46f1-9bba-f7caedb01644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create model\n",
            "layer 1 : input_4 is trainable: True\n",
            "layer 2 : block1_conv1 is trainable: True\n",
            "layer 3 : block1_conv2 is trainable: True\n",
            "layer 4 : block1_pool is trainable: True\n",
            "layer 5 : block2_conv1 is trainable: True\n",
            "layer 6 : block2_conv2 is trainable: True\n",
            "layer 7 : block2_pool is trainable: True\n",
            "layer 8 : block3_conv1 is trainable: True\n",
            "layer 9 : block3_conv2 is trainable: True\n",
            "layer 10 : block3_conv3 is trainable: True\n",
            "layer 11 : block3_pool is trainable: True\n",
            "layer 12 : block4_conv1 is trainable: True\n",
            "layer 13 : block4_conv2 is trainable: True\n",
            "layer 14 : block4_conv3 is trainable: True\n",
            "layer 15 : block4_pool is trainable: True\n",
            "layer 16 : block5_conv1 is trainable: True\n",
            "layer 17 : block5_conv2 is trainable: True\n",
            "layer 18 : block5_conv3 is trainable: True\n",
            "layer 19 : block5_pool is trainable: True\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 14,764,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "rows in train_df 934\n",
            "rows in val_df 234\n",
            "Found 934 non-validated image filenames.\n",
            "Found 234 non-validated image filenames.\n",
            "15/15 - 324s - loss: 1.0172 - accuracy: 0.5150 - val_loss: 0.6935 - val_accuracy: 0.4375 - 324s/epoch - 22s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [01:20<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "Threshold: 1\n",
            "F1 Score: 0.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10982/10982 [1:43:51<00:00,  1.76it/s]\n"
          ]
        }
      ],
      "source": [
        "Model_Name='Melignant Model Saved'\n",
        "model = create_model_malignant()\n",
        "model.summary()\n",
        "\n",
        "# get the current timestamp. This timestamp is used to save the model data with a unique name\n",
        "now = datetime.now()\n",
        "today = date.today()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "timestamp = str(today) + \"_\" + str(current_time)\n",
        "\n",
        "callback_list = []\n",
        "\n",
        "# if the model does not improve for 50 epochs, stop the training\n",
        "stop_early = EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
        "callback_list.append(stop_early)\n",
        "\n",
        "# if the output of the model should be saved, create a checkpoint callback function\n",
        "if SAVE_OUTPUT:\n",
        "    # set the weight path for saving the model\n",
        "    weight_path = CascadeLearning+'/' + timestamp + \"-model.hdf5\"\n",
        "    # create the model checkpoint callback to save the model wheights to a file\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        weight_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=VERBOSE_LEVEL,\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        overwrite=True,\n",
        "        mode='auto',\n",
        "    )\n",
        "    # append the checkpoint callback to the callback list\n",
        "    callback_list.append(checkpoint)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "# create a training and validation dataset from the train df\n",
        "train_df, val_df = create_splits(train, 0.2, 'target')\n",
        "\n",
        "print(\"rows in train_df\", train_df.shape[0])\n",
        "print(\"rows in val_df\", val_df.shape[0])\n",
        "\n",
        "# because we do not need the target column anymore we can drop it\n",
        "train_df.drop(['target'], axis=1, inplace=True)\n",
        "val_df.drop(['target'], axis=1, inplace=True)\n",
        "\n",
        "# call the generator functions\n",
        "train_gen = get_training_gen(train_df)\n",
        "val_gen = get_validation_gen(val_df)\n",
        "valX, valY = val_gen.next()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE)\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = [\n",
        "    'accuracy', \n",
        "    'AUC'\n",
        "] \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "'''model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),           loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.0)])\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "historyMalignant = model.fit(train_gen, epochs=1, verbose=VERBOSE_LEVEL, validation_data=(valX, valY))\n",
        "#        callbacks=callback_list, validation_data=(valX, valY))\n",
        "\n",
        "#Save Model\n",
        "type(model)\n",
        "model.save(Model_Name)\n",
        "\n",
        "\n",
        "#Model Evaluation\n",
        "# plot model history\n",
        "#save_history(historyMalignant.history, timestamp,Model_Name)\n",
        "#plt.savefig(CascadeLearning+'/'+Model_Name+'  Model Accuracy(save_history)',format='pdf')\n",
        "\n",
        "\n",
        "# plot the auc\n",
        "y_t = [] # true labels\n",
        "y_p = [] # predictions\n",
        "\n",
        "# iterate over the validation df and make a prediction for each image\n",
        "for i in tqdm(range(val_df.shape[0])):\n",
        "    y_true = val_df.iloc[i].target_1\n",
        "    image_path = val_df.iloc[i].image_path\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    img_array = tf.expand_dims(img, 0)\n",
        "    y_pred = model.predict(img_array)\n",
        "    y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "\n",
        "    y_t.append(y_true)\n",
        "    y_p.append(y_pred)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,len(y_p)):\n",
        "  y_p[i]=1\n",
        "\n",
        "plot_auc(y_t, y_p)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Model Auc(plot auc)',format='pdf')\n",
        "\n",
        "# calculate the precision, recall and the thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_t, y_p)\n",
        "\n",
        "# calculate the f1 score\n",
        "f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n",
        "\n",
        "# get the index from the highest f1 score\n",
        "idx = np.argmax(f1score)\n",
        "\n",
        "# get the precision, recall, threshold and the f1score\n",
        "precision = round(precision[idx], 4)\n",
        "recall = round(recall[idx], 4)\n",
        "threshold = round(thresholds[idx], 4)\n",
        "f1score = round(f1score[idx], 4)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Threshold:', threshold)\n",
        "print('F1 Score:', f1score)\n",
        "\n",
        "\n",
        "y_pred_binary = [pred_to_binary(x) for x in y_p]\n",
        "\n",
        "#Confusion Matrix\n",
        "cm =  confusion_matrix(y_t, y_pred_binary)\n",
        "cm_plot_label =['benign', 'malignant']\n",
        "plot_confusion_matrix(cm, cm_plot_label)\n",
        "plt.savefig(CascadeLearning+'/'+Model_Name+' Confusion_Matrix',format='pdf')\n",
        "#The model predicted 191 images correclty, but failed on 43.\n",
        "\n",
        "#Inference\n",
        "# Show a prediction for a random image\n",
        "image_path = test.iloc[0].image_path\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "img = img / 255\n",
        "img_array = tf.expand_dims(img, 0)\n",
        "\n",
        "\n",
        "\n",
        "if SAVE_OUTPUT:\n",
        "    # save the model to a json file\n",
        "    model_json = model.to_json()\n",
        "    with open(\"./\" + timestamp + \"-model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # create the submission.csv file\n",
        "    data=[]\n",
        "    for i in tqdm(range(test.shape[0])):\n",
        "        image_path = test.iloc[i].image_path\n",
        "        image_name = test.iloc[i].image_name\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = keras.preprocessing.image.img_to_array(img)\n",
        "        img = img / 255\n",
        "        img_array = tf.expand_dims(img, 0)\n",
        "        y_pred = model.predict(img_array)\n",
        "        y_pred = tf.nn.softmax(y_pred)[0].numpy()[1]\n",
        "        data.append([image_name, y_pred])\n",
        "\n",
        "    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n",
        "    sub_df.to_csv(\"./Malignant_submission.csv\", index=False)\n",
        "\n",
        "    sub_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucDcvNxBvKGv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRJlyAgXtNU1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiTLTqcRtNQ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNt_eIRItNMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2eKv2Jr3w5p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt-OcdVO8gLI"
      },
      "source": [
        "#Plot all Graphs for 150 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCiKrNTGGj-h",
        "outputId": "201d8c30-f1c9-47fb-cb99-02a185c1dab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/University of Southampton/Desertation Project/Code/Main Code files/cascade_transfer_learning_medical/Cascade all Model Layers Graph\n"
          ]
        }
      ],
      "source": [
        "cd Cascade all Model Layers Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXFySrcpGj7s"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "history0 = open('E2E Model Saved 2022-08-24_09:35:54-history.json')\n",
        "history0 = json.load(history0)\n",
        "history1 = open('Pretrained plus 1st layer Model Saved 2022-08-24_17:12:35-history.json')\n",
        "history1 = json.load(history1)\n",
        "history2 = open('Pretrained plus 2nd layer Model Saved 2022-08-24_22:52:27-history.json')\n",
        "history2 = json.load(history2)\n",
        "history3 = open('Pretrained plus 3rd layer Model Saved 2022-08-25_03:15:54-history.json')\n",
        "history3 = json.load(history3)\n",
        "history4 = open('Pretrained plus 4th layer Model Saved 2022-08-25_10:49:19-history.json')\n",
        "history4 = json.load(history4)\n",
        "history5 = open('Pretrained plus 5th layer Model Saved 2022-08-25_16:32:56-history.json')\n",
        "history5 = json.load(history5)\n",
        "history6 = open('Pretrained plus 6th layer Model Saved 2022-08-25_23:34:27-history.json')\n",
        "history6 = json.load(history6)\n",
        "history7 = open('Pretrained plus 7th layer Model Saved 2022-08-26_04:22:51-history.json')\n",
        "history7 = json.load(history7)\n",
        "history8 = open('Pretrained plus 8th layer Model Saved 2022-08-26_17:01:05-history.json')\n",
        "history8 = json.load(history8)\n",
        "historyResnet = open('ResNet Model Saved 2022-08-28_11:06:13-history.json')\n",
        "historyResnet = json.load(historyResnet)\n",
        "historyVGG = open('VGG Model Saved 2022-08-28_18:56:38-history.json')\n",
        "historyVGG = json.load(historyVGG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WypQ3Em5JjXQ",
        "outputId": "8ccce445-edb3-46ce-afcb-26adbd218127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy E2E = 0.6864\n",
            "Accuracy Layer 1 = 0.7373\n",
            "Accuracy Layer 2 = 0.7432\n",
            "Accuracy Layer 3 = 0.7194\n",
            "Accuracy Layer 4 = 0.7472\n",
            "Accuracy Layer 5 = 0.7465\n",
            "Accuracy Layer 6 = 0.7216\n",
            "Accuracy Layer 7 = 0.6546\n",
            "Accuracy Layer 8 = 0.683\n",
            "Accuracy ResNet = 0.9323\n",
            "Accuracy VGG = 0.9093\n"
          ]
        }
      ],
      "source": [
        "Accuracy0 = Average(history0['accuracy'])\n",
        "Accuracy1 = Average(history1['accuracy'])\n",
        "Accuracy2 = Average(history2['accuracy'])\n",
        "Accuracy3 = Average(history3['accuracy'])\n",
        "Accuracy4 = Average(history4['accuracy'])\n",
        "Accuracy5 = Average(history5['accuracy'])\n",
        "Accuracy6 = Average(history6['accuracy'])\n",
        "Accuracy7 = Average(history7['accuracy'])\n",
        "Accuracy8 = Average(history8['accuracy'])\n",
        "AccuracyResnet = Average(historyResnet['accuracy'])\n",
        "AccuracyVGG = Average(historyVGG['accuracy'])\n",
        "  \n",
        "# Printing average of the list\n",
        "print(\"Accuracy E2E =\", round(Accuracy0,4))\n",
        "print(\"Accuracy Layer 1 =\", round(Accuracy1, 4))\n",
        "print(\"Accuracy Layer 2 =\", round(Accuracy2, 4))\n",
        "print(\"Accuracy Layer 3 =\", round(Accuracy3, 4))\n",
        "print(\"Accuracy Layer 4 =\", round(Accuracy4, 4))\n",
        "print(\"Accuracy Layer 5 =\", round(Accuracy5, 4))\n",
        "print(\"Accuracy Layer 6 =\", round(Accuracy6, 4))\n",
        "print(\"Accuracy Layer 7 =\", round(Accuracy7, 4))\n",
        "print(\"Accuracy Layer 8 =\", round(Accuracy8, 4))\n",
        "print(\"Accuracy ResNet =\", round(AccuracyResnet, 4))\n",
        "print(\"Accuracy VGG =\", round(AccuracyVGG, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns0rhgjWMOGL"
      },
      "outputs": [],
      "source": [
        "names = ['Accuracy ResNet', 'Accuracy VGG', 'Accuracy E2E','Accuracy TCL']\n",
        "values = [AccuracyResnet, AccuracyVGG,Accuracy0, Accuracy4]\n",
        "\n",
        "plt.figure(figsize=(9, 3))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.bar(names, values)\n",
        "plt.subplot(132)\n",
        "plt.scatter(names, values)\n",
        "plt.subplot(133)\n",
        "plt.plot(names, values)\n",
        "plt.suptitle('Categorical Plotting')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQMbRIp-Js3L"
      },
      "outputs": [],
      "source": [
        "F1_VGG= 0.8077\n",
        "F1_Resnet= 0.7893\n",
        "F1_E2E= 0.7417\n",
        "F1_L1= 0.8\n",
        "F1_L2= 0.8145\n",
        "F1_L3= 0.8268\n",
        "F1_L4= 0.7761\n",
        "F1_L5= 0.7698\n",
        "F1_L6= 0.7673\n",
        "F1_L7= 0.7595\n",
        "F1_L8= 0.6667\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "3RZdnV-jMOCz",
        "outputId": "828a0bee-b11b-4733-86dc-663f6a34ec44"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"0df10549-6ecd-4569-807b-326350b05c92\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0df10549-6ecd-4569-807b-326350b05c92\")) {                    Plotly.newPlot(                        \"0df10549-6ecd-4569-807b-326350b05c92\",                        [{\"x\":[\"Accuracy ResNet\",\"Accuracy VGG\",\"Accuracy E2E\",\"Accuracy TCL\"],\"y\":[0.9323197706540426,0.9093147770563761,0.6863510184817844,0.74715203444163],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0df10549-6ecd-4569-807b-326350b05c92');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "fig = go.Figure( go.Scatter(x=names, y=values ) )\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "-H8wszWfMOAT",
        "outputId": "af0de68c-76a0-428b-81ab-a94f32c78a63"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"2da17929-df7b-4382-bf30-5989fa9d8de1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2da17929-df7b-4382-bf30-5989fa9d8de1\")) {                    Plotly.newPlot(                        \"2da17929-df7b-4382-bf30-5989fa9d8de1\",                        [{\"x\":[\"Accuracy ResNet\",\"Accuracy VGG\",\"Accuracy E2E\",\"Accuracy TCL\"],\"y\":[0.9323197706540426,0.9093147770563761,0.6863510184817844,0.74715203444163],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Transfer learning using TCL, E2E, ResNet and VGG architectures\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2da17929-df7b-4382-bf30-5989fa9d8de1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=names, y=values)],\n",
        "    layout_title_text=\"Transfer learning using TCL, E2E, ResNet and VGG architectures\"\n",
        ")\n",
        "fig.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACBJ-40YMN8j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed5fr1MyMN46"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obwoh-eIMN07"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke-67TLQJjUh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNKUscJTnNYO"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2['accuracy'], label='Layer 2 accuracy')\n",
        "plt.plot(history3['accuracy'], label='Layer 3 accuracy')\n",
        "plt.plot(history4['accuracy'], label='Layer 4 accuracy')\n",
        "plt.plot(history5['accuracy'], label='Layer 5 accuracy')\n",
        "plt.plot(history6['accuracy'], label='Layer 6 accuracy')\n",
        "plt.plot(history7['accuracy'], label='Layer 7 accuracy')\n",
        "plt.plot(history8['accuracy'], label='Layer 8 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig('All Layers Model Accuracy(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKwD8eRMnNYP"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3['val_accuracy'], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4['val_accuracy'], label='Layer 4 Val_Accuracy')\n",
        "plt.plot(history5['val_accuracy'], label='Layer 5 Val_Accuracy')\n",
        "plt.plot(history6['val_accuracy'], label='Layer 6 Val_Accuracy')\n",
        "plt.plot(history7['val_accuracy'], label='Layer 7 Val_Accuracy')\n",
        "plt.plot(history8['val_accuracy'], label='Layer 8 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig('All Layers Model Val_Accuracy(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4tKipCEnNYP"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['loss'], label='E2E Loss')\n",
        "plt.plot(history1['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2['loss'], label='Layer 2 Loss')\n",
        "plt.plot(history3['loss'], label='Layer 3 Loss')\n",
        "plt.plot(history4['loss'], label='Layer 4 Loss')\n",
        "plt.plot(history5['loss'], label='Layer 5 Loss')\n",
        "plt.plot(history6['loss'], label='Layer 6 Loss')\n",
        "plt.plot(history7['loss'], label='Layer 7 Loss')\n",
        "plt.plot(history8['loss'], label='Layer 8 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig('All Layers Model Loss(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCLzdWjmnNYP"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3['val_loss'], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4['val_loss'], label='Layer 4 Val_Loss')\n",
        "plt.plot(history5['val_loss'], label='Layer 5 Val_Loss')\n",
        "plt.plot(history6['val_loss'], label='Layer 6 Val_Loss')\n",
        "plt.plot(history7['val_loss'], label='Layer 7 Val_Loss')\n",
        "plt.plot(history8['val_loss'], label='Layer 8 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig('All Layers Model Val_Loss(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1EJQU7CnNYQ"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['auc'], label='E2E Auc')\n",
        "plt.plot(history1['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2['auc'], label='Layer 2 Auc')\n",
        "plt.plot(history3['auc'], label='Layer 3 Auc')\n",
        "plt.plot(history4['auc'], label='Layer 4 Auc')\n",
        "plt.plot(history5['auc'], label='Layer 5 Auc')\n",
        "plt.plot(history6['auc'], label='Layer 6 Auc')\n",
        "plt.plot(history7['auc'], label='Layer 7 Auc')\n",
        "plt.plot(history8['auc'], label='Layer 8 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig('All Layers Model Auc(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LeiRKNnnNYQ"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3['val_auc'], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4['val_auc'], label='Layer 4 Val_Auc')\n",
        "plt.plot(history5['val_auc'], label='Layer 5 Val_Auc')\n",
        "plt.plot(history6['val_auc'], label='Layer 6 Val_Auc')\n",
        "plt.plot(history7['val_auc'], label='Layer 7 Val_Auc')\n",
        "plt.plot(history8['val_auc'], label='Layer 8 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig('All Layers Model Val_Auc(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOEai3A3HVGL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXxK2r6xno88"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbYlyI0Gm_QW"
      },
      "source": [
        "##Plot comparision between TCL, VGG and RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRWGF780N0hR"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['accuracy'], label='E2E accuracy')\n",
        "plt.plot(history1['accuracy'], label='Layer 1 accuracy')\n",
        "plt.plot(history2['accuracy'], label='Layer 2 accuracy')\n",
        "plt.plot(history3['accuracy'], label='Layer 3 accuracy')\n",
        "plt.plot(history4['accuracy'], label='Layer 4 accuracy')\n",
        "plt.plot(history5['accuracy'], label='Layer 5 accuracy')\n",
        "plt.plot(history6['accuracy'], label='Layer 6 accuracy')\n",
        "plt.plot(history7['accuracy'], label='Layer 7 accuracy')\n",
        "plt.plot(history8['accuracy'], label='Layer 8 accuracy')\n",
        "plt.plot(historyResnet['accuracy'], label='ResNet accuracy')\n",
        "plt.plot(historyVGG['accuracy'], label='VGG accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig('All Model Accuracy(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iSn14b-xysf"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_accuracy'], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1['val_accuracy'], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2['val_accuracy'], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3['val_accuracy'], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4['val_accuracy'], label='Layer 4 Val_Accuracy')\n",
        "plt.plot(history5['val_accuracy'], label='Layer 5 Val_Accuracy')\n",
        "plt.plot(history6['val_accuracy'], label='Layer 6 Val_Accuracy')\n",
        "plt.plot(history7['val_accuracy'], label='Layer 7 Val_Accuracy')\n",
        "plt.plot(history8['val_accuracy'], label='Layer 8 Val_Accuracy')\n",
        "plt.plot(historyResnet['val_accuracy'], label='ResNet Val_Accuracy')\n",
        "plt.plot(historyVGG['val_accuracy'], label='VGG Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig('All Model Val_Accuracy(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odbE039bvVKT"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['loss'], label='E2E Loss')\n",
        "plt.plot(history1['loss'], label='Layer 1 Loss')\n",
        "plt.plot(history2['loss'], label='Layer 2 Loss')\n",
        "plt.plot(history3['loss'], label='Layer 3 Loss')\n",
        "plt.plot(history4['loss'], label='Layer 4 Loss')\n",
        "plt.plot(history5['loss'], label='Layer 5 Loss')\n",
        "plt.plot(history6['loss'], label='Layer 6 Loss')\n",
        "plt.plot(history7['loss'], label='Layer 7 Loss')\n",
        "plt.plot(history8['loss'], label='Layer 8 loss')\n",
        "plt.plot(historyResnet['loss'], label='ResNet Loss')\n",
        "plt.plot(historyVGG['loss'], label='VGG Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig('All Model Loss(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIFv-q39wFz0"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_loss'], label='E2E Val_Loss')\n",
        "plt.plot(history1['val_loss'], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2['val_loss'], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3['val_loss'], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4['val_loss'], label='Layer 4 Val_Loss')\n",
        "plt.plot(history5['val_loss'], label='Layer 5 Val_Loss')\n",
        "plt.plot(history6['val_loss'], label='Layer 6 Val_Loss')\n",
        "plt.plot(history7['val_loss'], label='Layer 7 Val_Loss')\n",
        "plt.plot(history8['val_loss'], label='Layer 8 Val_Loss')\n",
        "plt.plot(historyResnet['val_loss'], label='ResNet Val_Loss')\n",
        "plt.plot(historyVGG['val_loss'], label='VGG Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig('All Model Val_Loss(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY6Y2dD4HVhL"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['auc'], label='E2E Auc')\n",
        "plt.plot(history1['auc'], label='Layer 1 Auc')\n",
        "plt.plot(history2['auc'], label='Layer 2 Auc')\n",
        "plt.plot(history3['auc'], label='Layer 3 Auc')\n",
        "plt.plot(history4['auc'], label='Layer 4 Auc')\n",
        "plt.plot(history5['auc'], label='Layer 5 Auc')\n",
        "plt.plot(history6['auc'], label='Layer 6 Auc')\n",
        "plt.plot(history7['auc'], label='Layer 7 Auc')\n",
        "plt.plot(history8['auc'], label='Layer 8 Auc')\n",
        "plt.plot(historyResnet['auc'], label='ResNet Auc')\n",
        "plt.plot(historyVGG['auc'], label='VGG Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig('All Model Auc(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AKjMPkfHVhM"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_auc'], label='E2E Val_Auc')\n",
        "plt.plot(history1['val_auc'], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2['val_auc'], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3['val_auc'], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4['val_auc'], label='Layer 4 Val_Auc')\n",
        "plt.plot(history5['val_auc'], label='Layer 5 Val_Auc')\n",
        "plt.plot(history6['val_auc'], label='Layer 6 Val_Auc')\n",
        "plt.plot(history7['val_auc'], label='Layer 7 Val_Auc')\n",
        "plt.plot(history8['val_auc'], label='Layer 8 Val_Auc')\n",
        "plt.plot(historyResnet['val_auc'], label='ResNet Val_Auc')\n",
        "plt.plot(historyVGG['val_auc'], label='VGG Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig('All Model Val_Auc(Comparission)',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCcdf98Zno6p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjn5HLkino3r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwibIw-YZCB1"
      },
      "source": [
        "#Plot all graphs for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR8_9qjjY-5G"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['accuracy'][:100], label='E2E accuracy')\n",
        "plt.plot(history1['accuracy'][:100], label='Layer 1 accuracy')\n",
        "plt.plot(history2['accuracy'][:100], label='Layer 2 accuracy')\n",
        "plt.plot(history3['accuracy'][:100], label='Layer 3 accuracy')\n",
        "plt.plot(history4['accuracy'][:100], label='Layer 4 accuracy')\n",
        "plt.plot(history5['accuracy'][:100], label='Layer 5 accuracy')\n",
        "plt.plot(history6['accuracy'][:100], label='Layer 6 accuracy')\n",
        "plt.plot(history7['accuracy'][:100], label='Layer 7 accuracy')\n",
        "plt.plot(history8['accuracy'][:100], label='Layer 8 accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig('All Layers Model Accuracy(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bUK2xFIY-5G"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_accuracy'][:100], label='LE2E Val_Accuracy')\n",
        "plt.plot(history1['val_accuracy'][:100], label='Layer 1 Val_Accuracy')\n",
        "plt.plot(history2['val_accuracy'][:100], label='Layer 2 Val_Accuracy')\n",
        "plt.plot(history3['val_accuracy'][:100], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4['val_accuracy'][:100], label='Layer 4 Val_Accuracy')\n",
        "plt.plot(history5['val_accuracy'][:100], label='Layer 5 Val_Accuracy')\n",
        "plt.plot(history6['val_accuracy'][:100], label='Layer 6 Val_Accuracy')\n",
        "plt.plot(history7['val_accuracy'][:100], label='Layer 7 Val_Accuracy')\n",
        "plt.plot(history8['val_accuracy'][:100], label='Layer 8 Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig('All Layers Model Val_Accuracy(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ewHNEmTY-5H"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['loss'][:100], label='E2E Loss')\n",
        "plt.plot(history1['loss'][:100], label='Layer 1 Loss')\n",
        "plt.plot(history2['loss'][:100], label='Layer 2 Loss')\n",
        "plt.plot(history3['loss'][:100], label='Layer 3 Loss')\n",
        "plt.plot(history4['loss'][:100], label='Layer 4 Loss')\n",
        "plt.plot(history5['loss'][:100], label='Layer 5 Loss')\n",
        "plt.plot(history6['loss'][:100], label='Layer 6 Loss')\n",
        "plt.plot(history7['loss'][:100], label='Layer 7 Loss')\n",
        "plt.plot(history8['loss'][:100], label='Layer 8 Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig('All Layers Model Loss(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1SG5qdBY-5H"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_loss'][:100], label='E2E Val_Loss')\n",
        "plt.plot(history1['val_loss'][:100], label='Layer 1 Val_Loss')\n",
        "plt.plot(history2['val_loss'][:100], label='Layer 2 Val_Loss')\n",
        "plt.plot(history3['val_loss'][:100], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4['val_loss'][:100], label='Layer 4 Val_Loss')\n",
        "plt.plot(history5['val_loss'][:100], label='Layer 5 Val_Loss')\n",
        "plt.plot(history6['val_loss'][:100], label='Layer 6 Val_Loss')\n",
        "plt.plot(history7['val_loss'][:100], label='Layer 7 Val_Loss')\n",
        "plt.plot(history8['val_loss'][:100], label='Layer 8 Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig('All Layers Model Val_Loss(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa7pVwCLY-5H"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['auc'][:100], label='E2E Auc')\n",
        "plt.plot(history1['auc'][:100], label='Layer 1 Auc')\n",
        "plt.plot(history2['auc'][:100], label='Layer 2 Auc')\n",
        "plt.plot(history3['auc'][:100], label='Layer 3 Auc')\n",
        "plt.plot(history4['auc'][:100], label='Layer 4 Auc')\n",
        "plt.plot(history5['auc'][:100], label='Layer 5 Auc')\n",
        "plt.plot(history6['auc'][:100], label='Layer 6 Auc')\n",
        "plt.plot(history7['auc'][:100], label='Layer 7 Auc')\n",
        "plt.plot(history8['auc'][:100], label='Layer 8 Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig('All Layers Model Auc(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGDc6G2GY-5H"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_auc'][:100], label='E2E Val_Auc')\n",
        "plt.plot(history1['val_auc'][:100], label='Layer 1 Val_Auc')\n",
        "plt.plot(history2['val_auc'][:100], label='Layer 2 Val_Auc')\n",
        "plt.plot(history3['val_auc'][:100], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4['val_auc'][:100], label='Layer 4 Val_Auc')\n",
        "plt.plot(history5['val_auc'][:100], label='Layer 5 Val_Auc')\n",
        "plt.plot(history6['val_auc'][:100], label='Layer 6 Val_Auc')\n",
        "plt.plot(history7['val_auc'][:100], label='Layer 7 Val_Auc')\n",
        "plt.plot(history8['val_auc'][:100], label='Layer 8 Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig('All Layers Model Val_Auc(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjy_CwPLY-5I"
      },
      "source": [
        "##Plot comparision between TCL, VGG and RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbKWeEHmY-5I"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['accuracy'][:100], label='E2E accuracy')\n",
        "#plt.plot(history1['accuracy'][:100], label='Layer 1 accuracy')\n",
        "#plt.plot(history2['accuracy'][:100], label='Layer 2 accuracy')\n",
        "#plt.plot(history3['accuracy'][:100], label='Layer 3 accuracy')\n",
        "plt.plot(history4['accuracy'][:100], label='TCL Layer 4 accuracy')\n",
        "#plt.plot(history5['accuracy'][:100], label='Layer 5 accuracy')\n",
        "#plt.plot(history6['accuracy'][:100], label='Layer 6 accuracy')\n",
        "#plt.plot(history7['accuracy'][:100], label='Layer 7 accuracy')\n",
        "#plt.plot(history8['accuracy'][:100], label='Layer 8 accuracy')\n",
        "plt.plot(historyResnet['accuracy'][:100], label='ResNet accuracy')\n",
        "plt.plot(historyVGG['accuracy'][:100], label='VGG accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.savefig('All Model Accuracy(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4VkTqxmY-5I"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_accuracy'][:100], label='LE2E Val_Accuracy')\n",
        "#plt.plot(history1['val_accuracy'][:100], label='Layer 1 Val_Accuracy')\n",
        "#plt.plot(history2['val_accuracy'][:100], label='Layer 2 Val_Accuracy')\n",
        "#plt.plot(history3['val_accuracy'][:100], label='Layer 3 Val_Accuracy')\n",
        "plt.plot(history4['val_accuracy'][:100], label='TCL Layer 4 Val_Accuracy')\n",
        "#plt.plot(history5['val_accuracy'][:100], label='Layer 5 Val_Accuracy')\n",
        "#plt.plot(history6['val_accuracy'][:100], label='Layer 6 Val_Accuracy')\n",
        "#plt.plot(history7['val_accuracy'][:100], label='Layer 7 Val_Accuracy')\n",
        "#plt.plot(history8['val_accuracy'][:100], label='Layer 8 Val_Accuracy')\n",
        "plt.plot(historyResnet['val_accuracy'][:100], label='ResNet Val_Accuracy')\n",
        "plt.plot(historyVGG['val_accuracy'][:100], label='VGG Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Accuracy\")\n",
        "plt.savefig('All Model Val_Accuracy(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDO9Xuc6Y-5I"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['loss'][:100], label='E2E Loss')\n",
        "#plt.plot(history1['loss'][:100], label='Layer 1 Loss')\n",
        "#plt.plot(history2['loss'][:100], label='Layer 2 Loss')\n",
        "#plt.plot(history3['loss'][:100], label='Layer 3 Loss')\n",
        "plt.plot(history4['loss'][:100], label='TCL Layer 4 Loss')\n",
        "#plt.plot(history5['loss'][:100], label='Layer 5 Loss')\n",
        "#plt.plot(history6['loss'][:100], label='Layer 6 Loss')\n",
        "#plt.plot(history7['loss'][:100], label='Layer 7 Loss')\n",
        "#plt.plot(history8['loss'][:100], label='Layer 8 loss')\n",
        "plt.plot(historyResnet['loss'][:100], label='ResNet Loss')\n",
        "plt.plot(historyVGG['loss'][:100], label='VGG Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "plt.savefig('All Model Loss(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsfUEHPxY-5J"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_loss'][:100], label='E2E Val_Loss')\n",
        "#plt.plot(history1['val_loss'][:100], label='Layer 1 Val_Loss')\n",
        "#plt.plot(history2['val_loss'][:100], label='Layer 2 Val_Loss')\n",
        "#plt.plot(history3['val_loss'][:100], label='Layer 3 Val_Loss')\n",
        "plt.plot(history4['val_loss'][:100], label='TCL Layer 4 Val_Loss')\n",
        "#plt.plot(history5['val_loss'][:100], label='Layer 5 Val_Loss')\n",
        "#plt.plot(history6['val_loss'][:100], label='Layer 6 Val_Loss')\n",
        "#plt.plot(history7['val_loss'][:100], label='Layer 7 Val_Loss')\n",
        "#plt.plot(history8['val_loss'][:100], label='Layer 8 Val_Loss')\n",
        "plt.plot(historyResnet['val_loss'][:100], label='ResNet Val_Loss')\n",
        "plt.plot(historyVGG['val_loss'][:100], label='VGG Val_Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Loss\")\n",
        "plt.savefig('All Model Val_Loss(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nddY9JSGY-5J"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['auc'][:100], label='E2E Auc')\n",
        "#plt.plot(history1['auc'][:100], label='Layer 1 Auc')\n",
        "#plt.plot(history2['auc'][:100], label='Layer 2 Auc')\n",
        "#plt.plot(history3['auc'][:100], label='Layer 3 Auc')\n",
        "plt.plot(history4['auc'][:100], label='TCL Layer 4 Auc')\n",
        "#plt.plot(history5['auc'][:100], label='Layer 5 Auc')\n",
        "#plt.plot(history6['auc'][:100], label='Layer 6 Auc')\n",
        "#plt.plot(history7['auc'][:100], label='Layer 7 Auc')\n",
        "#plt.plot(history8['auc'][:100], label='Layer 8 Auc')\n",
        "plt.plot(historyResnet['auc'][:100], label='ResNet Auc')\n",
        "plt.plot(historyVGG['auc'][:100], label='VGG Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Auc\")\n",
        "plt.savefig('All Model Auc(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r2I_7dbY-5J"
      },
      "outputs": [],
      "source": [
        "#def save_history(history, timestamp,Model_Name):\n",
        "f = plt.figure()\n",
        "f.set_figwidth(15)\n",
        "plt.plot(history0['val_auc'][:100], label='E2E Val_Auc')\n",
        "#plt.plot(history1['val_auc'][:100], label='Layer 1 Val_Auc')\n",
        "#plt.plot(history2['val_auc'][:100], label='Layer 2 Val_Auc')\n",
        "#plt.plot(history3['val_auc'][:100], label='Layer 3 Val_Auc')\n",
        "plt.plot(history4['val_auc'][:100], label='Layer 4 Val_Auc')\n",
        "#plt.plot(history5['val_auc'][:100], label='Layer 5 Val_Auc')\n",
        "#plt.plot(history6['val_auc'][:100], label='Layer 6 Val_Auc')\n",
        "#plt.plot(history7['val_auc'][:100], label='Layer 7 Val_Auc')\n",
        "#plt.plot(history8['val_auc'][:100], label='Layer 8 Val_Auc')\n",
        "plt.plot(historyResnet['val_auc'][:100], label='ResNet Val_Auc')\n",
        "plt.plot(historyVGG['val_auc'][:100], label='VGG Val_Auc')\n",
        "plt.legend()\n",
        "plt.title(\"Model Val_Auc\")\n",
        "plt.savefig('All Model Val_Auc(Comparission) for 100 epochs',format='pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6OORy3Cno00"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tsGIPHbnoxm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNPtnBpwnouh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QRi-CJTBt1i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0-wrmMJBtyj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbVqmYIwZY1B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwGHYKz19SW9"
      },
      "source": [
        "#END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmgwTSanZYyj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed_bbwVhZYvq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRdxql_iZYsx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDpqKydPZYqB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qswR3TT-ZYnC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhdEHGviZYjR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZuxUZqHZYgS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrJ5VsqZZYdh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwQBVBotZYax"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drcLQcRQNzwY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX1iAFDDNztQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy8rCfz8zrTV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}